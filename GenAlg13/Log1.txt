2020-03-27 10:01:47.824336: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-03-27 10:01:47.827887: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  0   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2020-03-27 10:01:58.485690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-03-27 10:01:58.509401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s
2020-03-27 10:01:58.515227: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-03-27 10:01:58.522470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-03-27 10:01:58.528583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-03-27 10:01:58.532379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-03-27 10:01:58.539748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-03-27 10:01:58.545753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-03-27 10:01:58.549412: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found
2020-03-27 10:01:58.552216: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-03-27 10:01:58.557493: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-03-27 10:01:58.560114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-27 10:01:58.562756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense (Dense)                (None, 1610)              1263850
_________________________________________________________________
activation (Activation)      (None, 1610)              0
_________________________________________________________________
dropout (Dropout)            (None, 1610)              0
_________________________________________________________________
batch_normalization (BatchNo (None, 1610)              6440
_________________________________________________________________
dense_1 (Dense)              (None, 610)               982710
_________________________________________________________________
activation_1 (Activation)    (None, 610)               0
_________________________________________________________________
batch_normalization_1 (Batch (None, 610)               2440
_________________________________________________________________
dense_2 (Dense)              (None, 1220)              745420
_________________________________________________________________
activation_2 (Activation)    (None, 1220)              0
_________________________________________________________________
dropout_1 (Dropout)          (None, 1220)              0
_________________________________________________________________
batch_normalization_2 (Batch (None, 1220)              4880
_________________________________________________________________
dense_3 (Dense)              (None, 10)                12210
=================================================================
Total params: 3,017,950
Trainable params: 3,011,070
Non-trainable params: 6,880
_________________________________________________________________
None
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_4 (Dense)              (None, 290)               227650
_________________________________________________________________
activation_3 (Activation)    (None, 290)               0
_________________________________________________________________
dropout_2 (Dropout)          (None, 290)               0
_________________________________________________________________
batch_normalization_3 (Batch (None, 290)               1160
_________________________________________________________________
dense_5 (Dense)              (None, 10)                2910
=================================================================
Total params: 231,720
Trainable params: 231,140
Non-trainable params: 580
_________________________________________________________________
None
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_6 (Dense)              (None, 620)               486700
_________________________________________________________________
activation_4 (Activation)    (None, 620)               0
_________________________________________________________________
batch_normalization_4 (Batch (None, 620)               2480
_________________________________________________________________
dense_7 (Dense)              (None, 430)               267030
_________________________________________________________________
activation_5 (Activation)    (None, 430)               0
_________________________________________________________________
dropout_3 (Dropout)          (None, 430)               0
_________________________________________________________________
batch_normalization_5 (Batch (None, 430)               1720
_________________________________________________________________
dense_8 (Dense)              (None, 10)                4310
=================================================================
Total params: 762,240
Trainable params: 760,140
Non-trainable params: 2,100
_________________________________________________________________
None
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_9 (Dense)              (None, 1900)              1491500
_________________________________________________________________
activation_6 (Activation)    (None, 1900)              0
_________________________________________________________________
dense_10 (Dense)             (None, 990)               1881990
_________________________________________________________________
activation_7 (Activation)    (None, 990)               0
_________________________________________________________________
dropout_4 (Dropout)          (None, 990)               0
_________________________________________________________________
batch_normalization_6 (Batch (None, 990)               3960
_________________________________________________________________
dense_11 (Dense)             (None, 490)               485590
_________________________________________________________________
activation_8 (Activation)    (None, 490)               0
_________________________________________________________________
dropout_5 (Dropout)          (None, 490)               0
_________________________________________________________________
batch_normalization_7 (Batch (None, 490)               1960
_________________________________________________________________
dense_12 (Dense)             (None, 1330)              653030
_________________________________________________________________
activation_9 (Activation)    (None, 1330)              0
_________________________________________________________________
dropout_6 (Dropout)          (None, 1330)              0
_________________________________________________________________
dense_13 (Dense)             (None, 10)                13310
=================================================================
Total params: 4,531,340
Trainable params: 4,528,380
Non-trainable params: 2,960
_________________________________________________________________
None
Model: "model_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_14 (Dense)             (None, 970)               761450
_________________________________________________________________
activation_10 (Activation)   (None, 970)               0
_________________________________________________________________
dense_15 (Dense)             (None, 1160)              1126360
_________________________________________________________________
activation_11 (Activation)   (None, 1160)              0
_________________________________________________________________
dropout_7 (Dropout)          (None, 1160)              0
_________________________________________________________________
batch_normalization_8 (Batch (None, 1160)              4640
_________________________________________________________________
dense_16 (Dense)             (None, 10)                11610
=================================================================
Total params: 1,904,060
Trainable params: 1,901,740
Non-trainable params: 2,320
_________________________________________________________________
None
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_17 (Dense)             (None, 50)                39250
_________________________________________________________________
activation_12 (Activation)   (None, 50)                0
_________________________________________________________________
dropout_8 (Dropout)          (None, 50)                0
_________________________________________________________________
batch_normalization_9 (Batch (None, 50)                200
_________________________________________________________________
dense_18 (Dense)             (None, 1160)              59160
_________________________________________________________________
activation_13 (Activation)   (None, 1160)              0
_________________________________________________________________
dropout_9 (Dropout)          (None, 1160)              0
_________________________________________________________________
batch_normalization_10 (Batc (None, 1160)              4640
_________________________________________________________________
dense_19 (Dense)             (None, 10)                11610
=================================================================
Total params: 114,860
Trainable params: 112,440
Non-trainable params: 2,420
_________________________________________________________________
None
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_20 (Dense)             (None, 940)               737900
_________________________________________________________________
activation_14 (Activation)   (None, 940)               0
_________________________________________________________________
dropout_10 (Dropout)         (None, 940)               0
_________________________________________________________________
dense_21 (Dense)             (None, 740)               696340
_________________________________________________________________
activation_15 (Activation)   (None, 740)               0
_________________________________________________________________
dropout_11 (Dropout)         (None, 740)               0
_________________________________________________________________
batch_normalization_11 (Batc (None, 740)               2960
_________________________________________________________________
dense_22 (Dense)             (None, 1910)              1415310
_________________________________________________________________
activation_16 (Activation)   (None, 1910)              0
_________________________________________________________________
dropout_12 (Dropout)         (None, 1910)              0
_________________________________________________________________
dense_23 (Dense)             (None, 10)                19110
_________________________________________________________________
activation_17 (Activation)   (None, 10)                0
_________________________________________________________________
dense_24 (Dense)             (None, 10)                110
=================================================================
Total params: 2,871,730
Trainable params: 2,870,250
Non-trainable params: 1,480
_________________________________________________________________
None
Model: "model_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_25 (Dense)             (None, 440)               345400
_________________________________________________________________
activation_18 (Activation)   (None, 440)               0
_________________________________________________________________
dropout_13 (Dropout)         (None, 440)               0
_________________________________________________________________
dense_26 (Dense)             (None, 10)                4410
=================================================================
Total params: 349,810
Trainable params: 349,810
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_27 (Dense)             (None, 200)               157000
_________________________________________________________________
activation_19 (Activation)   (None, 200)               0
_________________________________________________________________
dropout_14 (Dropout)         (None, 200)               0
_________________________________________________________________
dense_28 (Dense)             (None, 1990)              399990
_________________________________________________________________
activation_20 (Activation)   (None, 1990)              0
_________________________________________________________________
dropout_15 (Dropout)         (None, 1990)              0
_________________________________________________________________
batch_normalization_12 (Batc (None, 1990)              7960
_________________________________________________________________
dense_29 (Dense)             (None, 1090)              2170190
_________________________________________________________________
activation_21 (Activation)   (None, 1090)              0
_________________________________________________________________
dropout_16 (Dropout)         (None, 1090)              0
_________________________________________________________________
batch_normalization_13 (Batc (None, 1090)              4360
_________________________________________________________________
dense_30 (Dense)             (None, 10)                10910
=================================================================
Total params: 2,750,410
Trainable params: 2,744,250
Non-trainable params: 6,160
_________________________________________________________________
None
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_31 (Dense)             (None, 220)               172700
_________________________________________________________________
activation_22 (Activation)   (None, 220)               0
_________________________________________________________________
batch_normalization_14 (Batc (None, 220)               880
_________________________________________________________________
dense_32 (Dense)             (None, 160)               35360
_________________________________________________________________
activation_23 (Activation)   (None, 160)               0
_________________________________________________________________
dropout_17 (Dropout)         (None, 160)               0
_________________________________________________________________
dense_33 (Dense)             (None, 470)               75670
_________________________________________________________________
activation_24 (Activation)   (None, 470)               0
_________________________________________________________________
dropout_18 (Dropout)         (None, 470)               0
_________________________________________________________________
batch_normalization_15 (Batc (None, 470)               1880
_________________________________________________________________
dense_34 (Dense)             (None, 1120)              527520
_________________________________________________________________
activation_25 (Activation)   (None, 1120)              0
_________________________________________________________________
dense_35 (Dense)             (None, 10)                11210
=================================================================
Total params: 825,220
Trainable params: 823,840
Non-trainable params: 1,380
_________________________________________________________________
None
Model: "model_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_36 (Dense)             (None, 840)               659400
_________________________________________________________________
activation_26 (Activation)   (None, 840)               0
_________________________________________________________________
dense_37 (Dense)             (None, 380)               319580
_________________________________________________________________
activation_27 (Activation)   (None, 380)               0
_________________________________________________________________
batch_normalization_16 (Batc (None, 380)               1520
_________________________________________________________________
dense_38 (Dense)             (None, 1520)              579120
_________________________________________________________________
activation_28 (Activation)   (None, 1520)              0
_________________________________________________________________
batch_normalization_17 (Batc (None, 1520)              6080
_________________________________________________________________
dense_39 (Dense)             (None, 10)                15210
=================================================================
Total params: 1,580,910
Trainable params: 1,577,110
Non-trainable params: 3,800
_________________________________________________________________
None
Model: "model_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_40 (Dense)             (None, 1480)              1161800
_________________________________________________________________
activation_29 (Activation)   (None, 1480)              0
_________________________________________________________________
dense_41 (Dense)             (None, 580)               858980
_________________________________________________________________
activation_30 (Activation)   (None, 580)               0
_________________________________________________________________
dropout_19 (Dropout)         (None, 580)               0
_________________________________________________________________
dense_42 (Dense)             (None, 320)               185920
_________________________________________________________________
activation_31 (Activation)   (None, 320)               0
_________________________________________________________________
dense_43 (Dense)             (None, 420)               134820
_________________________________________________________________
activation_32 (Activation)   (None, 420)               0
_________________________________________________________________
batch_normalization_18 (Batc (None, 420)               1680
_________________________________________________________________
dense_44 (Dense)             (None, 10)                4210
=================================================================
Total params: 2,347,410
Trainable params: 2,346,570
Non-trainable params: 840
_________________________________________________________________
None
Model: "model_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_45 (Dense)             (None, 1130)              887050
_________________________________________________________________
activation_33 (Activation)   (None, 1130)              0
_________________________________________________________________
dense_46 (Dense)             (None, 90)                101790
_________________________________________________________________
activation_34 (Activation)   (None, 90)                0
_________________________________________________________________
dropout_20 (Dropout)         (None, 90)                0
_________________________________________________________________
batch_normalization_19 (Batc (None, 90)                360
_________________________________________________________________
dense_47 (Dense)             (None, 820)               74620
_________________________________________________________________
activation_35 (Activation)   (None, 820)               0
_________________________________________________________________
dropout_21 (Dropout)         (None, 820)               0
_________________________________________________________________
dense_48 (Dense)             (None, 1320)              1083720
_________________________________________________________________
activation_36 (Activation)   (None, 1320)              0
_________________________________________________________________
dense_49 (Dense)             (None, 10)                13210
=================================================================
Total params: 2,160,750
Trainable params: 2,160,570
Non-trainable params: 180
_________________________________________________________________
None
Model: "model_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_50 (Dense)             (None, 1800)              1413000
_________________________________________________________________
activation_37 (Activation)   (None, 1800)              0
_________________________________________________________________
batch_normalization_20 (Batc (None, 1800)              7200
_________________________________________________________________
dense_51 (Dense)             (None, 700)               1260700
_________________________________________________________________
activation_38 (Activation)   (None, 700)               0
_________________________________________________________________
dropout_22 (Dropout)         (None, 700)               0
_________________________________________________________________
dense_52 (Dense)             (None, 520)               364520
_________________________________________________________________
activation_39 (Activation)   (None, 520)               0
_________________________________________________________________
dropout_23 (Dropout)         (None, 520)               0
_________________________________________________________________
batch_normalization_21 (Batc (None, 520)               2080
_________________________________________________________________
dense_53 (Dense)             (None, 10)                5210
=================================================================
Total params: 3,052,710
Trainable params: 3,048,070
Non-trainable params: 4,640
_________________________________________________________________
None
Model: "model_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_54 (Dense)             (None, 1720)              1350200
_________________________________________________________________
activation_40 (Activation)   (None, 1720)              0
_________________________________________________________________
dropout_24 (Dropout)         (None, 1720)              0
_________________________________________________________________
batch_normalization_22 (Batc (None, 1720)              6880
_________________________________________________________________
dense_55 (Dense)             (None, 510)               877710
_________________________________________________________________
activation_41 (Activation)   (None, 510)               0
_________________________________________________________________
dense_56 (Dense)             (None, 10)                5110
=================================================================
Total params: 2,239,900
Trainable params: 2,236,460
Non-trainable params: 3,440
_________________________________________________________________
None
Model: "model_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_57 (Dense)             (None, 60)                47100
_________________________________________________________________
activation_42 (Activation)   (None, 60)                0
_________________________________________________________________
dropout_25 (Dropout)         (None, 60)                0
_________________________________________________________________
dense_58 (Dense)             (None, 390)               23790
_________________________________________________________________
activation_43 (Activation)   (None, 390)               0
_________________________________________________________________
batch_normalization_23 (Batc (None, 390)               1560
_________________________________________________________________
dense_59 (Dense)             (None, 880)               344080
_________________________________________________________________
activation_44 (Activation)   (None, 880)               0
_________________________________________________________________
dense_60 (Dense)             (None, 10)                8810
=================================================================
Total params: 425,340
Trainable params: 424,560
Non-trainable params: 780
_________________________________________________________________
None
Model: "model_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_61 (Dense)             (None, 910)               714350
_________________________________________________________________
activation_45 (Activation)   (None, 910)               0
_________________________________________________________________
dropout_26 (Dropout)         (None, 910)               0
_________________________________________________________________
batch_normalization_24 (Batc (None, 910)               3640
_________________________________________________________________
dense_62 (Dense)             (None, 10)                9110
=================================================================
Total params: 727,100
Trainable params: 725,280
Non-trainable params: 1,820
_________________________________________________________________
None
Model: "model_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_63 (Dense)             (None, 880)               690800
_________________________________________________________________
activation_46 (Activation)   (None, 880)               0
_________________________________________________________________
batch_normalization_25 (Batc (None, 880)               3520
_________________________________________________________________
dense_64 (Dense)             (None, 50)                44050
_________________________________________________________________
activation_47 (Activation)   (None, 50)                0
_________________________________________________________________
dropout_27 (Dropout)         (None, 50)                0
_________________________________________________________________
batch_normalization_26 (Batc (None, 50)                200
_________________________________________________________________
dense_65 (Dense)             (None, 970)               49470
_________________________________________________________________
activation_48 (Activation)   (None, 970)               0
_________________________________________________________________
dense_66 (Dense)             (None, 890)               864190
_________________________________________________________________
activation_49 (Activation)   (None, 890)               0
_________________________________________________________________
dropout_28 (Dropout)         (None, 890)               0
_________________________________________________________________
batch_normalization_27 (Batc (None, 890)               3560
_________________________________________________________________
dense_67 (Dense)             (None, 10)                8910
=================================================================
Total params: 1,664,700
Trainable params: 1,661,060
Non-trainable params: 3,640
_________________________________________________________________
None
Model: "model_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_68 (Dense)             (None, 460)               361100
_________________________________________________________________
activation_50 (Activation)   (None, 460)               0
_________________________________________________________________
dropout_29 (Dropout)         (None, 460)               0
_________________________________________________________________
dense_69 (Dense)             (None, 1890)              871290
_________________________________________________________________
activation_51 (Activation)   (None, 1890)              0
_________________________________________________________________
dropout_30 (Dropout)         (None, 1890)              0
_________________________________________________________________
dense_70 (Dense)             (None, 1720)              3252520
_________________________________________________________________
activation_52 (Activation)   (None, 1720)              0
_________________________________________________________________
dense_71 (Dense)             (None, 1580)              2719180
_________________________________________________________________
activation_53 (Activation)   (None, 1580)              0
_________________________________________________________________
dense_72 (Dense)             (None, 10)                15810
=================================================================
Total params: 7,219,900
Trainable params: 7,219,900
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_73 (Dense)             (None, 1910)              1499350
_________________________________________________________________
activation_54 (Activation)   (None, 1910)              0
_________________________________________________________________
batch_normalization_28 (Batc (None, 1910)              7640
_________________________________________________________________
dense_74 (Dense)             (None, 1120)              2140320
_________________________________________________________________
activation_55 (Activation)   (None, 1120)              0
_________________________________________________________________
dropout_31 (Dropout)         (None, 1120)              0
_________________________________________________________________
batch_normalization_29 (Batc (None, 1120)              4480
_________________________________________________________________
dense_75 (Dense)             (None, 890)               997690
_________________________________________________________________
activation_56 (Activation)   (None, 890)               0
_________________________________________________________________
dropout_32 (Dropout)         (None, 890)               0
_________________________________________________________________
dense_76 (Dense)             (None, 170)               151470
_________________________________________________________________
activation_57 (Activation)   (None, 170)               0
_________________________________________________________________
batch_normalization_30 (Batc (None, 170)               680
_________________________________________________________________
dense_77 (Dense)             (None, 10)                1710
=================================================================
Total params: 4,803,340
Trainable params: 4,796,940
Non-trainable params: 6,400
_________________________________________________________________
None
Model: "model_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_78 (Dense)             (None, 1180)              926300
_________________________________________________________________
activation_58 (Activation)   (None, 1180)              0
_________________________________________________________________
dense_79 (Dense)             (None, 10)                11810
=================================================================
Total params: 938,110
Trainable params: 938,110
Non-trainable params: 0
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples

Epoch 1/10
Epoch 1/10
Epoch 1/10
Epoch 1/10
Epoch 1/10Train on 48000 samples, validate on 12000 samples

Train on 48000 samples, validate on 12000 samplesEpoch 1/10

Epoch 1/10
 -> id = 20  Epoch: 0   accuracy: 0.9036458  val_acc: 0.93841666
48000/48000 - 25s - loss: 0.3351 - accuracy: 0.9036 - val_loss: 0.2187 - val_accuracy: 0.9384
Epoch 2/10
 -> id = 7  Epoch: 0   accuracy: 0.8214375  val_acc: 0.92266667
48000/48000 - 33s - loss: 0.5637 - accuracy: 0.8214 - val_loss: 0.2684 - val_accuracy: 0.9227
Epoch 2/10
 -> id = 1  Epoch: 0   accuracy: 0.8478125  val_acc: 0.92125
48000/48000 - 82s - loss: 0.4975 - accuracy: 0.8478 - val_loss: 0.3225 - val_accuracy: 0.9212
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.92139584  val_acc: 0.96091664
48000/48000 - 97s - loss: 0.2553 - accuracy: 0.9214 - val_loss: 0.1565 - val_accuracy: 0.9609
Epoch 2/10
 -> id = 4  Epoch: 0   accuracy: 0.9240208  val_acc: 0.96066666
48000/48000 - 103s - loss: 0.2608 - accuracy: 0.9240 - val_loss: 0.1258 - val_accuracy: 0.9607
Epoch 2/10
 -> id = 12  Epoch: 0   accuracy: 0.86777085  val_acc: 0.94516665
48000/48000 - 110s - loss: 0.4908 - accuracy: 0.8678 - val_loss: 0.1760 - val_accuracy: 0.9452
Epoch 2/10
 -> id = 7  Epoch: 1   accuracy: 0.9075625  val_acc: 0.9406667
48000/48000 - 78s - loss: 0.3086 - accuracy: 0.9076 - val_loss: 0.2140 - val_accuracy: 0.9407
Epoch 3/10
 -> id = 15  Epoch: 0   accuracy: 0.86639583  val_acc: 0.9316667
48000/48000 - 113s - loss: 0.4339 - accuracy: 0.8664 - val_loss: 0.2470 - val_accuracy: 0.9317
Epoch 2/10
 -> id = 14  Epoch: 0   accuracy: 0.92345834  val_acc: 0.95675
48000/48000 - 114s - loss: 0.2663 - accuracy: 0.9235 - val_loss: 0.1333 - val_accuracy: 0.9567
Epoch 2/10
 -> id = 20  Epoch: 1   accuracy: 0.944  val_acc: 0.95308334
48000/48000 - 91s - loss: 0.1927 - accuracy: 0.9440 - val_loss: 0.1656 - val_accuracy: 0.9531
Epoch 3/10
 -> id = 2  Epoch: 0   accuracy: 0.9171042  val_acc: 0.94275
48000/48000 - 118s - loss: 0.2816 - accuracy: 0.9171 - val_loss: 0.2283 - val_accuracy: 0.9427
Epoch 2/10
 -> id = 5  Epoch: 0   accuracy: 0.869875  val_acc: 0.9238333
48000/48000 - 119s - loss: 0.4487 - accuracy: 0.8699 - val_loss: 0.2587 - val_accuracy: 0.9238
Epoch 2/10
 -> id = 11  Epoch: 0   accuracy: 0.80789584  val_acc: 0.86475
48000/48000 - 129s - loss: 0.5956 - accuracy: 0.8079 - val_loss: 1.0819 - val_accuracy: 0.8648
Epoch 2/10
 -> id = 9  Epoch: 0   accuracy: 0.83964586  val_acc: 0.56908333
48000/48000 - 133s - loss: 0.4824 - accuracy: 0.8396 - val_loss: 1.3550 - val_accuracy: 0.5691
Epoch 2/10
 -> id = 10  Epoch: 0   accuracy: 0.9244375  val_acc: 0.94633335
48000/48000 - 134s - loss: 0.2799 - accuracy: 0.9244 - val_loss: 0.1830 - val_accuracy: 0.9463
Epoch 2/10
 -> id = 18  Epoch: 0   accuracy: 0.6783958  val_acc: 0.9285833
48000/48000 - 140s - loss: 0.9168 - accuracy: 0.6784 - val_loss: 0.2451 - val_accuracy: 0.9286
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.82685417  val_acc: 0.92075
48000/48000 - 145s - loss: 0.7844 - accuracy: 0.8269 - val_loss: 0.4226 - val_accuracy: 0.9208
Epoch 2/10
 -> id = 17  Epoch: 0   accuracy: 0.858375  val_acc: 0.9360833
48000/48000 - 152s - loss: 0.4941 - accuracy: 0.8584 - val_loss: 0.2239 - val_accuracy: 0.9361
Epoch 2/10
 -> id = 8  Epoch: 0   accuracy: 0.706625  val_acc: 0.90708333
48000/48000 - 155s - loss: 0.9953 - accuracy: 0.7066 - val_loss: 0.3387 - val_accuracy: 0.9071
Epoch 2/10
 -> id = 13  Epoch: 0   accuracy: 0.5950417  val_acc: 0.903
48000/48000 - 161s - loss: 1.4245 - accuracy: 0.5950 - val_loss: 0.6548 - val_accuracy: 0.9030
Epoch 2/10
 -> id = 1  Epoch: 1   accuracy: 0.91625  val_acc: 0.942
48000/48000 - 83s - loss: 0.2849 - accuracy: 0.9162 - val_loss: 0.2127 - val_accuracy: 0.9420
Epoch 3/10
 -> id = 0  Epoch: 0   accuracy: 0.8776875  val_acc: 0.9374167
48000/48000 - 166s - loss: 0.4390 - accuracy: 0.8777 - val_loss: 0.6675 - val_accuracy: 0.9374
Epoch 2/10
 -> id = 3  Epoch: 0   accuracy: 0.9201458  val_acc: 0.9590833
48000/48000 - 170s - loss: 0.2726 - accuracy: 0.9201 - val_loss: 0.1417 - val_accuracy: 0.9591
Epoch 2/10
 -> id = 19  Epoch: 0   accuracy: 0.91258335  val_acc: 0.95533335
48000/48000 - 173s - loss: 0.2975 - accuracy: 0.9126 - val_loss: 0.1619 - val_accuracy: 0.9553
Epoch 2/10
 -> id = 7  Epoch: 2   accuracy: 0.9269583  val_acc: 0.95025
48000/48000 - 66s - loss: 0.2389 - accuracy: 0.9270 - val_loss: 0.1749 - val_accuracy: 0.9503
Epoch 4/10
 -> id = 16  Epoch: 1   accuracy: 0.96552086  val_acc: 0.9715833
48000/48000 - 85s - loss: 0.1156 - accuracy: 0.9655 - val_loss: 0.0971 - val_accuracy: 0.9716
Epoch 3/10
 -> id = 12  Epoch: 1   accuracy: 0.94839585  val_acc: 0.9569167
48000/48000 - 84s - loss: 0.1716 - accuracy: 0.9484 - val_loss: 0.1429 - val_accuracy: 0.9569
Epoch 3/10
 -> id = 15  Epoch: 1   accuracy: 0.9238333  val_acc: 0.95383334
48000/48000 - 87s - loss: 0.2483 - accuracy: 0.9238 - val_loss: 0.1569 - val_accuracy: 0.9538
Epoch 3/10
 -> id = 20  Epoch: 2   accuracy: 0.96002084  val_acc: 0.96258336
48000/48000 - 87s - loss: 0.1372 - accuracy: 0.9600 - val_loss: 0.1336 - val_accuracy: 0.9626
Epoch 4/10
 -> id = 2  Epoch: 1   accuracy: 0.961  val_acc: 0.96533334
48000/48000 - 90s - loss: 0.1315 - accuracy: 0.9610 - val_loss: 0.1210 - val_accuracy: 0.9653
Epoch 3/10
 -> id = 5  Epoch: 1   accuracy: 0.9158958  val_acc: 0.9406667
48000/48000 - 89s - loss: 0.2845 - accuracy: 0.9159 - val_loss: 0.2136 - val_accuracy: 0.9407
Epoch 3/10
 -> id = 4  Epoch: 1   accuracy: 0.97008336  val_acc: 0.96433336
48000/48000 - 106s - loss: 0.1003 - accuracy: 0.9701 - val_loss: 0.1257 - val_accuracy: 0.9643
Epoch 3/10
 -> id = 14  Epoch: 1   accuracy: 0.96164584  val_acc: 0.96491665
48000/48000 - 103s - loss: 0.1269 - accuracy: 0.9616 - val_loss: 0.1265 - val_accuracy: 0.9649
Epoch 3/10
 -> id = 9  Epoch: 1   accuracy: 0.9490625  val_acc: 0.9619167
48000/48000 - 96s - loss: 0.1722 - accuracy: 0.9491 - val_loss: 0.1444 - val_accuracy: 0.9619
Epoch 3/10
 -> id = 11  Epoch: 1   accuracy: 0.8923542  val_acc: 0.94491667
48000/48000 - 106s - loss: 0.3536 - accuracy: 0.8924 - val_loss: 0.2031 - val_accuracy: 0.9449
Epoch 3/10
 -> id = 10  Epoch: 1   accuracy: 0.96220833  val_acc: 0.9565
48000/48000 - 109s - loss: 0.1264 - accuracy: 0.9622 - val_loss: 0.1550 - val_accuracy: 0.9565
Epoch 3/10
 -> id = 1  Epoch: 2   accuracy: 0.93897915  val_acc: 0.95566666
48000/48000 - 87s - loss: 0.2119 - accuracy: 0.9390 - val_loss: 0.1639 - val_accuracy: 0.9557
Epoch 4/10
 -> id = 7  Epoch: 3   accuracy: 0.9400833  val_acc: 0.9558333
48000/48000 - 74s - loss: 0.1969 - accuracy: 0.9401 - val_loss: 0.1479 - val_accuracy: 0.9558
Epoch 5/10
 -> id = 17  Epoch: 1   accuracy: 0.9156042  val_acc: 0.9454167
48000/48000 - 113s - loss: 0.2899 - accuracy: 0.9156 - val_loss: 0.1833 - val_accuracy: 0.9454
Epoch 3/10
 -> id = 6  Epoch: 1   accuracy: 0.92908335  val_acc: 0.9468333
48000/48000 - 127s - loss: 0.3416 - accuracy: 0.9291 - val_loss: 0.2430 - val_accuracy: 0.9468
Epoch 3/10
 -> id = 16  Epoch: 2   accuracy: 0.9735417  val_acc: 0.97258335
48000/48000 - 89s - loss: 0.0860 - accuracy: 0.9735 - val_loss: 0.0930 - val_accuracy: 0.9726
Epoch 4/10
 -> id = 18  Epoch: 1   accuracy: 0.927125  val_acc: 0.9543333
48000/48000 - 136s - loss: 0.2552 - accuracy: 0.9271 - val_loss: 0.1559 - val_accuracy: 0.9543
Epoch 3/10
 -> id = 8  Epoch: 1   accuracy: 0.87366664  val_acc: 0.9266667
48000/48000 - 122s - loss: 0.4131 - accuracy: 0.8737 - val_loss: 0.2578 - val_accuracy: 0.9267
Epoch 3/10
 -> id = 13  Epoch: 1   accuracy: 0.76195836  val_acc: 0.9095
48000/48000 - 118s - loss: 0.8920 - accuracy: 0.7620 - val_loss: 0.4377 - val_accuracy: 0.9095
Epoch 3/10
 -> id = 20  Epoch: 3   accuracy: 0.96933335  val_acc: 0.96708333
48000/48000 - 81s - loss: 0.1043 - accuracy: 0.9693 - val_loss: 0.1160 - val_accuracy: 0.9671
Epoch 5/10
 -> id = 12  Epoch: 2   accuracy: 0.96152085  val_acc: 0.96033335
48000/48000 - 90s - loss: 0.1248 - accuracy: 0.9615 - val_loss: 0.1481 - val_accuracy: 0.9603
Epoch 4/10
 -> id = 15  Epoch: 2   accuracy: 0.9375  val_acc: 0.9594167
48000/48000 - 88s - loss: 0.2037 - accuracy: 0.9375 - val_loss: 0.1333 - val_accuracy: 0.9594
Epoch 4/10
 -> id = 0  Epoch: 1   accuracy: 0.935  val_acc: 0.94941664
48000/48000 - 131s - loss: 0.2400 - accuracy: 0.9350 - val_loss: 0.1935 - val_accuracy: 0.9494
Epoch 3/10
 -> id = 2  Epoch: 2   accuracy: 0.9716667  val_acc: 0.96458334
48000/48000 - 90s - loss: 0.0956 - accuracy: 0.9717 - val_loss: 0.1176 - val_accuracy: 0.9646
Epoch 4/10
 -> id = 5  Epoch: 2   accuracy: 0.932125  val_acc: 0.9508333
48000/48000 - 89s - loss: 0.2305 - accuracy: 0.9321 - val_loss: 0.1822 - val_accuracy: 0.9508
Epoch 4/10
 -> id = 4  Epoch: 2   accuracy: 0.97954166  val_acc: 0.9688333
48000/48000 - 99s - loss: 0.0651 - accuracy: 0.9795 - val_loss: 0.1143 - val_accuracy: 0.9688
Epoch 4/10
 -> id = 3  Epoch: 1   accuracy: 0.9642083  val_acc: 0.96091664
48000/48000 - 141s - loss: 0.1227 - accuracy: 0.9642 - val_loss: 0.1473 - val_accuracy: 0.9609
Epoch 3/10
 -> id = 19  Epoch: 1   accuracy: 0.9479167  val_acc: 0.9600833
48000/48000 - 141s - loss: 0.1706 - accuracy: 0.9479 - val_loss: 0.1357 - val_accuracy: 0.9601
Epoch 3/10
 -> id = 7  Epoch: 4   accuracy: 0.94929165  val_acc: 0.96241665
48000/48000 - 65s - loss: 0.1674 - accuracy: 0.9493 - val_loss: 0.1289 - val_accuracy: 0.9624
Epoch 6/10
 -> id = 9  Epoch: 2   accuracy: 0.9645208  val_acc: 0.96033335
48000/48000 - 90s - loss: 0.1196 - accuracy: 0.9645 - val_loss: 0.1438 - val_accuracy: 0.9603
Epoch 4/10
 -> id = 14  Epoch: 2   accuracy: 0.97127086  val_acc: 0.97241664
48000/48000 - 107s - loss: 0.0933 - accuracy: 0.9713 - val_loss: 0.0993 - val_accuracy: 0.9724
Epoch 4/10
 -> id = 1  Epoch: 3   accuracy: 0.9507292  val_acc: 0.96258336
48000/48000 - 75s - loss: 0.1667 - accuracy: 0.9507 - val_loss: 0.1365 - val_accuracy: 0.9626
Epoch 5/10
 -> id = 11  Epoch: 2   accuracy: 0.92345834  val_acc: 0.95566666
48000/48000 - 105s - loss: 0.2520 - accuracy: 0.9235 - val_loss: 0.1563 - val_accuracy: 0.9557
Epoch 4/10
 -> id = 10  Epoch: 2   accuracy: 0.9707083  val_acc: 0.96325
48000/48000 - 108s - loss: 0.0958 - accuracy: 0.9707 - val_loss: 0.1447 - val_accuracy: 0.9632
Epoch 4/10
 -> id = 16  Epoch: 3   accuracy: 0.9776667  val_acc: 0.9766667
48000/48000 - 94s - loss: 0.0724 - accuracy: 0.9777 - val_loss: 0.0797 - val_accuracy: 0.9767
Epoch 5/10
 -> id = 12  Epoch: 3   accuracy: 0.9686667  val_acc: 0.97008336
48000/48000 - 88s - loss: 0.1011 - accuracy: 0.9687 - val_loss: 0.1011 - val_accuracy: 0.9701
Epoch 5/10
 -> id = 20  Epoch: 4   accuracy: 0.9761875  val_acc: 0.9688333
48000/48000 - 89s - loss: 0.0803 - accuracy: 0.9762 - val_loss: 0.1052 - val_accuracy: 0.9688
Epoch 6/10
 -> id = 17  Epoch: 2   accuracy: 0.9306667  val_acc: 0.9545
48000/48000 - 111s - loss: 0.2371 - accuracy: 0.9307 - val_loss: 0.1558 - val_accuracy: 0.9545
Epoch 4/10
 -> id = 15  Epoch: 3   accuracy: 0.9428333  val_acc: 0.96241665
48000/48000 - 91s - loss: 0.1828 - accuracy: 0.9428 - val_loss: 0.1307 - val_accuracy: 0.9624
Epoch 5/10
 -> id = 7  Epoch: 5   accuracy: 0.95708334  val_acc: 0.96433336
48000/48000 - 74s - loss: 0.1429 - accuracy: 0.9571 - val_loss: 0.1191 - val_accuracy: 0.9643
Epoch 7/10
 -> id = 2  Epoch: 3   accuracy: 0.9775208  val_acc: 0.9698333
48000/48000 - 96s - loss: 0.0741 - accuracy: 0.9775 - val_loss: 0.1020 - val_accuracy: 0.9698
Epoch 5/10
 -> id = 5  Epoch: 3   accuracy: 0.93872917  val_acc: 0.9535
48000/48000 - 96s - loss: 0.2006 - accuracy: 0.9387 - val_loss: 0.1635 - val_accuracy: 0.9535
Epoch 5/10
 -> id = 6  Epoch: 2   accuracy: 0.93797916  val_acc: 0.955
48000/48000 - 124s - loss: 0.2575 - accuracy: 0.9380 - val_loss: 0.1932 - val_accuracy: 0.9550
Epoch 4/10
 -> id = 4  Epoch: 3   accuracy: 0.98354167  val_acc: 0.97291666
48000/48000 - 98s - loss: 0.0504 - accuracy: 0.9835 - val_loss: 0.0958 - val_accuracy: 0.9729
Epoch 5/10
 -> id = 13  Epoch: 2   accuracy: 0.77595836  val_acc: 0.9255
48000/48000 - 129s - loss: 0.8052 - accuracy: 0.7760 - val_loss: 0.3876 - val_accuracy: 0.9255
Epoch 4/10
 -> id = 18  Epoch: 2   accuracy: 0.9498125  val_acc: 0.96575
48000/48000 - 132s - loss: 0.1716 - accuracy: 0.9498 - val_loss: 0.1163 - val_accuracy: 0.9657
Epoch 4/10
 -> id = 8  Epoch: 2   accuracy: 0.90079165  val_acc: 0.94016665
48000/48000 - 131s - loss: 0.3231 - accuracy: 0.9008 - val_loss: 0.2046 - val_accuracy: 0.9402
Epoch 4/10
 -> id = 1  Epoch: 4   accuracy: 0.95991665  val_acc: 0.96533334
48000/48000 - 89s - loss: 0.1347 - accuracy: 0.9599 - val_loss: 0.1190 - val_accuracy: 0.9653
Epoch 6/10
 -> id = 9  Epoch: 3   accuracy: 0.973625  val_acc: 0.96541667
48000/48000 - 99s - loss: 0.0889 - accuracy: 0.9736 - val_loss: 0.1261 - val_accuracy: 0.9654
Epoch 5/10
 -> id = 14  Epoch: 3   accuracy: 0.97639585  val_acc: 0.97275
48000/48000 - 105s - loss: 0.0752 - accuracy: 0.9764 - val_loss: 0.1044 - val_accuracy: 0.9728
Epoch 5/10
 -> id = 0  Epoch: 2   accuracy: 0.9493542  val_acc: 0.96425
48000/48000 - 133s - loss: 0.1930 - accuracy: 0.9494 - val_loss: 0.1429 - val_accuracy: 0.9643
Epoch 4/10
 -> id = 11  Epoch: 3   accuracy: 0.9417292  val_acc: 0.9615833
48000/48000 - 106s - loss: 0.1942 - accuracy: 0.9417 - val_loss: 0.1350 - val_accuracy: 0.9616
Epoch 5/10
 -> id = 16  Epoch: 4   accuracy: 0.9800625  val_acc: 0.97908336
48000/48000 - 85s - loss: 0.0625 - accuracy: 0.9801 - val_loss: 0.0704 - val_accuracy: 0.9791
Epoch 6/10
 -> id = 3  Epoch: 2   accuracy: 0.972875  val_acc: 0.97333336
48000/48000 - 141s - loss: 0.0915 - accuracy: 0.9729 - val_loss: 0.0979 - val_accuracy: 0.9733
Epoch 4/10
 -> id = 7  Epoch: 6   accuracy: 0.960875  val_acc: 0.96683335
48000/48000 - 64s - loss: 0.1273 - accuracy: 0.9609 - val_loss: 0.1100 - val_accuracy: 0.9668
Epoch 8/10
 -> id = 12  Epoch: 4   accuracy: 0.9738542  val_acc: 0.96641666
48000/48000 - 83s - loss: 0.0836 - accuracy: 0.9739 - val_loss: 0.1214 - val_accuracy: 0.9664
Epoch 6/10
 -> id = 19  Epoch: 2   accuracy: 0.95977086  val_acc: 0.9605
48000/48000 - 142s - loss: 0.1341 - accuracy: 0.9598 - val_loss: 0.1271 - val_accuracy: 0.9605
Epoch 4/10
 -> id = 10  Epoch: 3   accuracy: 0.97539586  val_acc: 0.9611667
48000/48000 - 107s - loss: 0.0800 - accuracy: 0.9754 - val_loss: 0.1384 - val_accuracy: 0.9612
Epoch 5/10
 -> id = 20  Epoch: 5   accuracy: 0.98183334  val_acc: 0.9691667
48000/48000 - 86s - loss: 0.0626 - accuracy: 0.9818 - val_loss: 0.1066 - val_accuracy: 0.9692
Epoch 7/10
 -> id = 15  Epoch: 4   accuracy: 0.9495417  val_acc: 0.9665
48000/48000 - 81s - loss: 0.1641 - accuracy: 0.9495 - val_loss: 0.1142 - val_accuracy: 0.9665
Epoch 6/10
 -> id = 5  Epoch: 4   accuracy: 0.9465625  val_acc: 0.9521667
48000/48000 - 89s - loss: 0.1765 - accuracy: 0.9466 - val_loss: 0.1592 - val_accuracy: 0.9522
Epoch 6/10
 -> id = 2  Epoch: 4   accuracy: 0.98010415  val_acc: 0.96858335
48000/48000 - 92s - loss: 0.0639 - accuracy: 0.9801 - val_loss: 0.1012 - val_accuracy: 0.9686
Epoch 6/10
 -> id = 17  Epoch: 3   accuracy: 0.94320834  val_acc: 0.958
48000/48000 - 110s - loss: 0.1928 - accuracy: 0.9432 - val_loss: 0.1452 - val_accuracy: 0.9580
Epoch 5/10
 -> id = 1  Epoch: 5   accuracy: 0.9667708  val_acc: 0.96925
48000/48000 - 91s - loss: 0.1128 - accuracy: 0.9668 - val_loss: 0.1089 - val_accuracy: 0.9693
Epoch 7/10
 -> id = 4  Epoch: 4   accuracy: 0.98760414  val_acc: 0.97491664
48000/48000 - 106s - loss: 0.0373 - accuracy: 0.9876 - val_loss: 0.0980 - val_accuracy: 0.9749
Epoch 6/10
 -> id = 9  Epoch: 4   accuracy: 0.97845834  val_acc: 0.9698333
48000/48000 - 100s - loss: 0.0724 - accuracy: 0.9785 - val_loss: 0.1094 - val_accuracy: 0.9698
Epoch 6/10
 -> id = 6  Epoch: 3   accuracy: 0.94645834  val_acc: 0.964
48000/48000 - 126s - loss: 0.2122 - accuracy: 0.9465 - val_loss: 0.1531 - val_accuracy: 0.9640
Epoch 5/10
 -> id = 7  Epoch: 7   accuracy: 0.9648333  val_acc: 0.9694167
48000/48000 - 73s - loss: 0.1140 - accuracy: 0.9648 - val_loss: 0.1000 - val_accuracy: 0.9694
Epoch 9/10
 -> id = 14  Epoch: 4   accuracy: 0.98008335  val_acc: 0.9740833
48000/48000 - 104s - loss: 0.0635 - accuracy: 0.9801 - val_loss: 0.1022 - val_accuracy: 0.9741
Epoch 6/10
 -> id = 13  Epoch: 3   accuracy: 0.77697915  val_acc: 0.92966664
48000/48000 - 126s - loss: 0.7763 - accuracy: 0.7770 - val_loss: 0.3632 - val_accuracy: 0.9297
Epoch 5/10
 -> id = 16  Epoch: 5   accuracy: 0.98354167  val_acc: 0.9784167
48000/48000 - 84s - loss: 0.0531 - accuracy: 0.9835 - val_loss: 0.0751 - val_accuracy: 0.9784
Epoch 7/10
 -> id = 18  Epoch: 3   accuracy: 0.9605  val_acc: 0.9716667
48000/48000 - 129s - loss: 0.1344 - accuracy: 0.9605 - val_loss: 0.1020 - val_accuracy: 0.9717
Epoch 5/10
 -> id = 8  Epoch: 3   accuracy: 0.9167917  val_acc: 0.95066667
48000/48000 - 129s - loss: 0.2724 - accuracy: 0.9168 - val_loss: 0.1730 - val_accuracy: 0.9507
Epoch 5/10
 -> id = 12  Epoch: 5   accuracy: 0.9771875  val_acc: 0.9684167
48000/48000 - 84s - loss: 0.0741 - accuracy: 0.9772 - val_loss: 0.1163 - val_accuracy: 0.9684
Epoch 7/10
 -> id = 20  Epoch: 6   accuracy: 0.9848125  val_acc: 0.97125
48000/48000 - 88s - loss: 0.0515 - accuracy: 0.9848 - val_loss: 0.0944 - val_accuracy: 0.9712
Epoch 8/10
 -> id = 15  Epoch: 5   accuracy: 0.9527917  val_acc: 0.96416664
48000/48000 - 89s - loss: 0.1502 - accuracy: 0.9528 - val_loss: 0.1165 - val_accuracy: 0.9642
Epoch 7/10
 -> id = 11  Epoch: 4   accuracy: 0.95310414  val_acc: 0.96758336
48000/48000 - 105s - loss: 0.1563 - accuracy: 0.9531 - val_loss: 0.1165 - val_accuracy: 0.9676
Epoch 6/10
 -> id = 0  Epoch: 3   accuracy: 0.95770836  val_acc: 0.96125
48000/48000 - 130s - loss: 0.1591 - accuracy: 0.9577 - val_loss: 0.1812 - val_accuracy: 0.9613
Epoch 5/10
 -> id = 10  Epoch: 4   accuracy: 0.97804165  val_acc: 0.9611667
48000/48000 - 111s - loss: 0.0678 - accuracy: 0.9780 - val_loss: 0.1470 - val_accuracy: 0.9612
Epoch 6/10
 -> id = 5  Epoch: 5   accuracy: 0.95110416  val_acc: 0.9594167
48000/48000 - 93s - loss: 0.1576 - accuracy: 0.9511 - val_loss: 0.1408 - val_accuracy: 0.9594
Epoch 7/10
 -> id = 2  Epoch: 5   accuracy: 0.98289585  val_acc: 0.97208333
48000/48000 - 91s - loss: 0.0532 - accuracy: 0.9829 - val_loss: 0.0907 - val_accuracy: 0.9721
Epoch 7/10
 -> id = 1  Epoch: 6   accuracy: 0.9713333  val_acc: 0.971
48000/48000 - 84s - loss: 0.0945 - accuracy: 0.9713 - val_loss: 0.0990 - val_accuracy: 0.9710
Epoch 8/10
 -> id = 7  Epoch: 8   accuracy: 0.968  val_acc: 0.9711667
48000/48000 - 65s - loss: 0.1012 - accuracy: 0.9680 - val_loss: 0.0954 - val_accuracy: 0.9712
Epoch 10/10
 -> id = 3  Epoch: 3   accuracy: 0.97952086  val_acc: 0.9745
48000/48000 - 145s - loss: 0.0683 - accuracy: 0.9795 - val_loss: 0.0924 - val_accuracy: 0.9745
Epoch 5/10
 -> id = 19  Epoch: 3   accuracy: 0.96654165  val_acc: 0.96566665
48000/48000 - 144s - loss: 0.1094 - accuracy: 0.9665 - val_loss: 0.1170 - val_accuracy: 0.9657
Epoch 5/10
 -> id = 17  Epoch: 4   accuracy: 0.947625  val_acc: 0.96358335
48000/48000 - 115s - loss: 0.1724 - accuracy: 0.9476 - val_loss: 0.1285 - val_accuracy: 0.9636
Epoch 6/10
 -> id = 9  Epoch: 5   accuracy: 0.9825  val_acc: 0.969
48000/48000 - 97s - loss: 0.0605 - accuracy: 0.9825 - val_loss: 0.1199 - val_accuracy: 0.9690
Epoch 7/10
 -> id = 4  Epoch: 5   accuracy: 0.99072915  val_acc: 0.97366667
48000/48000 - 105s - loss: 0.0281 - accuracy: 0.9907 - val_loss: 0.1104 - val_accuracy: 0.9737
Epoch 7/10
 -> id = 16  Epoch: 6   accuracy: 0.98366666  val_acc: 0.9795
48000/48000 - 87s - loss: 0.0505 - accuracy: 0.9837 - val_loss: 0.0675 - val_accuracy: 0.9795
Epoch 8/10
 -> id = 12  Epoch: 6   accuracy: 0.979875  val_acc: 0.97066665
48000/48000 - 88s - loss: 0.0642 - accuracy: 0.9799 - val_loss: 0.1274 - val_accuracy: 0.9707
Epoch 8/10
 -> id = 20  Epoch: 7   accuracy: 0.98777086  val_acc: 0.9686667
48000/48000 - 87s - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.1032 - val_accuracy: 0.9687
Epoch 9/10
 -> id = 14  Epoch: 5   accuracy: 0.98310417  val_acc: 0.97616667
48000/48000 - 106s - loss: 0.0530 - accuracy: 0.9831 - val_loss: 0.0909 - val_accuracy: 0.9762
Epoch 7/10
 -> id = 15  Epoch: 6   accuracy: 0.9564375  val_acc: 0.9715
48000/48000 - 93s - loss: 0.1361 - accuracy: 0.9564 - val_loss: 0.0973 - val_accuracy: 0.9715
Epoch 8/10
 -> id = 6  Epoch: 4   accuracy: 0.951  val_acc: 0.96316665
48000/48000 - 123s - loss: 0.1916 - accuracy: 0.9510 - val_loss: 0.1578 - val_accuracy: 0.9632
Epoch 6/10
 -> id = 11  Epoch: 5   accuracy: 0.9611667  val_acc: 0.9705833
48000/48000 - 106s - loss: 0.1272 - accuracy: 0.9612 - val_loss: 0.1044 - val_accuracy: 0.9706
Epoch 7/10
 -> id = 13  Epoch: 4   accuracy: 0.7820625  val_acc: 0.9295833
48000/48000 - 126s - loss: 0.7362 - accuracy: 0.7821 - val_loss: 0.3554 - val_accuracy: 0.9296
Epoch 6/10
 -> id = 7  Epoch: 9   accuracy: 0.9714792  val_acc: 0.97358334
48000/48000 - 75s - loss: 0.0931 - accuracy: 0.9715 - val_loss: 0.0890 - val_accuracy: 0.9736
 -> id = 1  Epoch: 7   accuracy: 0.97541666  val_acc: 0.97391665
48000/48000 - 77s - loss: 0.0822 - accuracy: 0.9754 - val_loss: 0.0912 - val_accuracy: 0.9739
Epoch 9/10
 -> id = 5  Epoch: 6   accuracy: 0.955375  val_acc: 0.9634167
48000/48000 - 92s - loss: 0.1441 - accuracy: 0.9554 - val_loss: 0.1317 - val_accuracy: 0.9634
Epoch 8/10
 -> id = 18  Epoch: 4   accuracy: 0.96708333  val_acc: 0.97358334
48000/48000 - 132s - loss: 0.1095 - accuracy: 0.9671 - val_loss: 0.0948 - val_accuracy: 0.9736
Epoch 6/10
 -> id = 2  Epoch: 6   accuracy: 0.98539585  val_acc: 0.9735
48000/48000 - 95s - loss: 0.0467 - accuracy: 0.9854 - val_loss: 0.0869 - val_accuracy: 0.9735
Epoch 8/10
 -> id = 8  Epoch: 4   accuracy: 0.92683333  val_acc: 0.95416665
48000/48000 - 133s - loss: 0.2363 - accuracy: 0.9268 - val_loss: 0.1589 - val_accuracy: 0.9542
Epoch 6/10
 -> id = 10  Epoch: 5   accuracy: 0.9825417  val_acc: 0.9688333
48000/48000 - 103s - loss: 0.0569 - accuracy: 0.9825 - val_loss: 0.1257 - val_accuracy: 0.9688
Epoch 7/10
 -> id = 0  Epoch: 4   accuracy: 0.9634167  val_acc: 0.9640833
48000/48000 - 131s - loss: 0.1399 - accuracy: 0.9634 - val_loss: 0.1572 - val_accuracy: 0.9641
Epoch 6/10
 -> id = 16  Epoch: 7   accuracy: 0.98614585  val_acc: 0.97891665
48000/48000 - 84s - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0720 - val_accuracy: 0.9789
Epoch 9/10
 -> id = 9  Epoch: 6   accuracy: 0.9841667  val_acc: 0.97075
48000/48000 - 92s - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.1219 - val_accuracy: 0.9707
Epoch 8/10
 -> id = 4  Epoch: 6   accuracy: 0.9919583  val_acc: 0.9698333
48000/48000 - 99s - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.1294 - val_accuracy: 0.9698
Epoch 8/10
 -> id = 20  Epoch: 8   accuracy: 0.99189585  val_acc: 0.97533333
48000/48000 - 81s - loss: 0.0309 - accuracy: 0.9919 - val_loss: 0.0840 - val_accuracy: 0.9753
Epoch 10/10
 -> id = 12  Epoch: 7   accuracy: 0.9822292  val_acc: 0.9745
48000/48000 - 89s - loss: 0.0554 - accuracy: 0.9822 - val_loss: 0.0988 - val_accuracy: 0.9745
Epoch 9/10
 -> id = 17  Epoch: 5   accuracy: 0.9557292  val_acc: 0.966
48000/48000 - 114s - loss: 0.1469 - accuracy: 0.9557 - val_loss: 0.1179 - val_accuracy: 0.9660
Epoch 7/10
 -> id = 3  Epoch: 4   accuracy: 0.9835208  val_acc: 0.9748333
48000/48000 - 136s - loss: 0.0535 - accuracy: 0.9835 - val_loss: 0.0914 - val_accuracy: 0.9748
Epoch 6/10
 -> id = 15  Epoch: 7   accuracy: 0.9587708  val_acc: 0.9723333
48000/48000 - 92s - loss: 0.1305 - accuracy: 0.9588 - val_loss: 0.0963 - val_accuracy: 0.9723
Epoch 9/10
 -> id = 14  Epoch: 6   accuracy: 0.9844375  val_acc: 0.9719167
48000/48000 - 101s - loss: 0.0465 - accuracy: 0.9844 - val_loss: 0.1022 - val_accuracy: 0.9719
Epoch 8/10
 -> id = 19  Epoch: 4   accuracy: 0.971  val_acc: 0.96775
48000/48000 - 144s - loss: 0.0944 - accuracy: 0.9710 - val_loss: 0.1082 - val_accuracy: 0.9678
Epoch 6/10
 -> id = 1  Epoch: 8   accuracy: 0.9783958  val_acc: 0.9744167
48000/48000 - 87s - loss: 0.0699 - accuracy: 0.9784 - val_loss: 0.0881 - val_accuracy: 0.9744
Epoch 10/10
 -> id = 5  Epoch: 7   accuracy: 0.95947915  val_acc: 0.9633333
48000/48000 - 86s - loss: 0.1290 - accuracy: 0.9595 - val_loss: 0.1295 - val_accuracy: 0.9633
Epoch 9/10
 -> id = 11  Epoch: 6   accuracy: 0.96783334  val_acc: 0.9741667
48000/48000 - 100s - loss: 0.1050 - accuracy: 0.9678 - val_loss: 0.0982 - val_accuracy: 0.9742
Epoch 8/10
 -> id = 2  Epoch: 7   accuracy: 0.98564583  val_acc: 0.9740833
48000/48000 - 97s - loss: 0.0445 - accuracy: 0.9856 - val_loss: 0.0854 - val_accuracy: 0.9741
Epoch 9/10
 -> id = 6  Epoch: 5   accuracy: 0.9545208  val_acc: 0.96541667
48000/48000 - 126s - loss: 0.1760 - accuracy: 0.9545 - val_loss: 0.1399 - val_accuracy: 0.9654
Epoch 7/10
 -> id = 10  Epoch: 6   accuracy: 0.9840208  val_acc: 0.96675
48000/48000 - 111s - loss: 0.0489 - accuracy: 0.9840 - val_loss: 0.1352 - val_accuracy: 0.9668
Epoch 8/10
 -> id = 13  Epoch: 5   accuracy: 0.7814792  val_acc: 0.9295
48000/48000 - 127s - loss: 0.7222 - accuracy: 0.7815 - val_loss: 0.3482 - val_accuracy: 0.9295
Epoch 7/10
 -> id = 16  Epoch: 8   accuracy: 0.98595834  val_acc: 0.9795833
48000/48000 - 87s - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.0732 - val_accuracy: 0.9796
Epoch 10/10
 -> id = 9  Epoch: 7   accuracy: 0.98660415  val_acc: 0.97241664
48000/48000 - 91s - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.1197 - val_accuracy: 0.9724
Epoch 9/10
 -> id = 8  Epoch: 5   accuracy: 0.9344792  val_acc: 0.9573333
48000/48000 - 129s - loss: 0.2155 - accuracy: 0.9345 - val_loss: 0.1448 - val_accuracy: 0.9573
Epoch 7/10
 -> id = 18  Epoch: 5   accuracy: 0.971625  val_acc: 0.97641665
48000/48000 - 131s - loss: 0.0973 - accuracy: 0.9716 - val_loss: 0.0873 - val_accuracy: 0.9764
Epoch 7/10
 -> id = 20  Epoch: 9   accuracy: 0.9930417  val_acc: 0.97325
48000/48000 - 86s - loss: 0.0258 - accuracy: 0.9930 - val_loss: 0.0936 - val_accuracy: 0.9732
 -> id = 12  Epoch: 8   accuracy: 0.98272914  val_acc: 0.97141665
48000/48000 - 87s - loss: 0.0565 - accuracy: 0.9827 - val_loss: 0.1114 - val_accuracy: 0.9714
Epoch 10/10
 -> id = 4  Epoch: 7   accuracy: 0.99320835  val_acc: 0.9745
48000/48000 - 97s - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.1100 - val_accuracy: 0.9745
Epoch 9/10
 -> id = 0  Epoch: 5   accuracy: 0.9667708  val_acc: 0.959
48000/48000 - 129s - loss: 0.1325 - accuracy: 0.9668 - val_loss: 0.1859 - val_accuracy: 0.9590
Epoch 7/10
 -> id = 17  Epoch: 6   accuracy: 0.961375  val_acc: 0.96875
48000/48000 - 106s - loss: 0.1292 - accuracy: 0.9614 - val_loss: 0.1076 - val_accuracy: 0.9688
Epoch 8/10
 -> id = 15  Epoch: 8   accuracy: 0.9618125  val_acc: 0.9745
48000/48000 - 89s - loss: 0.1184 - accuracy: 0.9618 - val_loss: 0.0893 - val_accuracy: 0.9745
Epoch 10/10
 -> id = 1  Epoch: 9   accuracy: 0.98129165  val_acc: 0.97475
48000/48000 - 77s - loss: 0.0620 - accuracy: 0.9813 - val_loss: 0.0854 - val_accuracy: 0.9747
 -> id = 5  Epoch: 8   accuracy: 0.9615625  val_acc: 0.96375
48000/48000 - 87s - loss: 0.1230 - accuracy: 0.9616 - val_loss: 0.1222 - val_accuracy: 0.9638
Epoch 10/10
 -> id = 14  Epoch: 7   accuracy: 0.98520833  val_acc: 0.97533333
48000/48000 - 106s - loss: 0.0466 - accuracy: 0.9852 - val_loss: 0.0945 - val_accuracy: 0.9753
Epoch 9/10
 -> id = 11  Epoch: 7   accuracy: 0.9715  val_acc: 0.96858335
48000/48000 - 97s - loss: 0.0912 - accuracy: 0.9715 - val_loss: 0.1089 - val_accuracy: 0.9686
Epoch 9/10
 -> id = 2  Epoch: 8   accuracy: 0.98716664  val_acc: 0.97475
48000/48000 - 91s - loss: 0.0386 - accuracy: 0.9872 - val_loss: 0.0830 - val_accuracy: 0.9747
Epoch 10/10
 -> id = 3  Epoch: 5   accuracy: 0.98714584  val_acc: 0.97491664
48000/48000 - 136s - loss: 0.0428 - accuracy: 0.9871 - val_loss: 0.1098 - val_accuracy: 0.9749
Epoch 7/10
 -> id = 16  Epoch: 9   accuracy: 0.9873125  val_acc: 0.98083335
48000/48000 - 88s - loss: 0.0388 - accuracy: 0.9873 - val_loss: 0.0646 - val_accuracy: 0.9808
 -> id = 10  Epoch: 7   accuracy: 0.9836875  val_acc: 0.9634167
48000/48000 - 99s - loss: 0.0493 - accuracy: 0.9837 - val_loss: 0.1574 - val_accuracy: 0.9634
Epoch 9/10
 -> id = 19  Epoch: 5   accuracy: 0.9740833  val_acc: 0.9715
48000/48000 - 139s - loss: 0.0811 - accuracy: 0.9741 - val_loss: 0.1013 - val_accuracy: 0.9715
Epoch 7/10
 -> id = 9  Epoch: 8   accuracy: 0.9876875  val_acc: 0.9716667
48000/48000 - 91s - loss: 0.0396 - accuracy: 0.9877 - val_loss: 0.1235 - val_accuracy: 0.9717
Epoch 10/10
 -> id = 12  Epoch: 9   accuracy: 0.9851875  val_acc: 0.97625
48000/48000 - 87s - loss: 0.0458 - accuracy: 0.9852 - val_loss: 0.0986 - val_accuracy: 0.9762
 -> id = 6  Epoch: 6   accuracy: 0.95545834  val_acc: 0.96141666
48000/48000 - 120s - loss: 0.1704 - accuracy: 0.9555 - val_loss: 0.1546 - val_accuracy: 0.9614
Epoch 8/10
 -> id = 15  Epoch: 9   accuracy: 0.9633125  val_acc: 0.9725
48000/48000 - 77s - loss: 0.1172 - accuracy: 0.9633 - val_loss: 0.0882 - val_accuracy: 0.9725
 -> id = 13  Epoch: 6   accuracy: 0.78520834  val_acc: 0.936
48000/48000 - 118s - loss: 0.7031 - accuracy: 0.7852 - val_loss: 0.3230 - val_accuracy: 0.9360
Epoch 8/10
 -> id = 4  Epoch: 8   accuracy: 0.99385417  val_acc: 0.97225
48000/48000 - 93s - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.1290 - val_accuracy: 0.9722
Epoch 10/10
 -> id = 5  Epoch: 9   accuracy: 0.96445835  val_acc: 0.9659167
48000/48000 - 76s - loss: 0.1115 - accuracy: 0.9645 - val_loss: 0.1180 - val_accuracy: 0.9659
 -> id = 17  Epoch: 7   accuracy: 0.9645417  val_acc: 0.9698333
48000/48000 - 97s - loss: 0.1176 - accuracy: 0.9645 - val_loss: 0.1058 - val_accuracy: 0.9698
Epoch 9/10
 -> id = 8  Epoch: 6   accuracy: 0.94122916  val_acc: 0.96133333
48000/48000 - 122s - loss: 0.1952 - accuracy: 0.9412 - val_loss: 0.1311 - val_accuracy: 0.9613
Epoch 8/10
 -> id = 18  Epoch: 6   accuracy: 0.9738125  val_acc: 0.9748333
48000/48000 - 128s - loss: 0.0872 - accuracy: 0.9738 - val_loss: 0.0892 - val_accuracy: 0.9748
Epoch 8/10
 -> id = 14  Epoch: 8   accuracy: 0.98791665  val_acc: 0.9748333
48000/48000 - 87s - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.0944 - val_accuracy: 0.9748
Epoch 10/10
 -> id = 2  Epoch: 9   accuracy: 0.9890417  val_acc: 0.9769167
48000/48000 - 78s - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.0813 - val_accuracy: 0.9769
 -> id = 11  Epoch: 8   accuracy: 0.9776458  val_acc: 0.97391665
48000/48000 - 85s - loss: 0.0714 - accuracy: 0.9776 - val_loss: 0.0901 - val_accuracy: 0.9739
Epoch 10/10
 -> id = 0  Epoch: 6   accuracy: 0.9696042  val_acc: 0.9659167
48000/48000 - 122s - loss: 0.1265 - accuracy: 0.9696 - val_loss: 0.1549 - val_accuracy: 0.9659
Epoch 8/10
 -> id = 9  Epoch: 9   accuracy: 0.9902292  val_acc: 0.97025
48000/48000 - 76s - loss: 0.0321 - accuracy: 0.9902 - val_loss: 0.1259 - val_accuracy: 0.9703
 -> id = 10  Epoch: 8   accuracy: 0.9845625  val_acc: 0.9695
48000/48000 - 87s - loss: 0.0478 - accuracy: 0.9846 - val_loss: 0.1312 - val_accuracy: 0.9695
Epoch 10/10
 -> id = 4  Epoch: 9   accuracy: 0.9927083  val_acc: 0.9723333
48000/48000 - 79s - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.1219 - val_accuracy: 0.9723
 -> id = 3  Epoch: 6   accuracy: 0.98791665  val_acc: 0.97325
48000/48000 - 123s - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.1218 - val_accuracy: 0.9732
Epoch 8/10
 -> id = 6  Epoch: 7   accuracy: 0.9592083  val_acc: 0.96275
48000/48000 - 102s - loss: 0.1623 - accuracy: 0.9592 - val_loss: 0.1471 - val_accuracy: 0.9628
Epoch 9/10
 -> id = 19  Epoch: 6   accuracy: 0.97729164  val_acc: 0.9759167
48000/48000 - 117s - loss: 0.0705 - accuracy: 0.9773 - val_loss: 0.0868 - val_accuracy: 0.9759
Epoch 8/10
 -> id = 17  Epoch: 8   accuracy: 0.9684167  val_acc: 0.973
48000/48000 - 84s - loss: 0.1045 - accuracy: 0.9684 - val_loss: 0.0957 - val_accuracy: 0.9730
Epoch 10/10
 -> id = 13  Epoch: 7   accuracy: 0.7904583  val_acc: 0.92975
48000/48000 - 101s - loss: 0.6829 - accuracy: 0.7905 - val_loss: 0.3357 - val_accuracy: 0.9298
Epoch 9/10
 -> id = 14  Epoch: 9   accuracy: 0.98760414  val_acc: 0.9745
48000/48000 - 79s - loss: 0.0379 - accuracy: 0.9876 - val_loss: 0.1040 - val_accuracy: 0.9745
 -> id = 11  Epoch: 9   accuracy: 0.98020834  val_acc: 0.9755833
48000/48000 - 74s - loss: 0.0636 - accuracy: 0.9802 - val_loss: 0.0921 - val_accuracy: 0.9756
 -> id = 8  Epoch: 7   accuracy: 0.94529164  val_acc: 0.9629167
48000/48000 - 103s - loss: 0.1794 - accuracy: 0.9453 - val_loss: 0.1288 - val_accuracy: 0.9629
Epoch 9/10
 -> id = 10  Epoch: 9   accuracy: 0.98770833  val_acc: 0.9605
48000/48000 - 68s - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.1639 - val_accuracy: 0.9605
 -> id = 0  Epoch: 7   accuracy: 0.970875  val_acc: 0.9690833
48000/48000 - 99s - loss: 0.1192 - accuracy: 0.9709 - val_loss: 0.1528 - val_accuracy: 0.9691
Epoch 9/10
 -> id = 18  Epoch: 7   accuracy: 0.9754375  val_acc: 0.976
48000/48000 - 114s - loss: 0.0808 - accuracy: 0.9754 - val_loss: 0.0891 - val_accuracy: 0.9760
Epoch 9/10
 -> id = 17  Epoch: 9   accuracy: 0.9704375  val_acc: 0.9738333
48000/48000 - 62s - loss: 0.0967 - accuracy: 0.9704 - val_loss: 0.0956 - val_accuracy: 0.9738
 -> id = 6  Epoch: 8   accuracy: 0.96064585  val_acc: 0.96708333
48000/48000 - 77s - loss: 0.1553 - accuracy: 0.9606 - val_loss: 0.1399 - val_accuracy: 0.9671
Epoch 10/10
 -> id = 13  Epoch: 8   accuracy: 0.79125  val_acc: 0.9295
48000/48000 - 76s - loss: 0.6707 - accuracy: 0.7912 - val_loss: 0.3217 - val_accuracy: 0.9295
Epoch 10/10
 -> id = 3  Epoch: 7   accuracy: 0.9897917  val_acc: 0.9745
48000/48000 - 92s - loss: 0.0346 - accuracy: 0.9898 - val_loss: 0.1101 - val_accuracy: 0.9745
Epoch 9/10
 -> id = 19  Epoch: 7   accuracy: 0.9800208  val_acc: 0.97575
48000/48000 - 94s - loss: 0.0630 - accuracy: 0.9800 - val_loss: 0.0842 - val_accuracy: 0.9758
Epoch 9/10
 -> id = 8  Epoch: 8   accuracy: 0.94864583  val_acc: 0.96641666
48000/48000 - 76s - loss: 0.1665 - accuracy: 0.9486 - val_loss: 0.1188 - val_accuracy: 0.9664
Epoch 10/10
 -> id = 0  Epoch: 8   accuracy: 0.9735417  val_acc: 0.967
48000/48000 - 79s - loss: 0.1099 - accuracy: 0.9735 - val_loss: 0.1623 - val_accuracy: 0.9670
Epoch 10/10
 -> id = 6  Epoch: 9   accuracy: 0.96075  val_acc: 0.967
48000/48000 - 65s - loss: 0.1494 - accuracy: 0.9607 - val_loss: 0.1346 - val_accuracy: 0.9670
 -> id = 18  Epoch: 8   accuracy: 0.978  val_acc: 0.97816664
48000/48000 - 95s - loss: 0.0720 - accuracy: 0.9780 - val_loss: 0.0892 - val_accuracy: 0.9782
Epoch 10/10
 -> id = 13  Epoch: 9   accuracy: 0.79072917  val_acc: 0.9381667
48000/48000 - 68s - loss: 0.6700 - accuracy: 0.7907 - val_loss: 0.2984 - val_accuracy: 0.9382
 -> id = 3  Epoch: 8   accuracy: 0.99027085  val_acc: 0.9730833
48000/48000 - 76s - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.1275 - val_accuracy: 0.9731
Epoch 10/10
 -> id = 8  Epoch: 9   accuracy: 0.95035416  val_acc: 0.96533334
48000/48000 - 63s - loss: 0.1595 - accuracy: 0.9504 - val_loss: 0.1137 - val_accuracy: 0.9653
 -> id = 19  Epoch: 8   accuracy: 0.98279166  val_acc: 0.97675
48000/48000 - 75s - loss: 0.0549 - accuracy: 0.9828 - val_loss: 0.0798 - val_accuracy: 0.9768
Epoch 10/10
 -> id = 0  Epoch: 9   accuracy: 0.9757083  val_acc: 0.96741664
48000/48000 - 59s - loss: 0.1037 - accuracy: 0.9757 - val_loss: 0.1626 - val_accuracy: 0.9674
 -> id = 18  Epoch: 9   accuracy: 0.9794792  val_acc: 0.9774167
48000/48000 - 61s - loss: 0.0669 - accuracy: 0.9795 - val_loss: 0.0843 - val_accuracy: 0.9774
 -> id = 3  Epoch: 9   accuracy: 0.9907708  val_acc: 0.97475
48000/48000 - 42s - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.1127 - val_accuracy: 0.9747
 -> id = 19  Epoch: 9   accuracy: 0.98508334  val_acc: 0.9730833
48000/48000 - 35s - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.0974 - val_accuracy: 0.9731
 id = 16  val_accuracy = 0.9808333516120911
 id = 18  val_accuracy = 0.9774166941642761
 id = 2  val_accuracy = 0.9769166707992554
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  1   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Model: "model_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_80 (Dense)             (None, 910)               714350
_________________________________________________________________
activation_59 (Activation)   (None, 910)               0
_________________________________________________________________
dropout_33 (Dropout)         (None, 910)               0
_________________________________________________________________
batch_normalization_31 (Batc (None, 910)               3640
_________________________________________________________________
dense_81 (Dense)             (None, 10)                9110
=================================================================
Total params: 727,100
Trainable params: 725,280
Non-trainable params: 1,820
_________________________________________________________________
None
Model: "model_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_82 (Dense)             (None, 460)               361100
_________________________________________________________________
activation_60 (Activation)   (None, 460)               0
_________________________________________________________________
dropout_34 (Dropout)         (None, 460)               0
_________________________________________________________________
dense_83 (Dense)             (None, 1890)              871290
_________________________________________________________________
activation_61 (Activation)   (None, 1890)              0
_________________________________________________________________
dropout_35 (Dropout)         (None, 1890)              0
_________________________________________________________________
dense_84 (Dense)             (None, 1720)              3252520
_________________________________________________________________
activation_62 (Activation)   (None, 1720)              0
_________________________________________________________________
dense_85 (Dense)             (None, 1580)              2719180
_________________________________________________________________
activation_63 (Activation)   (None, 1580)              0
_________________________________________________________________
dense_86 (Dense)             (None, 10)                15810
=================================================================
Total params: 7,219,900
Trainable params: 7,219,900
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_87 (Dense)             (None, 620)               486700
_________________________________________________________________
activation_64 (Activation)   (None, 620)               0
_________________________________________________________________
batch_normalization_32 (Batc (None, 620)               2480
_________________________________________________________________
dense_88 (Dense)             (None, 430)               267030
_________________________________________________________________
activation_65 (Activation)   (None, 430)               0
_________________________________________________________________
dropout_36 (Dropout)         (None, 430)               0
_________________________________________________________________
batch_normalization_33 (Batc (None, 430)               1720
_________________________________________________________________
dense_89 (Dense)             (None, 10)                4310
=================================================================
Total params: 762,240
Trainable params: 760,140
Non-trainable params: 2,100
_________________________________________________________________
None
Model: "model_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_90 (Dense)             (None, 1108)              869780
_________________________________________________________________
activation_66 (Activation)   (None, 1108)              0
_________________________________________________________________
dropout_37 (Dropout)         (None, 1108)              0
_________________________________________________________________
batch_normalization_34 (Batc (None, 1108)              4432
_________________________________________________________________
dense_91 (Dense)             (None, 10)                11090
=================================================================
Total params: 885,302
Trainable params: 883,086
Non-trainable params: 2,216
_________________________________________________________________
None
Model: "model_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_92 (Dense)             (None, 675)               529875
_________________________________________________________________
activation_67 (Activation)   (None, 675)               0
_________________________________________________________________
dropout_38 (Dropout)         (None, 675)               0
_________________________________________________________________
dense_93 (Dense)             (None, 2774)              1875224
_________________________________________________________________
activation_68 (Activation)   (None, 2774)              0
_________________________________________________________________
dropout_39 (Dropout)         (None, 2774)              0
_________________________________________________________________
dense_94 (Dense)             (None, 915)               2539125
_________________________________________________________________
activation_69 (Activation)   (None, 915)               0
_________________________________________________________________
dense_95 (Dense)             (None, 2319)              2124204
_________________________________________________________________
activation_70 (Activation)   (None, 2319)              0
_________________________________________________________________
dense_96 (Dense)             (None, 10)                23200
=================================================================
Total params: 7,091,628
Trainable params: 7,091,628
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_97 (Dense)             (None, 1890)              1483650
_________________________________________________________________
activation_71 (Activation)   (None, 1890)              0
_________________________________________________________________
batch_normalization_35 (Batc (None, 1890)              7560
_________________________________________________________________
dense_98 (Dense)             (None, 840)               1588440
_________________________________________________________________
activation_72 (Activation)   (None, 840)               0
_________________________________________________________________
dropout_40 (Dropout)         (None, 840)               0
_________________________________________________________________
dense_99 (Dense)             (None, 1890)              1589490
_________________________________________________________________
activation_73 (Activation)   (None, 1890)              0
_________________________________________________________________
dense_100 (Dense)            (None, 780)               1474980
_________________________________________________________________
activation_74 (Activation)   (None, 780)               0
_________________________________________________________________
batch_normalization_36 (Batc (None, 780)               3120
_________________________________________________________________
dense_101 (Dense)            (None, 10)                7810
=================================================================
Total params: 6,155,050
Trainable params: 6,149,710
Non-trainable params: 5,340
_________________________________________________________________
None
Model: "model_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_102 (Dense)            (None, 1960)              1538600
_________________________________________________________________
activation_75 (Activation)   (None, 1960)              0
_________________________________________________________________
batch_normalization_37 (Batc (None, 1960)              7840
_________________________________________________________________
dense_103 (Dense)            (None, 1440)              2823840
_________________________________________________________________
activation_76 (Activation)   (None, 1440)              0
_________________________________________________________________
dropout_41 (Dropout)         (None, 1440)              0
_________________________________________________________________
dense_104 (Dense)            (None, 590)               850190
_________________________________________________________________
activation_77 (Activation)   (None, 590)               0
_________________________________________________________________
dropout_42 (Dropout)         (None, 590)               0
_________________________________________________________________
dense_105 (Dense)            (None, 10)                5910
=================================================================
Total params: 5,226,380
Trainable params: 5,222,460
Non-trainable params: 3,920
_________________________________________________________________
None
Model: "model_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_106 (Dense)            (None, 90)                70650
_________________________________________________________________
activation_78 (Activation)   (None, 90)                0
_________________________________________________________________
batch_normalization_38 (Batc (None, 90)                360
_________________________________________________________________
dense_107 (Dense)            (None, 1730)              157430
_________________________________________________________________
activation_79 (Activation)   (None, 1730)              0
_________________________________________________________________
dense_108 (Dense)            (None, 1150)              1990650
_________________________________________________________________
activation_80 (Activation)   (None, 1150)              0
_________________________________________________________________
dropout_43 (Dropout)         (None, 1150)              0
_________________________________________________________________
dense_109 (Dense)            (None, 900)               1035900
_________________________________________________________________
activation_81 (Activation)   (None, 900)               0
_________________________________________________________________
dropout_44 (Dropout)         (None, 900)               0
_________________________________________________________________
batch_normalization_39 (Batc (None, 900)               3600
_________________________________________________________________
dense_110 (Dense)            (None, 10)                9010
=================================================================
Total params: 3,267,600
Trainable params: 3,265,620
Non-trainable params: 1,980
_________________________________________________________________
None
Model: "model_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_111 (Dense)            (None, 1470)              1153950
_________________________________________________________________
activation_82 (Activation)   (None, 1470)              0
_________________________________________________________________
batch_normalization_40 (Batc (None, 1470)              5880
_________________________________________________________________
dense_112 (Dense)            (None, 1190)              1750490
_________________________________________________________________
activation_83 (Activation)   (None, 1190)              0
_________________________________________________________________
dropout_45 (Dropout)         (None, 1190)              0
_________________________________________________________________
batch_normalization_41 (Batc (None, 1190)              4760
_________________________________________________________________
dense_113 (Dense)            (None, 80)                95280
_________________________________________________________________
activation_84 (Activation)   (None, 80)                0
_________________________________________________________________
dropout_46 (Dropout)         (None, 80)                0
_________________________________________________________________
batch_normalization_42 (Batc (None, 80)                320
_________________________________________________________________
dense_114 (Dense)            (None, 160)               12960
_________________________________________________________________
activation_85 (Activation)   (None, 160)               0
_________________________________________________________________
dropout_47 (Dropout)         (None, 160)               0
_________________________________________________________________
batch_normalization_43 (Batc (None, 160)               640
_________________________________________________________________
dense_115 (Dense)            (None, 10)                1610
=================================================================
Total params: 3,025,890
Trainable params: 3,020,090
Non-trainable params: 5,800
_________________________________________________________________
None
Model: "model_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_116 (Dense)            (None, 1490)              1169650
_________________________________________________________________
activation_86 (Activation)   (None, 1490)              0
_________________________________________________________________
batch_normalization_44 (Batc (None, 1490)              5960
_________________________________________________________________
dense_117 (Dense)            (None, 10)                14910
=================================================================
Total params: 1,190,520
Trainable params: 1,187,540
Non-trainable params: 2,980
_________________________________________________________________
None
Model: "model_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_118 (Dense)            (None, 1540)              1208900
_________________________________________________________________
activation_87 (Activation)   (None, 1540)              0
_________________________________________________________________
dropout_48 (Dropout)         (None, 1540)              0
_________________________________________________________________
dense_119 (Dense)            (None, 540)               832140
_________________________________________________________________
activation_88 (Activation)   (None, 540)               0
_________________________________________________________________
batch_normalization_45 (Batc (None, 540)               2160
_________________________________________________________________
dense_120 (Dense)            (None, 560)               302960
_________________________________________________________________
activation_89 (Activation)   (None, 560)               0
_________________________________________________________________
dense_121 (Dense)            (None, 410)               230010
_________________________________________________________________
activation_90 (Activation)   (None, 410)               0
_________________________________________________________________
dense_122 (Dense)            (None, 10)                4110
=================================================================
Total params: 2,580,280
Trainable params: 2,579,200
Non-trainable params: 1,080
_________________________________________________________________
None
Model: "model_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_123 (Dense)            (None, 230)               180550
_________________________________________________________________
activation_91 (Activation)   (None, 230)               0
_________________________________________________________________
batch_normalization_46 (Batc (None, 230)               920
_________________________________________________________________
dense_124 (Dense)            (None, 470)               108570
_________________________________________________________________
activation_92 (Activation)   (None, 470)               0
_________________________________________________________________
batch_normalization_47 (Batc (None, 470)               1880
_________________________________________________________________
dense_125 (Dense)            (None, 1830)              861930
_________________________________________________________________
activation_93 (Activation)   (None, 1830)              0
_________________________________________________________________
dropout_49 (Dropout)         (None, 1830)              0
_________________________________________________________________
batch_normalization_48 (Batc (None, 1830)              7320
_________________________________________________________________
dense_126 (Dense)            (None, 240)               439440
_________________________________________________________________
activation_94 (Activation)   (None, 240)               0
_________________________________________________________________
dropout_50 (Dropout)         (None, 240)               0
_________________________________________________________________
batch_normalization_49 (Batc (None, 240)               960
_________________________________________________________________
dense_127 (Dense)            (None, 10)                2410
=================================================================
Total params: 1,603,980
Trainable params: 1,598,440
Non-trainable params: 5,540
_________________________________________________________________
None
Model: "model_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_128 (Dense)            (None, 760)               596600
_________________________________________________________________
activation_95 (Activation)   (None, 760)               0
_________________________________________________________________
batch_normalization_50 (Batc (None, 760)               3040
_________________________________________________________________
dense_129 (Dense)            (None, 550)               418550
_________________________________________________________________
activation_96 (Activation)   (None, 550)               0
_________________________________________________________________
dropout_51 (Dropout)         (None, 550)               0
_________________________________________________________________
dense_130 (Dense)            (None, 10)                5510
=================================================================
Total params: 1,023,700
Trainable params: 1,022,180
Non-trainable params: 1,520
_________________________________________________________________
None
Model: "model_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_131 (Dense)            (None, 780)               612300
_________________________________________________________________
activation_97 (Activation)   (None, 780)               0
_________________________________________________________________
dense_132 (Dense)            (None, 1140)              890340
_________________________________________________________________
activation_98 (Activation)   (None, 1140)              0
_________________________________________________________________
dropout_52 (Dropout)         (None, 1140)              0
_________________________________________________________________
dense_133 (Dense)            (None, 290)               330890
_________________________________________________________________
activation_99 (Activation)   (None, 290)               0
_________________________________________________________________
dropout_53 (Dropout)         (None, 290)               0
_________________________________________________________________
batch_normalization_51 (Batc (None, 290)               1160
_________________________________________________________________
dense_134 (Dense)            (None, 10)                2910
=================================================================
Total params: 1,837,600
Trainable params: 1,837,020
Non-trainable params: 580
_________________________________________________________________
None
Model: "model_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_135 (Dense)            (None, 770)               604450
_________________________________________________________________
activation_100 (Activation)  (None, 770)               0
_________________________________________________________________
dropout_54 (Dropout)         (None, 770)               0
_________________________________________________________________
batch_normalization_52 (Batc (None, 770)               3080
_________________________________________________________________
dense_136 (Dense)            (None, 10)                7710
_________________________________________________________________
activation_101 (Activation)  (None, 10)                0
_________________________________________________________________
batch_normalization_53 (Batc (None, 10)                40
_________________________________________________________________
dense_137 (Dense)            (None, 280)               3080
_________________________________________________________________
activation_102 (Activation)  (None, 280)               0
_________________________________________________________________
dense_138 (Dense)            (None, 1050)              295050
_________________________________________________________________
activation_103 (Activation)  (None, 1050)              0
_________________________________________________________________
dense_139 (Dense)            (None, 10)                10510
=================================================================
Total params: 923,920
Trainable params: 922,360
Non-trainable params: 1,560
_________________________________________________________________
None
Model: "model_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_140 (Dense)            (None, 1890)              1483650
_________________________________________________________________
activation_104 (Activation)  (None, 1890)              0
_________________________________________________________________
dropout_55 (Dropout)         (None, 1890)              0
_________________________________________________________________
dense_141 (Dense)            (None, 330)               624030
_________________________________________________________________
activation_105 (Activation)  (None, 330)               0
_________________________________________________________________
batch_normalization_54 (Batc (None, 330)               1320
_________________________________________________________________
dense_142 (Dense)            (None, 1170)              387270
_________________________________________________________________
activation_106 (Activation)  (None, 1170)              0
_________________________________________________________________
dropout_56 (Dropout)         (None, 1170)              0
_________________________________________________________________
batch_normalization_55 (Batc (None, 1170)              4680
_________________________________________________________________
dense_143 (Dense)            (None, 1950)              2283450
_________________________________________________________________
activation_107 (Activation)  (None, 1950)              0
_________________________________________________________________
dropout_57 (Dropout)         (None, 1950)              0
_________________________________________________________________
dense_144 (Dense)            (None, 10)                19510
=================================================================
Total params: 4,803,910
Trainable params: 4,800,910
Non-trainable params: 3,000
_________________________________________________________________
None
Model: "model_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_145 (Dense)            (None, 1640)              1287400
_________________________________________________________________
activation_108 (Activation)  (None, 1640)              0
_________________________________________________________________
dense_146 (Dense)            (None, 1470)              2412270
_________________________________________________________________
activation_109 (Activation)  (None, 1470)              0
_________________________________________________________________
dense_147 (Dense)            (None, 1300)              1912300
_________________________________________________________________
activation_110 (Activation)  (None, 1300)              0
_________________________________________________________________
dropout_58 (Dropout)         (None, 1300)              0
_________________________________________________________________
dense_148 (Dense)            (None, 350)               455350
_________________________________________________________________
activation_111 (Activation)  (None, 350)               0
_________________________________________________________________
batch_normalization_56 (Batc (None, 350)               1400
_________________________________________________________________
dense_149 (Dense)            (None, 10)                3510
=================================================================
Total params: 6,072,230
Trainable params: 6,071,530
Non-trainable params: 700
_________________________________________________________________
None
Model: "model_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_150 (Dense)            (None, 760)               596600
_________________________________________________________________
activation_112 (Activation)  (None, 760)               0
_________________________________________________________________
dropout_59 (Dropout)         (None, 760)               0
_________________________________________________________________
batch_normalization_57 (Batc (None, 760)               3040
_________________________________________________________________
dense_151 (Dense)            (None, 1890)              1438290
_________________________________________________________________
activation_113 (Activation)  (None, 1890)              0
_________________________________________________________________
dense_152 (Dense)            (None, 230)               434930
_________________________________________________________________
activation_114 (Activation)  (None, 230)               0
_________________________________________________________________
dropout_60 (Dropout)         (None, 230)               0
_________________________________________________________________
batch_normalization_58 (Batc (None, 230)               920
_________________________________________________________________
dense_153 (Dense)            (None, 1640)              378840
_________________________________________________________________
activation_115 (Activation)  (None, 1640)              0
_________________________________________________________________
batch_normalization_59 (Batc (None, 1640)              6560
_________________________________________________________________
dense_154 (Dense)            (None, 10)                16410
=================================================================
Total params: 2,875,590
Trainable params: 2,870,330
Non-trainable params: 5,260
_________________________________________________________________
None
Model: "model_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_155 (Dense)            (None, 1430)              1122550
_________________________________________________________________
activation_116 (Activation)  (None, 1430)              0
_________________________________________________________________
batch_normalization_60 (Batc (None, 1430)              5720
_________________________________________________________________
dense_156 (Dense)            (None, 10)                14310
=================================================================
Total params: 1,142,580
Trainable params: 1,139,720
Non-trainable params: 2,860
_________________________________________________________________
None
Model: "model_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_157 (Dense)            (None, 440)               345400
_________________________________________________________________
activation_117 (Activation)  (None, 440)               0
_________________________________________________________________
dense_158 (Dense)            (None, 140)               61740
_________________________________________________________________
activation_118 (Activation)  (None, 140)               0
_________________________________________________________________
dropout_61 (Dropout)         (None, 140)               0
_________________________________________________________________
dense_159 (Dense)            (None, 1240)              174840
_________________________________________________________________
activation_119 (Activation)  (None, 1240)              0
_________________________________________________________________
dense_160 (Dense)            (None, 10)                12410
=================================================================
Total params: 594,390
Trainable params: 594,390
Non-trainable params: 0
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesEpoch 1/10Epoch 1/10


Epoch 1/10Train on 48000 samples, validate on 12000 samples

Epoch 1/10
Train on 48000 samples, validate on 12000 samplesTrain on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesTrain on 48000 samples, validate on 12000 samplesTrain on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesTrain on 48000 samples, validate on 12000 samples
Epoch 1/10


Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Epoch 1/10Train on 48000 samples, validate on 12000 samplesEpoch 1/10Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10




Train on 48000 samples, validate on 12000 samplesEpoch 1/10
Epoch 1/10
Epoch 1/10

Epoch 1/10

Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
 -> id = 19  Epoch: 0   accuracy: 0.90497917  val_acc: 0.96375
48000/48000 - 90s - loss: 0.3145 - accuracy: 0.9050 - val_loss: 0.1239 - val_accuracy: 0.9638
Epoch 2/10
 -> id = 0  Epoch: 0   accuracy: 0.9214583  val_acc: 0.96133333
48000/48000 - 110s - loss: 0.2597 - accuracy: 0.9215 - val_loss: 0.1478 - val_accuracy: 0.9613
Epoch 2/10
 -> id = 18  Epoch: 0   accuracy: 0.8903125  val_acc: 0.8998333
48000/48000 - 121s - loss: 0.4272 - accuracy: 0.8903 - val_loss: 0.3479 - val_accuracy: 0.8998
Epoch 2/10
 -> id = 3  Epoch: 0   accuracy: 0.92722917  val_acc: 0.9605
48000/48000 - 123s - loss: 0.2432 - accuracy: 0.9272 - val_loss: 0.1475 - val_accuracy: 0.9605
Epoch 2/10
 -> id = 9  Epoch: 0   accuracy: 0.87295836  val_acc: 0.92575
48000/48000 - 123s - loss: 0.5250 - accuracy: 0.8730 - val_loss: 1.2740 - val_accuracy: 0.9258
Epoch 2/10
 -> id = 12  Epoch: 0   accuracy: 0.9290208  val_acc: 0.95816666
48000/48000 - 125s - loss: 0.2378 - accuracy: 0.9290 - val_loss: 0.2882 - val_accuracy: 0.9582
Epoch 2/10
 -> id = 10  Epoch: 0   accuracy: 0.90920836  val_acc: 0.95341665
48000/48000 - 145s - loss: 0.2975 - accuracy: 0.9092 - val_loss: 0.1652 - val_accuracy: 0.9534
Epoch 2/10
 -> id = 13  Epoch: 0   accuracy: 0.9064375  val_acc: 0.9565
48000/48000 - 157s - loss: 0.3060 - accuracy: 0.9064 - val_loss: 0.1438 - val_accuracy: 0.9565
Epoch 2/10
 -> id = 2  Epoch: 0   accuracy: 0.91704166  val_acc: 0.94575
48000/48000 - 164s - loss: 0.2822 - accuracy: 0.9170 - val_loss: 0.2141 - val_accuracy: 0.9457
Epoch 2/10
 -> id = 14  Epoch: 0   accuracy: 0.78704166  val_acc: 0.9205833
48000/48000 - 169s - loss: 0.6983 - accuracy: 0.7870 - val_loss: 0.2728 - val_accuracy: 0.9206
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.87470835  val_acc: 0.59008336
48000/48000 - 173s - loss: 0.3848 - accuracy: 0.8747 - val_loss: 1.1522 - val_accuracy: 0.5901
Epoch 2/10
 -> id = 8  Epoch: 0   accuracy: 0.82404166  val_acc: 0.6243333
48000/48000 - 174s - loss: 0.5905 - accuracy: 0.8240 - val_loss: 1.0691 - val_accuracy: 0.6243
Epoch 2/10
 -> id = 11  Epoch: 0   accuracy: 0.89125  val_acc: 0.41441667
48000/48000 - 175s - loss: 0.3641 - accuracy: 0.8913 - val_loss: 1.5847 - val_accuracy: 0.4144
Epoch 2/10
 -> id = 4  Epoch: 0   accuracy: 0.6125625  val_acc: 0.93008333
48000/48000 - 186s - loss: 1.0664 - accuracy: 0.6126 - val_loss: 0.2389 - val_accuracy: 0.9301
Epoch 2/10
 -> id = 7  Epoch: 0   accuracy: 0.7868958  val_acc: 0.89958334
48000/48000 - 190s - loss: 0.6961 - accuracy: 0.7869 - val_loss: 0.3482 - val_accuracy: 0.8996
Epoch 2/10
 -> id = 15  Epoch: 0   accuracy: 0.8218125  val_acc: 0.91533333
48000/48000 - 192s - loss: 0.5734 - accuracy: 0.8218 - val_loss: 0.2811 - val_accuracy: 0.9153
Epoch 2/10
 -> id = 1  Epoch: 0   accuracy: 0.673625  val_acc: 0.93666667
48000/48000 - 196s - loss: 0.9289 - accuracy: 0.6736 - val_loss: 0.2132 - val_accuracy: 0.9367
Epoch 2/10
 -> id = 17  Epoch: 0   accuracy: 0.89210415  val_acc: 0.9565833
48000/48000 - 199s - loss: 0.3962 - accuracy: 0.8921 - val_loss: 0.1616 - val_accuracy: 0.9566
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.9110417  val_acc: 0.94775
48000/48000 - 202s - loss: 0.3010 - accuracy: 0.9110 - val_loss: 0.1700 - val_accuracy: 0.9477
Epoch 2/10
 -> id = 0  Epoch: 1   accuracy: 0.96475  val_acc: 0.97275
48000/48000 - 104s - loss: 0.1171 - accuracy: 0.9647 - val_loss: 0.0904 - val_accuracy: 0.9728
Epoch 3/10
 -> id = 19  Epoch: 1   accuracy: 0.9630625  val_acc: 0.9698333
48000/48000 - 125s - loss: 0.1213 - accuracy: 0.9631 - val_loss: 0.1017 - val_accuracy: 0.9698
Epoch 3/10
 -> id = 12  Epoch: 1   accuracy: 0.96177083  val_acc: 0.96641666
48000/48000 - 104s - loss: 0.1271 - accuracy: 0.9618 - val_loss: 0.1137 - val_accuracy: 0.9664
Epoch 3/10
 -> id = 5  Epoch: 0   accuracy: 0.9009375  val_acc: 0.8164167
48000/48000 - 228s - loss: 0.3415 - accuracy: 0.9009 - val_loss: 1.2360 - val_accuracy: 0.8164
Epoch 2/10
 -> id = 9  Epoch: 1   accuracy: 0.9634375  val_acc: 0.96475
48000/48000 - 112s - loss: 0.1261 - accuracy: 0.9634 - val_loss: 0.1447 - val_accuracy: 0.9647
Epoch 3/10
 -> id = 3  Epoch: 1   accuracy: 0.96652085  val_acc: 0.9715
48000/48000 - 125s - loss: 0.1115 - accuracy: 0.9665 - val_loss: 0.0963 - val_accuracy: 0.9715
Epoch 3/10
 -> id = 18  Epoch: 1   accuracy: 0.93364584  val_acc: 0.9378333
48000/48000 - 129s - loss: 0.2285 - accuracy: 0.9336 - val_loss: 0.2251 - val_accuracy: 0.9378
Epoch 3/10
 -> id = 10  Epoch: 1   accuracy: 0.9537708  val_acc: 0.96108335
48000/48000 - 123s - loss: 0.1493 - accuracy: 0.9538 - val_loss: 0.1295 - val_accuracy: 0.9611
Epoch 3/10
 -> id = 13  Epoch: 1   accuracy: 0.9508333  val_acc: 0.96508336
48000/48000 - 134s - loss: 0.1627 - accuracy: 0.9508 - val_loss: 0.1145 - val_accuracy: 0.9651
Epoch 3/10
 -> id = 14  Epoch: 1   accuracy: 0.9159167  val_acc: 0.94741666
48000/48000 - 132s - loss: 0.2967 - accuracy: 0.9159 - val_loss: 0.1897 - val_accuracy: 0.9474
Epoch 3/10
 -> id = 2  Epoch: 1   accuracy: 0.9598542  val_acc: 0.9658333
48000/48000 - 140s - loss: 0.1327 - accuracy: 0.9599 - val_loss: 0.1232 - val_accuracy: 0.9658
Epoch 3/10
 -> id = 8  Epoch: 1   accuracy: 0.92645836  val_acc: 0.95625
48000/48000 - 137s - loss: 0.2594 - accuracy: 0.9265 - val_loss: 0.1446 - val_accuracy: 0.9563
Epoch 3/10
 -> id = 0  Epoch: 2   accuracy: 0.9732083  val_acc: 0.9755833
48000/48000 - 107s - loss: 0.0870 - accuracy: 0.9732 - val_loss: 0.0846 - val_accuracy: 0.9756
Epoch 4/10
 -> id = 6  Epoch: 1   accuracy: 0.96491665  val_acc: 0.9669167
48000/48000 - 150s - loss: 0.1197 - accuracy: 0.9649 - val_loss: 0.1131 - val_accuracy: 0.9669
Epoch 3/10
 -> id = 11  Epoch: 1   accuracy: 0.95520836  val_acc: 0.95958334
48000/48000 - 153s - loss: 0.1498 - accuracy: 0.9552 - val_loss: 0.1343 - val_accuracy: 0.9596
Epoch 3/10
 -> id = 19  Epoch: 2   accuracy: 0.97554165  val_acc: 0.974
48000/48000 - 125s - loss: 0.0825 - accuracy: 0.9755 - val_loss: 0.0914 - val_accuracy: 0.9740
Epoch 4/10
 -> id = 12  Epoch: 2   accuracy: 0.96935415  val_acc: 0.969
48000/48000 - 114s - loss: 0.0976 - accuracy: 0.9694 - val_loss: 0.1078 - val_accuracy: 0.9690
Epoch 4/10
 -> id = 15  Epoch: 1   accuracy: 0.921625  val_acc: 0.95316666
48000/48000 - 157s - loss: 0.2511 - accuracy: 0.9216 - val_loss: 0.1536 - val_accuracy: 0.9532
Epoch 3/10
 -> id = 7  Epoch: 1   accuracy: 0.90877086  val_acc: 0.93333334
48000/48000 - 167s - loss: 0.3044 - accuracy: 0.9088 - val_loss: 0.2212 - val_accuracy: 0.9333
Epoch 3/10
 -> id = 9  Epoch: 2   accuracy: 0.97610414  val_acc: 0.9688333
48000/48000 - 128s - loss: 0.0836 - accuracy: 0.9761 - val_loss: 0.1019 - val_accuracy: 0.9688
Epoch 4/10
 -> id = 4  Epoch: 1   accuracy: 0.92964584  val_acc: 0.96275
48000/48000 - 180s - loss: 0.2500 - accuracy: 0.9296 - val_loss: 0.1328 - val_accuracy: 0.9628
Epoch 3/10
 -> id = 17  Epoch: 1   accuracy: 0.94114584  val_acc: 0.9600833
48000/48000 - 168s - loss: 0.1980 - accuracy: 0.9411 - val_loss: 0.1475 - val_accuracy: 0.9601
Epoch 3/10
 -> id = 16  Epoch: 1   accuracy: 0.95477086  val_acc: 0.9590833
48000/48000 - 172s - loss: 0.1468 - accuracy: 0.9548 - val_loss: 0.1369 - val_accuracy: 0.9591
Epoch 3/10
 -> id = 3  Epoch: 2   accuracy: 0.9737292  val_acc: 0.97241664
48000/48000 - 127s - loss: 0.0847 - accuracy: 0.9737 - val_loss: 0.0920 - val_accuracy: 0.9724
Epoch 4/10
 -> id = 1  Epoch: 1   accuracy: 0.9308125  val_acc: 0.96108335
48000/48000 - 185s - loss: 0.2425 - accuracy: 0.9308 - val_loss: 0.1368 - val_accuracy: 0.9611
Epoch 3/10
 -> id = 18  Epoch: 2   accuracy: 0.9515833  val_acc: 0.9579167
48000/48000 - 134s - loss: 0.1613 - accuracy: 0.9516 - val_loss: 0.1461 - val_accuracy: 0.9579
Epoch 4/10
 -> id = 10  Epoch: 2   accuracy: 0.96475  val_acc: 0.9684167
48000/48000 - 124s - loss: 0.1115 - accuracy: 0.9647 - val_loss: 0.1018 - val_accuracy: 0.9684
Epoch 4/10
 -> id = 0  Epoch: 3   accuracy: 0.9770625  val_acc: 0.97475
48000/48000 - 101s - loss: 0.0733 - accuracy: 0.9771 - val_loss: 0.0853 - val_accuracy: 0.9747
Epoch 5/10
 -> id = 2  Epoch: 2   accuracy: 0.9723542  val_acc: 0.9661667
48000/48000 - 127s - loss: 0.0945 - accuracy: 0.9724 - val_loss: 0.1091 - val_accuracy: 0.9662
Epoch 4/10
 -> id = 5  Epoch: 1   accuracy: 0.9386875  val_acc: 0.83816665
48000/48000 - 204s - loss: 0.2039 - accuracy: 0.9387 - val_loss: 0.5512 - val_accuracy: 0.8382
Epoch 3/10
 -> id = 14  Epoch: 2   accuracy: 0.93658334  val_acc: 0.95525
48000/48000 - 131s - loss: 0.2273 - accuracy: 0.9366 - val_loss: 0.1685 - val_accuracy: 0.9553
Epoch 4/10
 -> id = 13  Epoch: 2   accuracy: 0.9607292  val_acc: 0.96566665
48000/48000 - 144s - loss: 0.1271 - accuracy: 0.9607 - val_loss: 0.1127 - val_accuracy: 0.9657
Epoch 4/10
 -> id = 8  Epoch: 2   accuracy: 0.9462708  val_acc: 0.96383333
48000/48000 - 134s - loss: 0.1904 - accuracy: 0.9463 - val_loss: 0.1190 - val_accuracy: 0.9638
Epoch 4/10
 -> id = 12  Epoch: 3   accuracy: 0.9759167  val_acc: 0.97433335
48000/48000 - 110s - loss: 0.0780 - accuracy: 0.9759 - val_loss: 0.1018 - val_accuracy: 0.9743
Epoch 5/10
 -> id = 19  Epoch: 3   accuracy: 0.98054165  val_acc: 0.9769167
48000/48000 - 117s - loss: 0.0642 - accuracy: 0.9805 - val_loss: 0.0870 - val_accuracy: 0.9769
Epoch 5/10
 -> id = 6  Epoch: 2   accuracy: 0.9761458  val_acc: 0.97258335
48000/48000 - 147s - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0973 - val_accuracy: 0.9726
Epoch 4/10
 -> id = 11  Epoch: 2   accuracy: 0.9689375  val_acc: 0.97008336
48000/48000 - 144s - loss: 0.1039 - accuracy: 0.9689 - val_loss: 0.1063 - val_accuracy: 0.9701
Epoch 4/10
 -> id = 9  Epoch: 3   accuracy: 0.9825625  val_acc: 0.9730833
48000/48000 - 127s - loss: 0.0608 - accuracy: 0.9826 - val_loss: 0.0907 - val_accuracy: 0.9731
Epoch 5/10
 -> id = 15  Epoch: 2   accuracy: 0.94029164  val_acc: 0.95575
48000/48000 - 158s - loss: 0.1950 - accuracy: 0.9403 - val_loss: 0.1486 - val_accuracy: 0.9557
Epoch 4/10
 -> id = 3  Epoch: 3   accuracy: 0.97902083  val_acc: 0.9773333
48000/48000 - 133s - loss: 0.0683 - accuracy: 0.9790 - val_loss: 0.0785 - val_accuracy: 0.9773
Epoch 5/10
 -> id = 18  Epoch: 3   accuracy: 0.962875  val_acc: 0.95591664
48000/48000 - 136s - loss: 0.1204 - accuracy: 0.9629 - val_loss: 0.1502 - val_accuracy: 0.9559
Epoch 5/10
 -> id = 10  Epoch: 3   accuracy: 0.973  val_acc: 0.97025
48000/48000 - 130s - loss: 0.0858 - accuracy: 0.9730 - val_loss: 0.0999 - val_accuracy: 0.9703
Epoch 5/10
 -> id = 0  Epoch: 4   accuracy: 0.98158336  val_acc: 0.97758335
48000/48000 - 102s - loss: 0.0608 - accuracy: 0.9816 - val_loss: 0.0788 - val_accuracy: 0.9776
Epoch 6/10
 -> id = 7  Epoch: 2   accuracy: 0.93170834  val_acc: 0.9446667
48000/48000 - 173s - loss: 0.2281 - accuracy: 0.9317 - val_loss: 0.1795 - val_accuracy: 0.9447
Epoch 4/10
 -> id = 17  Epoch: 2   accuracy: 0.95104164  val_acc: 0.964
48000/48000 - 164s - loss: 0.1602 - accuracy: 0.9510 - val_loss: 0.1310 - val_accuracy: 0.9640
Epoch 4/10
 -> id = 4  Epoch: 2   accuracy: 0.9532292  val_acc: 0.9605833
48000/48000 - 176s - loss: 0.1669 - accuracy: 0.9532 - val_loss: 0.1326 - val_accuracy: 0.9606
Epoch 4/10
 -> id = 2  Epoch: 3   accuracy: 0.9760208  val_acc: 0.96933335
48000/48000 - 121s - loss: 0.0777 - accuracy: 0.9760 - val_loss: 0.1003 - val_accuracy: 0.9693
Epoch 5/10
 -> id = 16  Epoch: 2   accuracy: 0.9649375  val_acc: 0.95916665
48000/48000 - 182s - loss: 0.1106 - accuracy: 0.9649 - val_loss: 0.1280 - val_accuracy: 0.9592
Epoch 4/10
 -> id = 12  Epoch: 4   accuracy: 0.9801667  val_acc: 0.96975
48000/48000 - 109s - loss: 0.0643 - accuracy: 0.9802 - val_loss: 0.1163 - val_accuracy: 0.9697
Epoch 6/10
 -> id = 14  Epoch: 3   accuracy: 0.94777083  val_acc: 0.9648333
48000/48000 - 130s - loss: 0.1842 - accuracy: 0.9478 - val_loss: 0.1257 - val_accuracy: 0.9648
Epoch 5/10
 -> id = 13  Epoch: 3   accuracy: 0.9669167  val_acc: 0.96791667
48000/48000 - 135s - loss: 0.1065 - accuracy: 0.9669 - val_loss: 0.0999 - val_accuracy: 0.9679
Epoch 5/10
 -> id = 1  Epoch: 2   accuracy: 0.95225  val_acc: 0.9676667
48000/48000 - 190s - loss: 0.1646 - accuracy: 0.9523 - val_loss: 0.1142 - val_accuracy: 0.9677
Epoch 4/10
 -> id = 19  Epoch: 4   accuracy: 0.9845625  val_acc: 0.97475
48000/48000 - 119s - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.0979 - val_accuracy: 0.9747
Epoch 6/10
 -> id = 8  Epoch: 3   accuracy: 0.95504165  val_acc: 0.96991664
48000/48000 - 132s - loss: 0.1577 - accuracy: 0.9550 - val_loss: 0.1000 - val_accuracy: 0.9699
Epoch 5/10
 -> id = 9  Epoch: 4   accuracy: 0.9873125  val_acc: 0.9741667
48000/48000 - 128s - loss: 0.0450 - accuracy: 0.9873 - val_loss: 0.0890 - val_accuracy: 0.9742
Epoch 6/10
 -> id = 6  Epoch: 3   accuracy: 0.9819792  val_acc: 0.9730833
48000/48000 - 151s - loss: 0.0578 - accuracy: 0.9820 - val_loss: 0.0978 - val_accuracy: 0.9731
Epoch 5/10
 -> id = 11  Epoch: 3   accuracy: 0.9746042  val_acc: 0.96783334
48000/48000 - 150s - loss: 0.0831 - accuracy: 0.9746 - val_loss: 0.1124 - val_accuracy: 0.9678
Epoch 5/10
 -> id = 0  Epoch: 5   accuracy: 0.98325  val_acc: 0.97625
48000/48000 - 101s - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.0771 - val_accuracy: 0.9762
Epoch 7/10
 -> id = 5  Epoch: 2   accuracy: 0.9508542  val_acc: 0.9324167
48000/48000 - 205s - loss: 0.1677 - accuracy: 0.9509 - val_loss: 0.2668 - val_accuracy: 0.9324
Epoch 4/10
 -> id = 3  Epoch: 4   accuracy: 0.98072916  val_acc: 0.9769167
48000/48000 - 131s - loss: 0.0603 - accuracy: 0.9807 - val_loss: 0.0804 - val_accuracy: 0.9769
Epoch 6/10
 -> id = 10  Epoch: 4   accuracy: 0.97672915  val_acc: 0.9680833
48000/48000 - 129s - loss: 0.0692 - accuracy: 0.9767 - val_loss: 0.1067 - val_accuracy: 0.9681
Epoch 6/10
 -> id = 18  Epoch: 4   accuracy: 0.971  val_acc: 0.96533334
48000/48000 - 135s - loss: 0.0923 - accuracy: 0.9710 - val_loss: 0.1165 - val_accuracy: 0.9653
Epoch 6/10
 -> id = 15  Epoch: 3   accuracy: 0.94775  val_acc: 0.96391666
48000/48000 - 164s - loss: 0.1667 - accuracy: 0.9477 - val_loss: 0.1228 - val_accuracy: 0.9639
Epoch 5/10
 -> id = 12  Epoch: 5   accuracy: 0.9821875  val_acc: 0.9695
48000/48000 - 122s - loss: 0.0579 - accuracy: 0.9822 - val_loss: 0.1153 - val_accuracy: 0.9695
Epoch 7/10
 -> id = 2  Epoch: 4   accuracy: 0.980875  val_acc: 0.971
48000/48000 - 133s - loss: 0.0626 - accuracy: 0.9809 - val_loss: 0.0960 - val_accuracy: 0.9710
Epoch 6/10
 -> id = 17  Epoch: 3   accuracy: 0.95889586  val_acc: 0.9669167
48000/48000 - 161s - loss: 0.1343 - accuracy: 0.9589 - val_loss: 0.1153 - val_accuracy: 0.9669
Epoch 5/10
 -> id = 7  Epoch: 3   accuracy: 0.94635415  val_acc: 0.9555
48000/48000 - 165s - loss: 0.1760 - accuracy: 0.9464 - val_loss: 0.1492 - val_accuracy: 0.9555
Epoch 5/10
 -> id = 19  Epoch: 5   accuracy: 0.9872083  val_acc: 0.97025
48000/48000 - 128s - loss: 0.0402 - accuracy: 0.9872 - val_loss: 0.1268 - val_accuracy: 0.9703
Epoch 7/10
 -> id = 14  Epoch: 4   accuracy: 0.9582292  val_acc: 0.967
48000/48000 - 142s - loss: 0.1517 - accuracy: 0.9582 - val_loss: 0.1142 - val_accuracy: 0.9670
Epoch 6/10
 -> id = 13  Epoch: 4   accuracy: 0.9726667  val_acc: 0.9738333
48000/48000 - 141s - loss: 0.0885 - accuracy: 0.9727 - val_loss: 0.0873 - val_accuracy: 0.9738
Epoch 6/10
 -> id = 8  Epoch: 4   accuracy: 0.96097916  val_acc: 0.97141665
48000/48000 - 142s - loss: 0.1345 - accuracy: 0.9610 - val_loss: 0.0992 - val_accuracy: 0.9714
Epoch 6/10
 -> id = 4  Epoch: 3   accuracy: 0.9626458  val_acc: 0.96925
48000/48000 - 182s - loss: 0.1274 - accuracy: 0.9626 - val_loss: 0.1114 - val_accuracy: 0.9693
Epoch 5/10
 -> id = 0  Epoch: 6   accuracy: 0.98466665  val_acc: 0.97866666
48000/48000 - 110s - loss: 0.0474 - accuracy: 0.9847 - val_loss: 0.0720 - val_accuracy: 0.9787
Epoch 8/10
 -> id = 16  Epoch: 3   accuracy: 0.9698333  val_acc: 0.96825
48000/48000 - 192s - loss: 0.0921 - accuracy: 0.9698 - val_loss: 0.1032 - val_accuracy: 0.9682
Epoch 5/10
 -> id = 9  Epoch: 5   accuracy: 0.99058336  val_acc: 0.97541666
48000/48000 - 137s - loss: 0.0341 - accuracy: 0.9906 - val_loss: 0.0889 - val_accuracy: 0.9754
Epoch 7/10
 -> id = 11  Epoch: 4   accuracy: 0.9801875  val_acc: 0.97041667
48000/48000 - 145s - loss: 0.0639 - accuracy: 0.9802 - val_loss: 0.1099 - val_accuracy: 0.9704
Epoch 6/10
 -> id = 6  Epoch: 4   accuracy: 0.9875625  val_acc: 0.97358334
48000/48000 - 147s - loss: 0.0411 - accuracy: 0.9876 - val_loss: 0.0997 - val_accuracy: 0.9736
Epoch 6/10
 -> id = 10  Epoch: 5   accuracy: 0.980375  val_acc: 0.9738333
48000/48000 - 120s - loss: 0.0593 - accuracy: 0.9804 - val_loss: 0.0929 - val_accuracy: 0.9738
Epoch 7/10
 -> id = 1  Epoch: 3   accuracy: 0.9620208  val_acc: 0.96933335
48000/48000 - 201s - loss: 0.1321 - accuracy: 0.9620 - val_loss: 0.1078 - val_accuracy: 0.9693
Epoch 5/10
 -> id = 3  Epoch: 5   accuracy: 0.98304164  val_acc: 0.9759167
48000/48000 - 141s - loss: 0.0531 - accuracy: 0.9830 - val_loss: 0.0798 - val_accuracy: 0.9759
Epoch 7/10
 -> id = 18  Epoch: 5   accuracy: 0.9774167  val_acc: 0.9663333
48000/48000 - 129s - loss: 0.0725 - accuracy: 0.9774 - val_loss: 0.1167 - val_accuracy: 0.9663
Epoch 7/10
 -> id = 12  Epoch: 6   accuracy: 0.9826667  val_acc: 0.97283334
48000/48000 - 109s - loss: 0.0527 - accuracy: 0.9827 - val_loss: 0.1064 - val_accuracy: 0.9728
Epoch 8/10
 -> id = 2  Epoch: 5   accuracy: 0.9828542  val_acc: 0.97491664
48000/48000 - 129s - loss: 0.0526 - accuracy: 0.9829 - val_loss: 0.0902 - val_accuracy: 0.9749
Epoch 7/10
 -> id = 19  Epoch: 6   accuracy: 0.9872083  val_acc: 0.97716665
48000/48000 - 126s - loss: 0.0399 - accuracy: 0.9872 - val_loss: 0.0889 - val_accuracy: 0.9772
Epoch 8/10
 -> id = 15  Epoch: 4   accuracy: 0.9557292  val_acc: 0.9686667
48000/48000 - 163s - loss: 0.1414 - accuracy: 0.9557 - val_loss: 0.1119 - val_accuracy: 0.9687
Epoch 6/10
 -> id = 14  Epoch: 5   accuracy: 0.9612917  val_acc: 0.96791667
48000/48000 - 134s - loss: 0.1354 - accuracy: 0.9613 - val_loss: 0.1172 - val_accuracy: 0.9679
Epoch 7/10
 -> id = 5  Epoch: 3   accuracy: 0.95872915  val_acc: 0.95875
48000/48000 - 204s - loss: 0.1434 - accuracy: 0.9587 - val_loss: 0.1449 - val_accuracy: 0.9588
Epoch 5/10
 -> id = 0  Epoch: 7   accuracy: 0.9857917  val_acc: 0.9785
48000/48000 - 107s - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.0747 - val_accuracy: 0.9785
Epoch 9/10
 -> id = 13  Epoch: 5   accuracy: 0.976125  val_acc: 0.97083336
48000/48000 - 144s - loss: 0.0759 - accuracy: 0.9761 - val_loss: 0.0954 - val_accuracy: 0.9708
Epoch 7/10
 -> id = 8  Epoch: 5   accuracy: 0.965125  val_acc: 0.97275
48000/48000 - 139s - loss: 0.1186 - accuracy: 0.9651 - val_loss: 0.0965 - val_accuracy: 0.9728
Epoch 7/10
 -> id = 17  Epoch: 4   accuracy: 0.96525  val_acc: 0.97083336
48000/48000 - 167s - loss: 0.1127 - accuracy: 0.9653 - val_loss: 0.1049 - val_accuracy: 0.9708
Epoch 6/10
 -> id = 7  Epoch: 4   accuracy: 0.9548542  val_acc: 0.9583333
48000/48000 - 172s - loss: 0.1458 - accuracy: 0.9549 - val_loss: 0.1408 - val_accuracy: 0.9583
Epoch 6/10
 -> id = 9  Epoch: 6   accuracy: 0.99266666  val_acc: 0.97466666
48000/48000 - 139s - loss: 0.0263 - accuracy: 0.9927 - val_loss: 0.0892 - val_accuracy: 0.9747
Epoch 8/10
 -> id = 12  Epoch: 7   accuracy: 0.9839583  val_acc: 0.9759167
48000/48000 - 107s - loss: 0.0475 - accuracy: 0.9840 - val_loss: 0.0907 - val_accuracy: 0.9759
Epoch 9/10
 -> id = 4  Epoch: 4   accuracy: 0.96714586  val_acc: 0.96975
48000/48000 - 183s - loss: 0.1121 - accuracy: 0.9671 - val_loss: 0.1126 - val_accuracy: 0.9697
Epoch 6/10
 -> id = 3  Epoch: 6   accuracy: 0.98441666  val_acc: 0.97825
48000/48000 - 129s - loss: 0.0470 - accuracy: 0.9844 - val_loss: 0.0762 - val_accuracy: 0.9783
Epoch 8/10
 -> id = 10  Epoch: 6   accuracy: 0.98320836  val_acc: 0.9748333
48000/48000 - 139s - loss: 0.0508 - accuracy: 0.9832 - val_loss: 0.0824 - val_accuracy: 0.9748
Epoch 8/10
 -> id = 6  Epoch: 5   accuracy: 0.99029166  val_acc: 0.97533333
48000/48000 - 148s - loss: 0.0317 - accuracy: 0.9903 - val_loss: 0.0976 - val_accuracy: 0.9753
Epoch 7/10
 -> id = 18  Epoch: 6   accuracy: 0.98039585  val_acc: 0.9684167
48000/48000 - 139s - loss: 0.0600 - accuracy: 0.9804 - val_loss: 0.1136 - val_accuracy: 0.9684
Epoch 8/10
 -> id = 16  Epoch: 4   accuracy: 0.97391665  val_acc: 0.97033334
48000/48000 - 178s - loss: 0.0805 - accuracy: 0.9739 - val_loss: 0.1040 - val_accuracy: 0.9703
Epoch 6/10
 -> id = 11  Epoch: 5   accuracy: 0.9840417  val_acc: 0.97466666
48000/48000 - 161s - loss: 0.0526 - accuracy: 0.9840 - val_loss: 0.1043 - val_accuracy: 0.9747
Epoch 7/10
 -> id = 2  Epoch: 6   accuracy: 0.9851458  val_acc: 0.9734167
48000/48000 - 130s - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.0924 - val_accuracy: 0.9734
Epoch 8/10
 -> id = 0  Epoch: 8   accuracy: 0.9875  val_acc: 0.9805
48000/48000 - 106s - loss: 0.0384 - accuracy: 0.9875 - val_loss: 0.0725 - val_accuracy: 0.9805
Epoch 10/10
 -> id = 19  Epoch: 7   accuracy: 0.9893542  val_acc: 0.97908336
48000/48000 - 126s - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.0915 - val_accuracy: 0.9791
Epoch 9/10
 -> id = 1  Epoch: 4   accuracy: 0.965375  val_acc: 0.9723333
48000/48000 - 202s - loss: 0.1190 - accuracy: 0.9654 - val_loss: 0.0939 - val_accuracy: 0.9723
Epoch 6/10
 -> id = 14  Epoch: 6   accuracy: 0.96416664  val_acc: 0.9701667
48000/48000 - 140s - loss: 0.1234 - accuracy: 0.9642 - val_loss: 0.1047 - val_accuracy: 0.9702
Epoch 8/10
 -> id = 15  Epoch: 5   accuracy: 0.9608542  val_acc: 0.9658333
48000/48000 - 166s - loss: 0.1249 - accuracy: 0.9609 - val_loss: 0.1157 - val_accuracy: 0.9658
Epoch 7/10
 -> id = 8  Epoch: 6   accuracy: 0.9683958  val_acc: 0.973
48000/48000 - 144s - loss: 0.1104 - accuracy: 0.9684 - val_loss: 0.0955 - val_accuracy: 0.9730
Epoch 8/10
 -> id = 13  Epoch: 6   accuracy: 0.9770833  val_acc: 0.97283334
48000/48000 - 149s - loss: 0.0711 - accuracy: 0.9771 - val_loss: 0.0880 - val_accuracy: 0.9728
Epoch 8/10
 -> id = 12  Epoch: 8   accuracy: 0.98629165  val_acc: 0.9751667
48000/48000 - 121s - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.0999 - val_accuracy: 0.9752
Epoch 10/10
 -> id = 17  Epoch: 5   accuracy: 0.968375  val_acc: 0.968
48000/48000 - 169s - loss: 0.1016 - accuracy: 0.9684 - val_loss: 0.1228 - val_accuracy: 0.9680
Epoch 7/10
 -> id = 9  Epoch: 7   accuracy: 0.9951875  val_acc: 0.97533333
48000/48000 - 135s - loss: 0.0196 - accuracy: 0.9952 - val_loss: 0.0937 - val_accuracy: 0.9753
Epoch 9/10
 -> id = 10  Epoch: 7   accuracy: 0.98554164  val_acc: 0.97566664
48000/48000 - 128s - loss: 0.0433 - accuracy: 0.9855 - val_loss: 0.0900 - val_accuracy: 0.9757
Epoch 9/10
 -> id = 7  Epoch: 5   accuracy: 0.96227086  val_acc: 0.96
48000/48000 - 173s - loss: 0.1262 - accuracy: 0.9623 - val_loss: 0.1362 - val_accuracy: 0.9600
Epoch 7/10
 -> id = 5  Epoch: 4   accuracy: 0.96329165  val_acc: 0.96741664
48000/48000 - 203s - loss: 0.1241 - accuracy: 0.9633 - val_loss: 0.1160 - val_accuracy: 0.9674
Epoch 6/10
 -> id = 3  Epoch: 7   accuracy: 0.9867917  val_acc: 0.97791666
48000/48000 - 135s - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.0768 - val_accuracy: 0.9779
Epoch 9/10
 -> id = 0  Epoch: 9   accuracy: 0.98791665  val_acc: 0.9803333
48000/48000 - 106s - loss: 0.0368 - accuracy: 0.9879 - val_loss: 0.0711 - val_accuracy: 0.9803
 -> id = 18  Epoch: 7   accuracy: 0.9840417  val_acc: 0.9691667
48000/48000 - 131s - loss: 0.0486 - accuracy: 0.9840 - val_loss: 0.1062 - val_accuracy: 0.9692
Epoch 9/10
 -> id = 6  Epoch: 6   accuracy: 0.9919583  val_acc: 0.97375
48000/48000 - 147s - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.1070 - val_accuracy: 0.9737
Epoch 8/10
 -> id = 2  Epoch: 7   accuracy: 0.9875625  val_acc: 0.9734167
48000/48000 - 128s - loss: 0.0391 - accuracy: 0.9876 - val_loss: 0.0854 - val_accuracy: 0.9734
Epoch 9/10
 -> id = 19  Epoch: 8   accuracy: 0.9906667  val_acc: 0.97875
48000/48000 - 127s - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.0886 - val_accuracy: 0.9787
Epoch 10/10
 -> id = 11  Epoch: 6   accuracy: 0.9862292  val_acc: 0.9691667
48000/48000 - 155s - loss: 0.0455 - accuracy: 0.9862 - val_loss: 0.1084 - val_accuracy: 0.9692
Epoch 8/10
 -> id = 4  Epoch: 5   accuracy: 0.97379166  val_acc: 0.9765
48000/48000 - 191s - loss: 0.0911 - accuracy: 0.9738 - val_loss: 0.0930 - val_accuracy: 0.9765
Epoch 7/10
 -> id = 16  Epoch: 5   accuracy: 0.9780833  val_acc: 0.96416664
48000/48000 - 179s - loss: 0.0678 - accuracy: 0.9781 - val_loss: 0.1203 - val_accuracy: 0.9642
Epoch 7/10
 -> id = 14  Epoch: 7   accuracy: 0.9673125  val_acc: 0.97325
48000/48000 - 137s - loss: 0.1124 - accuracy: 0.9673 - val_loss: 0.1083 - val_accuracy: 0.9732
Epoch 9/10
 -> id = 12  Epoch: 9   accuracy: 0.98745835  val_acc: 0.97366667
48000/48000 - 107s - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.1144 - val_accuracy: 0.9737
 -> id = 8  Epoch: 7   accuracy: 0.97075  val_acc: 0.9774167
48000/48000 - 143s - loss: 0.0998 - accuracy: 0.9707 - val_loss: 0.0827 - val_accuracy: 0.9774
Epoch 9/10
 -> id = 13  Epoch: 7   accuracy: 0.9804375  val_acc: 0.97491664
48000/48000 - 140s - loss: 0.0601 - accuracy: 0.9804 - val_loss: 0.0826 - val_accuracy: 0.9749
Epoch 9/10
 -> id = 15  Epoch: 6   accuracy: 0.9642083  val_acc: 0.9719167
48000/48000 - 151s - loss: 0.1145 - accuracy: 0.9642 - val_loss: 0.0998 - val_accuracy: 0.9719
Epoch 8/10
 -> id = 9  Epoch: 8   accuracy: 0.9965417  val_acc: 0.977
48000/48000 - 126s - loss: 0.0146 - accuracy: 0.9965 - val_loss: 0.0909 - val_accuracy: 0.9770
Epoch 10/10
 -> id = 10  Epoch: 8   accuracy: 0.98689586  val_acc: 0.97466666
48000/48000 - 121s - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.0910 - val_accuracy: 0.9747
Epoch 10/10
 -> id = 3  Epoch: 8   accuracy: 0.9863125  val_acc: 0.97933334
48000/48000 - 120s - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.0750 - val_accuracy: 0.9793
Epoch 10/10
 -> id = 1  Epoch: 5   accuracy: 0.9709375  val_acc: 0.97425
48000/48000 - 193s - loss: 0.0988 - accuracy: 0.9709 - val_loss: 0.0922 - val_accuracy: 0.9743
Epoch 7/10
 -> id = 18  Epoch: 8   accuracy: 0.98722917  val_acc: 0.976
48000/48000 - 128s - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.0912 - val_accuracy: 0.9760
Epoch 10/10
 -> id = 2  Epoch: 8   accuracy: 0.98808336  val_acc: 0.97525
48000/48000 - 113s - loss: 0.0376 - accuracy: 0.9881 - val_loss: 0.0841 - val_accuracy: 0.9753
Epoch 10/10
 -> id = 17  Epoch: 6   accuracy: 0.9695208  val_acc: 0.97125
48000/48000 - 163s - loss: 0.0942 - accuracy: 0.9695 - val_loss: 0.1053 - val_accuracy: 0.9712
Epoch 8/10
 -> id = 19  Epoch: 9   accuracy: 0.9919792  val_acc: 0.9774167
48000/48000 - 114s - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.0954 - val_accuracy: 0.9774
 -> id = 7  Epoch: 6   accuracy: 0.96541667  val_acc: 0.96175
48000/48000 - 162s - loss: 0.1117 - accuracy: 0.9654 - val_loss: 0.1334 - val_accuracy: 0.9617
Epoch 8/10
 -> id = 6  Epoch: 7   accuracy: 0.9939375  val_acc: 0.9738333
48000/48000 - 144s - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.1159 - val_accuracy: 0.9738
Epoch 9/10
 -> id = 11  Epoch: 7   accuracy: 0.987375  val_acc: 0.97125
48000/48000 - 152s - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.1196 - val_accuracy: 0.9712
Epoch 9/10
 -> id = 5  Epoch: 5   accuracy: 0.9675417  val_acc: 0.96608335
48000/48000 - 193s - loss: 0.1102 - accuracy: 0.9675 - val_loss: 0.1231 - val_accuracy: 0.9661
Epoch 7/10
 -> id = 14  Epoch: 8   accuracy: 0.96977085  val_acc: 0.97291666
48000/48000 - 129s - loss: 0.1040 - accuracy: 0.9698 - val_loss: 0.0991 - val_accuracy: 0.9729
Epoch 10/10
 -> id = 16  Epoch: 6   accuracy: 0.9805833  val_acc: 0.97008336
48000/48000 - 161s - loss: 0.0587 - accuracy: 0.9806 - val_loss: 0.1044 - val_accuracy: 0.9701
Epoch 8/10
 -> id = 13  Epoch: 8   accuracy: 0.9825  val_acc: 0.9759167
48000/48000 - 123s - loss: 0.0536 - accuracy: 0.9825 - val_loss: 0.0820 - val_accuracy: 0.9759
Epoch 10/10
 -> id = 4  Epoch: 6   accuracy: 0.97577083  val_acc: 0.97316664
48000/48000 - 172s - loss: 0.0850 - accuracy: 0.9758 - val_loss: 0.0978 - val_accuracy: 0.9732
Epoch 8/10
 -> id = 10  Epoch: 9   accuracy: 0.98745835  val_acc: 0.9769167
48000/48000 - 114s - loss: 0.0370 - accuracy: 0.9875 - val_loss: 0.0825 - val_accuracy: 0.9769
 -> id = 9  Epoch: 9   accuracy: 0.99714583  val_acc: 0.9745833
48000/48000 - 121s - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.0965 - val_accuracy: 0.9746
 -> id = 8  Epoch: 8   accuracy: 0.97241664  val_acc: 0.977
48000/48000 - 134s - loss: 0.0909 - accuracy: 0.9724 - val_loss: 0.0880 - val_accuracy: 0.9770
Epoch 10/10
 -> id = 3  Epoch: 9   accuracy: 0.98727083  val_acc: 0.9791667
48000/48000 - 117s - loss: 0.0381 - accuracy: 0.9873 - val_loss: 0.0728 - val_accuracy: 0.9792
 -> id = 2  Epoch: 9   accuracy: 0.9876458  val_acc: 0.9745833
48000/48000 - 109s - loss: 0.0367 - accuracy: 0.9876 - val_loss: 0.0878 - val_accuracy: 0.9746
 -> id = 18  Epoch: 9   accuracy: 0.98983335  val_acc: 0.97433335
48000/48000 - 113s - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.0966 - val_accuracy: 0.9743
 -> id = 15  Epoch: 7   accuracy: 0.96758336  val_acc: 0.97208333
48000/48000 - 144s - loss: 0.1035 - accuracy: 0.9676 - val_loss: 0.0925 - val_accuracy: 0.9721
Epoch 9/10
 -> id = 17  Epoch: 7   accuracy: 0.9744167  val_acc: 0.9709167
48000/48000 - 140s - loss: 0.0817 - accuracy: 0.9744 - val_loss: 0.1079 - val_accuracy: 0.9709
Epoch 9/10
 -> id = 6  Epoch: 8   accuracy: 0.9939167  val_acc: 0.9751667
48000/48000 - 126s - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.1087 - val_accuracy: 0.9752
Epoch 10/10
 -> id = 1  Epoch: 6   accuracy: 0.9746042  val_acc: 0.97491664
48000/48000 - 171s - loss: 0.0843 - accuracy: 0.9746 - val_loss: 0.0870 - val_accuracy: 0.9749
Epoch 8/10
 -> id = 7  Epoch: 7   accuracy: 0.97041667  val_acc: 0.96541667
48000/48000 - 142s - loss: 0.0983 - accuracy: 0.9704 - val_loss: 0.1152 - val_accuracy: 0.9654
Epoch 9/10
 -> id = 14  Epoch: 9   accuracy: 0.9735208  val_acc: 0.97475
48000/48000 - 101s - loss: 0.0907 - accuracy: 0.9735 - val_loss: 0.0968 - val_accuracy: 0.9747
 -> id = 11  Epoch: 8   accuracy: 0.9875208  val_acc: 0.97391665
48000/48000 - 126s - loss: 0.0361 - accuracy: 0.9875 - val_loss: 0.1104 - val_accuracy: 0.9739
Epoch 10/10
 -> id = 13  Epoch: 9   accuracy: 0.98377085  val_acc: 0.9769167
48000/48000 - 104s - loss: 0.0504 - accuracy: 0.9838 - val_loss: 0.0809 - val_accuracy: 0.9769
 -> id = 8  Epoch: 9   accuracy: 0.97325  val_acc: 0.9745
48000/48000 - 114s - loss: 0.0887 - accuracy: 0.9732 - val_loss: 0.0887 - val_accuracy: 0.9745
 -> id = 16  Epoch: 7   accuracy: 0.9825625  val_acc: 0.9661667
48000/48000 - 135s - loss: 0.0522 - accuracy: 0.9826 - val_loss: 0.1168 - val_accuracy: 0.9662
Epoch 9/10
 -> id = 5  Epoch: 6   accuracy: 0.9723125  val_acc: 0.97225
48000/48000 - 167s - loss: 0.0980 - accuracy: 0.9723 - val_loss: 0.0995 - val_accuracy: 0.9722
Epoch 8/10
 -> id = 4  Epoch: 7   accuracy: 0.97747916  val_acc: 0.9745
48000/48000 - 154s - loss: 0.0772 - accuracy: 0.9775 - val_loss: 0.0974 - val_accuracy: 0.9745
Epoch 9/10
 -> id = 15  Epoch: 8   accuracy: 0.97035414  val_acc: 0.97616667
48000/48000 - 129s - loss: 0.0949 - accuracy: 0.9704 - val_loss: 0.0882 - val_accuracy: 0.9762
Epoch 10/10
 -> id = 17  Epoch: 8   accuracy: 0.97652084  val_acc: 0.974
48000/48000 - 113s - loss: 0.0771 - accuracy: 0.9765 - val_loss: 0.1077 - val_accuracy: 0.9740
Epoch 10/10
 -> id = 6  Epoch: 9   accuracy: 0.9938125  val_acc: 0.97566664
48000/48000 - 112s - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.1134 - val_accuracy: 0.9757
 -> id = 7  Epoch: 8   accuracy: 0.9732083  val_acc: 0.96875
48000/48000 - 107s - loss: 0.0880 - accuracy: 0.9732 - val_loss: 0.1118 - val_accuracy: 0.9688
Epoch 10/10
 -> id = 11  Epoch: 9   accuracy: 0.9905625  val_acc: 0.97575
48000/48000 - 95s - loss: 0.0309 - accuracy: 0.9906 - val_loss: 0.0969 - val_accuracy: 0.9758
 -> id = 1  Epoch: 7   accuracy: 0.97629166  val_acc: 0.976
48000/48000 - 135s - loss: 0.0802 - accuracy: 0.9763 - val_loss: 0.0862 - val_accuracy: 0.9760
Epoch 9/10
 -> id = 16  Epoch: 8   accuracy: 0.9847917  val_acc: 0.97275
48000/48000 - 102s - loss: 0.0466 - accuracy: 0.9848 - val_loss: 0.0920 - val_accuracy: 0.9728
Epoch 10/10
 -> id = 17  Epoch: 9   accuracy: 0.9768958  val_acc: 0.97625
48000/48000 - 86s - loss: 0.0728 - accuracy: 0.9769 - val_loss: 0.0946 - val_accuracy: 0.9762
 -> id = 7  Epoch: 9   accuracy: 0.9765  val_acc: 0.97175
48000/48000 - 80s - loss: 0.0782 - accuracy: 0.9765 - val_loss: 0.1041 - val_accuracy: 0.9718
 -> id = 15  Epoch: 9   accuracy: 0.9713333  val_acc: 0.97125
48000/48000 - 105s - loss: 0.0903 - accuracy: 0.9713 - val_loss: 0.1025 - val_accuracy: 0.9712
 -> id = 5  Epoch: 7   accuracy: 0.9739583  val_acc: 0.973
48000/48000 - 128s - loss: 0.0887 - accuracy: 0.9740 - val_loss: 0.0991 - val_accuracy: 0.9730
Epoch 9/10
 -> id = 4  Epoch: 8   accuracy: 0.9795  val_acc: 0.97775
48000/48000 - 116s - loss: 0.0683 - accuracy: 0.9795 - val_loss: 0.0917 - val_accuracy: 0.9778
Epoch 10/10
 -> id = 1  Epoch: 8   accuracy: 0.9780833  val_acc: 0.97641665
48000/48000 - 92s - loss: 0.0735 - accuracy: 0.9781 - val_loss: 0.0838 - val_accuracy: 0.9764
Epoch 10/10
 -> id = 16  Epoch: 9   accuracy: 0.9847083  val_acc: 0.975
48000/48000 - 68s - loss: 0.0457 - accuracy: 0.9847 - val_loss: 0.0918 - val_accuracy: 0.9750
 -> id = 5  Epoch: 8   accuracy: 0.97652084  val_acc: 0.97325
48000/48000 - 68s - loss: 0.0818 - accuracy: 0.9765 - val_loss: 0.1011 - val_accuracy: 0.9732
Epoch 10/10
 -> id = 4  Epoch: 9   accuracy: 0.98104167  val_acc: 0.97608334
48000/48000 - 66s - loss: 0.0634 - accuracy: 0.9810 - val_loss: 0.0971 - val_accuracy: 0.9761
 -> id = 1  Epoch: 9   accuracy: 0.98097914  val_acc: 0.97816664
48000/48000 - 49s - loss: 0.0625 - accuracy: 0.9810 - val_loss: 0.0826 - val_accuracy: 0.9782
 -> id = 5  Epoch: 9   accuracy: 0.977375  val_acc: 0.974
48000/48000 - 25s - loss: 0.0773 - accuracy: 0.9774 - val_loss: 0.1048 - val_accuracy: 0.9740
 id = 0  val_accuracy = 0.9803333282470703
 id = 3  val_accuracy = 0.9791666865348816
 id = 1  val_accuracy = 0.9781666398048401
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  2   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Model: "model_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_161 (Dense)            (None, 910)               714350
_________________________________________________________________
activation_120 (Activation)  (None, 910)               0
_________________________________________________________________
dropout_62 (Dropout)         (None, 910)               0
_________________________________________________________________
batch_normalization_61 (Batc (None, 910)               3640
_________________________________________________________________
dense_162 (Dense)            (None, 10)                9110
=================================================================
Total params: 727,100
Trainable params: 725,280
Non-trainable params: 1,820
_________________________________________________________________
None
Model: "model_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_163 (Dense)            (None, 1108)              869780
_________________________________________________________________
activation_121 (Activation)  (None, 1108)              0
_________________________________________________________________
dropout_63 (Dropout)         (None, 1108)              0
_________________________________________________________________
batch_normalization_62 (Batc (None, 1108)              4432
_________________________________________________________________
dense_164 (Dense)            (None, 10)                11090
=================================================================
Total params: 885,302
Trainable params: 883,086
Non-trainable params: 2,216
_________________________________________________________________
None
Model: "model_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_165 (Dense)            (None, 460)               361100
_________________________________________________________________
activation_122 (Activation)  (None, 460)               0
_________________________________________________________________
dropout_64 (Dropout)         (None, 460)               0
_________________________________________________________________
dense_166 (Dense)            (None, 1890)              871290
_________________________________________________________________
activation_123 (Activation)  (None, 1890)              0
_________________________________________________________________
dropout_65 (Dropout)         (None, 1890)              0
_________________________________________________________________
dense_167 (Dense)            (None, 1720)              3252520
_________________________________________________________________
activation_124 (Activation)  (None, 1720)              0
_________________________________________________________________
dense_168 (Dense)            (None, 1580)              2719180
_________________________________________________________________
activation_125 (Activation)  (None, 1580)              0
_________________________________________________________________
dense_169 (Dense)            (None, 10)                15810
=================================================================
Total params: 7,219,900
Trainable params: 7,219,900
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_170 (Dense)            (None, 585)               459225
_________________________________________________________________
activation_126 (Activation)  (None, 585)               0
_________________________________________________________________
dropout_66 (Dropout)         (None, 585)               0
_________________________________________________________________
batch_normalization_63 (Batc (None, 585)               2340
_________________________________________________________________
dense_171 (Dense)            (None, 10)                5860
=================================================================
Total params: 467,425
Trainable params: 466,255
Non-trainable params: 1,170
_________________________________________________________________
None
Model: "model_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_172 (Dense)            (None, 986)               774010
_________________________________________________________________
activation_127 (Activation)  (None, 986)               0
_________________________________________________________________
dropout_67 (Dropout)         (None, 986)               0
_________________________________________________________________
batch_normalization_64 (Batc (None, 986)               3944
_________________________________________________________________
dense_173 (Dense)            (None, 10)                9870
=================================================================
Total params: 787,824
Trainable params: 785,852
Non-trainable params: 1,972
_________________________________________________________________
None
Model: "model_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_174 (Dense)            (None, 1770)              1389450
_________________________________________________________________
activation_128 (Activation)  (None, 1770)              0
_________________________________________________________________
dropout_68 (Dropout)         (None, 1770)              0
_________________________________________________________________
dense_175 (Dense)            (None, 1000)              1771000
_________________________________________________________________
activation_129 (Activation)  (None, 1000)              0
_________________________________________________________________
dense_176 (Dense)            (None, 730)               730730
_________________________________________________________________
activation_130 (Activation)  (None, 730)               0
_________________________________________________________________
dropout_69 (Dropout)         (None, 730)               0
_________________________________________________________________
dense_177 (Dense)            (None, 10)                7310
=================================================================
Total params: 3,898,490
Trainable params: 3,898,490
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_178 (Dense)            (None, 1770)              1389450
_________________________________________________________________
activation_131 (Activation)  (None, 1770)              0
_________________________________________________________________
dropout_70 (Dropout)         (None, 1770)              0
_________________________________________________________________
dense_179 (Dense)            (None, 190)               336490
_________________________________________________________________
activation_132 (Activation)  (None, 190)               0
_________________________________________________________________
dropout_71 (Dropout)         (None, 190)               0
_________________________________________________________________
batch_normalization_65 (Batc (None, 190)               760
_________________________________________________________________
dense_180 (Dense)            (None, 1340)              255940
_________________________________________________________________
activation_133 (Activation)  (None, 1340)              0
_________________________________________________________________
dense_181 (Dense)            (None, 10)                13410
=================================================================
Total params: 1,996,050
Trainable params: 1,995,670
Non-trainable params: 380
_________________________________________________________________
None
Model: "model_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_182 (Dense)            (None, 120)               94200
_________________________________________________________________
activation_134 (Activation)  (None, 120)               0
_________________________________________________________________
dense_183 (Dense)            (None, 1430)              173030
_________________________________________________________________
activation_135 (Activation)  (None, 1430)              0
_________________________________________________________________
dense_184 (Dense)            (None, 10)                14310
=================================================================
Total params: 281,540
Trainable params: 281,540
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_185 (Dense)            (None, 920)               722200
_________________________________________________________________
activation_136 (Activation)  (None, 920)               0
_________________________________________________________________
dropout_72 (Dropout)         (None, 920)               0
_________________________________________________________________
batch_normalization_66 (Batc (None, 920)               3680
_________________________________________________________________
dense_186 (Dense)            (None, 1030)              948630
_________________________________________________________________
activation_137 (Activation)  (None, 1030)              0
_________________________________________________________________
batch_normalization_67 (Batc (None, 1030)              4120
_________________________________________________________________
dense_187 (Dense)            (None, 1960)              2020760
_________________________________________________________________
activation_138 (Activation)  (None, 1960)              0
_________________________________________________________________
dropout_73 (Dropout)         (None, 1960)              0
_________________________________________________________________
dense_188 (Dense)            (None, 10)                19610
=================================================================
Total params: 3,719,000
Trainable params: 3,715,100
Non-trainable params: 3,900
_________________________________________________________________
None
Model: "model_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_189 (Dense)            (None, 1660)              1303100
_________________________________________________________________
activation_139 (Activation)  (None, 1660)              0
_________________________________________________________________
batch_normalization_68 (Batc (None, 1660)              6640
_________________________________________________________________
dense_190 (Dense)            (None, 260)               431860
_________________________________________________________________
activation_140 (Activation)  (None, 260)               0
_________________________________________________________________
batch_normalization_69 (Batc (None, 260)               1040
_________________________________________________________________
dense_191 (Dense)            (None, 10)                2610
=================================================================
Total params: 1,745,250
Trainable params: 1,741,410
Non-trainable params: 3,840
_________________________________________________________________
None
Model: "model_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_192 (Dense)            (None, 330)               259050
_________________________________________________________________
activation_141 (Activation)  (None, 330)               0
_________________________________________________________________
dense_193 (Dense)            (None, 10)                3310
=================================================================
Total params: 262,360
Trainable params: 262,360
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_194 (Dense)            (None, 830)               651550
_________________________________________________________________
activation_142 (Activation)  (None, 830)               0
_________________________________________________________________
dense_195 (Dense)            (None, 1800)              1495800
_________________________________________________________________
activation_143 (Activation)  (None, 1800)              0
_________________________________________________________________
batch_normalization_70 (Batc (None, 1800)              7200
_________________________________________________________________
dense_196 (Dense)            (None, 770)               1386770
_________________________________________________________________
activation_144 (Activation)  (None, 770)               0
_________________________________________________________________
dropout_74 (Dropout)         (None, 770)               0
_________________________________________________________________
batch_normalization_71 (Batc (None, 770)               3080
_________________________________________________________________
dense_197 (Dense)            (None, 10)                7710
=================================================================
Total params: 3,552,110
Trainable params: 3,546,970
Non-trainable params: 5,140
_________________________________________________________________
None
Model: "model_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_198 (Dense)            (None, 1690)              1326650
_________________________________________________________________
activation_145 (Activation)  (None, 1690)              0
_________________________________________________________________
dropout_75 (Dropout)         (None, 1690)              0
_________________________________________________________________
dense_199 (Dense)            (None, 1390)              2350490
_________________________________________________________________
activation_146 (Activation)  (None, 1390)              0
_________________________________________________________________
dropout_76 (Dropout)         (None, 1390)              0
_________________________________________________________________
dense_200 (Dense)            (None, 1540)              2142140
_________________________________________________________________
activation_147 (Activation)  (None, 1540)              0
_________________________________________________________________
batch_normalization_72 (Batc (None, 1540)              6160
_________________________________________________________________
dense_201 (Dense)            (None, 820)               1263620
_________________________________________________________________
activation_148 (Activation)  (None, 820)               0
_________________________________________________________________
dropout_77 (Dropout)         (None, 820)               0
_________________________________________________________________
dense_202 (Dense)            (None, 10)                8210
=================================================================
Total params: 7,097,270
Trainable params: 7,094,190
Non-trainable params: 3,080
_________________________________________________________________
None
Model: "model_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_203 (Dense)            (None, 1430)              1122550
_________________________________________________________________
activation_149 (Activation)  (None, 1430)              0
_________________________________________________________________
batch_normalization_73 (Batc (None, 1430)              5720
_________________________________________________________________
dense_204 (Dense)            (None, 10)                14310
=================================================================
Total params: 1,142,580
Trainable params: 1,139,720
Non-trainable params: 2,860
_________________________________________________________________
None
Model: "model_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_205 (Dense)            (None, 770)               604450
_________________________________________________________________
activation_150 (Activation)  (None, 770)               0
_________________________________________________________________
batch_normalization_74 (Batc (None, 770)               3080
_________________________________________________________________
dense_206 (Dense)            (None, 1700)              1310700
_________________________________________________________________
activation_151 (Activation)  (None, 1700)              0
_________________________________________________________________
dense_207 (Dense)            (None, 10)                17010
=================================================================
Total params: 1,935,240
Trainable params: 1,933,700
Non-trainable params: 1,540
_________________________________________________________________
None
Model: "model_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_208 (Dense)            (None, 1420)              1114700
_________________________________________________________________
activation_152 (Activation)  (None, 1420)              0
_________________________________________________________________
batch_normalization_75 (Batc (None, 1420)              5680
_________________________________________________________________
dense_209 (Dense)            (None, 520)               738920
_________________________________________________________________
activation_153 (Activation)  (None, 520)               0
_________________________________________________________________
dense_210 (Dense)            (None, 10)                5210
=================================================================
Total params: 1,864,510
Trainable params: 1,861,670
Non-trainable params: 2,840
_________________________________________________________________
None
Model: "model_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_211 (Dense)            (None, 1540)              1208900
_________________________________________________________________
activation_154 (Activation)  (None, 1540)              0
_________________________________________________________________
dense_212 (Dense)            (None, 10)                15410
=================================================================
Total params: 1,224,310
Trainable params: 1,224,310
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_213 (Dense)            (None, 1430)              1122550
_________________________________________________________________
activation_155 (Activation)  (None, 1430)              0
_________________________________________________________________
batch_normalization_76 (Batc (None, 1430)              5720
_________________________________________________________________
dense_214 (Dense)            (None, 360)               515160
_________________________________________________________________
activation_156 (Activation)  (None, 360)               0
_________________________________________________________________
dense_215 (Dense)            (None, 1850)              667850
_________________________________________________________________
activation_157 (Activation)  (None, 1850)              0
_________________________________________________________________
dropout_78 (Dropout)         (None, 1850)              0
_________________________________________________________________
dense_216 (Dense)            (None, 1810)              3350310
_________________________________________________________________
activation_158 (Activation)  (None, 1810)              0
_________________________________________________________________
batch_normalization_77 (Batc (None, 1810)              7240
_________________________________________________________________
dense_217 (Dense)            (None, 10)                18110
=================================================================
Total params: 5,686,940
Trainable params: 5,680,460
Non-trainable params: 6,480
_________________________________________________________________
None
Model: "model_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_218 (Dense)            (None, 1030)              808550
_________________________________________________________________
activation_159 (Activation)  (None, 1030)              0
_________________________________________________________________
dense_219 (Dense)            (None, 190)               195890
_________________________________________________________________
activation_160 (Activation)  (None, 190)               0
_________________________________________________________________
dropout_79 (Dropout)         (None, 190)               0
_________________________________________________________________
batch_normalization_78 (Batc (None, 190)               760
_________________________________________________________________
dense_220 (Dense)            (None, 70)                13370
_________________________________________________________________
activation_161 (Activation)  (None, 70)                0
_________________________________________________________________
dropout_80 (Dropout)         (None, 70)                0
_________________________________________________________________
dense_221 (Dense)            (None, 1190)              84490
_________________________________________________________________
activation_162 (Activation)  (None, 1190)              0
_________________________________________________________________
batch_normalization_79 (Batc (None, 1190)              4760
_________________________________________________________________
dense_222 (Dense)            (None, 10)                11910
=================================================================
Total params: 1,119,730
Trainable params: 1,116,970
Non-trainable params: 2,760
_________________________________________________________________
None
Model: "model_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_223 (Dense)            (None, 1630)              1279550
_________________________________________________________________
activation_163 (Activation)  (None, 1630)              0
_________________________________________________________________
dense_224 (Dense)            (None, 1090)              1777790
_________________________________________________________________
activation_164 (Activation)  (None, 1090)              0
_________________________________________________________________
dropout_81 (Dropout)         (None, 1090)              0
_________________________________________________________________
dense_225 (Dense)            (None, 1880)              2051080
_________________________________________________________________
activation_165 (Activation)  (None, 1880)              0
_________________________________________________________________
dropout_82 (Dropout)         (None, 1880)              0
_________________________________________________________________
batch_normalization_80 (Batc (None, 1880)              7520
_________________________________________________________________
dense_226 (Dense)            (None, 10)                18810
=================================================================
Total params: 5,134,750
Trainable params: 5,130,990
Non-trainable params: 3,760
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samplesTrain on 48000 samples, validate on 12000 samples

Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesTrain on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples

Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Epoch 1/10Epoch 1/10
Epoch 1/10

Epoch 1/10


Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Epoch 1/10
Epoch 1/10
Epoch 1/10

 -> id = 10  Epoch: 0   accuracy: 0.8933333  val_acc: 0.93383336
48000/48000 - 40s - loss: 0.3730 - accuracy: 0.8933 - val_loss: 0.2391 - val_accuracy: 0.9338
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.89416665  val_acc: 0.9224167
48000/48000 - 53s - loss: 0.3608 - accuracy: 0.8942 - val_loss: 0.2734 - val_accuracy: 0.9224
Epoch 2/10
 -> id = 7  Epoch: 0   accuracy: 0.82527083  val_acc: 0.92025
48000/48000 - 68s - loss: 0.5659 - accuracy: 0.8253 - val_loss: 0.2654 - val_accuracy: 0.9202
Epoch 2/10
 -> id = 0  Epoch: 0   accuracy: 0.92214584  val_acc: 0.96175
48000/48000 - 92s - loss: 0.2565 - accuracy: 0.9221 - val_loss: 0.1497 - val_accuracy: 0.9617
Epoch 2/10
 -> id = 1  Epoch: 0   accuracy: 0.9222083  val_acc: 0.96416664
48000/48000 - 93s - loss: 0.2513 - accuracy: 0.9222 - val_loss: 0.1410 - val_accuracy: 0.9642
Epoch 2/10
 -> id = 4  Epoch: 0   accuracy: 0.92320836  val_acc: 0.96475
48000/48000 - 100s - loss: 0.2555 - accuracy: 0.9232 - val_loss: 0.1409 - val_accuracy: 0.9647
Epoch 2/10
 -> id = 3  Epoch: 0   accuracy: 0.9115625  val_acc: 0.9626667
48000/48000 - 100s - loss: 0.2906 - accuracy: 0.9116 - val_loss: 0.1474 - val_accuracy: 0.9627
Epoch 2/10
 -> id = 13  Epoch: 0   accuracy: 0.8963125  val_acc: 0.9295
48000/48000 - 106s - loss: 0.4019 - accuracy: 0.8963 - val_loss: 0.2509 - val_accuracy: 0.9295
Epoch 2/10
 -> id = 5  Epoch: 0   accuracy: 0.37260416  val_acc: 0.56091666
48000/48000 - 121s - loss: 1.4684 - accuracy: 0.3726 - val_loss: 0.9901 - val_accuracy: 0.5609
Epoch 2/10
 -> id = 15  Epoch: 0   accuracy: 0.92966664  val_acc: 0.94483334
48000/48000 - 127s - loss: 0.2616 - accuracy: 0.9297 - val_loss: 0.1812 - val_accuracy: 0.9448
Epoch 2/10
 -> id = 14  Epoch: 0   accuracy: 0.8988542  val_acc: 0.8448333
48000/48000 - 131s - loss: 0.3447 - accuracy: 0.8989 - val_loss: 0.4695 - val_accuracy: 0.8448
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.8567708  val_acc: 0.9385833
48000/48000 - 132s - loss: 0.4464 - accuracy: 0.8568 - val_loss: 0.1961 - val_accuracy: 0.9386
Epoch 2/10
 -> id = 10  Epoch: 1   accuracy: 0.939125  val_acc: 0.95241666
48000/48000 - 95s - loss: 0.2123 - accuracy: 0.9391 - val_loss: 0.1759 - val_accuracy: 0.9524
Epoch 3/10
 -> id = 18  Epoch: 0   accuracy: 0.86475  val_acc: 0.92366666
48000/48000 - 136s - loss: 0.4521 - accuracy: 0.8648 - val_loss: 0.8972 - val_accuracy: 0.9237
Epoch 2/10
 -> id = 9  Epoch: 0   accuracy: 0.9454375  val_acc: 0.95975
48000/48000 - 141s - loss: 0.1859 - accuracy: 0.9454 - val_loss: 0.1487 - val_accuracy: 0.9597
Epoch 2/10
 -> id = 16  Epoch: 1   accuracy: 0.9325208  val_acc: 0.9425
48000/48000 - 92s - loss: 0.2348 - accuracy: 0.9325 - val_loss: 0.1989 - val_accuracy: 0.9425
Epoch 3/10
 -> id = 11  Epoch: 0   accuracy: 0.8994167  val_acc: 0.73358333
48000/48000 - 168s - loss: 0.3560 - accuracy: 0.8994 - val_loss: 1.2756 - val_accuracy: 0.7336
Epoch 2/10
 -> id = 7  Epoch: 1   accuracy: 0.9266458  val_acc: 0.94425
48000/48000 - 100s - loss: 0.2459 - accuracy: 0.9266 - val_loss: 0.1942 - val_accuracy: 0.9442
Epoch 3/10
 -> id = 1  Epoch: 1   accuracy: 0.966625  val_acc: 0.97108334
48000/48000 - 75s - loss: 0.1108 - accuracy: 0.9666 - val_loss: 0.0944 - val_accuracy: 0.9711
Epoch 3/10
 -> id = 0  Epoch: 1   accuracy: 0.9640833  val_acc: 0.97258335
48000/48000 - 78s - loss: 0.1188 - accuracy: 0.9641 - val_loss: 0.0938 - val_accuracy: 0.9726
Epoch 3/10
 -> id = 4  Epoch: 1   accuracy: 0.9648542  val_acc: 0.97141665
48000/48000 - 80s - loss: 0.1152 - accuracy: 0.9649 - val_loss: 0.0982 - val_accuracy: 0.9714
Epoch 3/10
 -> id = 19  Epoch: 0   accuracy: 0.91495836  val_acc: 0.96458334
48000/48000 - 181s - loss: 0.3124 - accuracy: 0.9150 - val_loss: 0.1248 - val_accuracy: 0.9646
Epoch 2/10
 -> id = 2  Epoch: 0   accuracy: 0.68427086  val_acc: 0.9399167
48000/48000 - 183s - loss: 0.9069 - accuracy: 0.6843 - val_loss: 0.2157 - val_accuracy: 0.9399
Epoch 2/10
 -> id = 3  Epoch: 1   accuracy: 0.9614583  val_acc: 0.97216666
48000/48000 - 84s - loss: 0.1286 - accuracy: 0.9615 - val_loss: 0.0993 - val_accuracy: 0.9722
Epoch 3/10
 -> id = 8  Epoch: 0   accuracy: 0.608125  val_acc: 0.8975833
48000/48000 - 185s - loss: 2.0111 - accuracy: 0.6081 - val_loss: 1.7463 - val_accuracy: 0.8976
Epoch 2/10
 -> id = 13  Epoch: 1   accuracy: 0.94864583  val_acc: 0.95475
48000/48000 - 95s - loss: 0.1722 - accuracy: 0.9486 - val_loss: 0.1594 - val_accuracy: 0.9548
Epoch 3/10
 -> id = 12  Epoch: 0   accuracy: 0.24558334  val_acc: 0.6134167
48000/48000 - 203s - loss: 1.9799 - accuracy: 0.2456 - val_loss: 1.3733 - val_accuracy: 0.6134
Epoch 2/10
 -> id = 17  Epoch: 0   accuracy: 0.721125  val_acc: 0.45533332
48000/48000 - 206s - loss: 0.8590 - accuracy: 0.7211 - val_loss: 2.0028 - val_accuracy: 0.4553
Epoch 2/10
 -> id = 10  Epoch: 2   accuracy: 0.9555417  val_acc: 0.959
48000/48000 - 89s - loss: 0.1538 - accuracy: 0.9555 - val_loss: 0.1499 - val_accuracy: 0.9590
Epoch 4/10
 -> id = 15  Epoch: 1   accuracy: 0.96739584  val_acc: 0.96608335
48000/48000 - 104s - loss: 0.1158 - accuracy: 0.9674 - val_loss: 0.1299 - val_accuracy: 0.9661
Epoch 3/10
 -> id = 16  Epoch: 2   accuracy: 0.9513125  val_acc: 0.9543333
48000/48000 - 86s - loss: 0.1649 - accuracy: 0.9513 - val_loss: 0.1543 - val_accuracy: 0.9543
Epoch 4/10
 -> id = 18  Epoch: 1   accuracy: 0.94575  val_acc: 0.96183336
48000/48000 - 102s - loss: 0.1949 - accuracy: 0.9457 - val_loss: 0.1377 - val_accuracy: 0.9618
Epoch 3/10
 -> id = 6  Epoch: 1   accuracy: 0.93591666  val_acc: 0.94941664
48000/48000 - 107s - loss: 0.2055 - accuracy: 0.9359 - val_loss: 0.1670 - val_accuracy: 0.9494
Epoch 3/10
 -> id = 14  Epoch: 1   accuracy: 0.94625  val_acc: 0.9525833
48000/48000 - 110s - loss: 0.1806 - accuracy: 0.9463 - val_loss: 0.1651 - val_accuracy: 0.9526
Epoch 3/10
 -> id = 0  Epoch: 2   accuracy: 0.9729375  val_acc: 0.97275
48000/48000 - 72s - loss: 0.0866 - accuracy: 0.9729 - val_loss: 0.0896 - val_accuracy: 0.9728
Epoch 4/10
 -> id = 9  Epoch: 1   accuracy: 0.97985417  val_acc: 0.9695
48000/48000 - 102s - loss: 0.0664 - accuracy: 0.9799 - val_loss: 0.1069 - val_accuracy: 0.9695
Epoch 3/10
 -> id = 1  Epoch: 2   accuracy: 0.9734167  val_acc: 0.97433335
48000/48000 - 77s - loss: 0.0857 - accuracy: 0.9734 - val_loss: 0.0865 - val_accuracy: 0.9743
Epoch 4/10
 -> id = 5  Epoch: 1   accuracy: 0.80745834  val_acc: 0.91908336
48000/48000 - 127s - loss: 0.5681 - accuracy: 0.8075 - val_loss: 0.2949 - val_accuracy: 0.9191
Epoch 3/10
 -> id = 4  Epoch: 2   accuracy: 0.9748333  val_acc: 0.97291666
48000/48000 - 79s - loss: 0.0824 - accuracy: 0.9748 - val_loss: 0.0870 - val_accuracy: 0.9729
Epoch 4/10
 -> id = 7  Epoch: 2   accuracy: 0.9455625  val_acc: 0.95091665
48000/48000 - 95s - loss: 0.1827 - accuracy: 0.9456 - val_loss: 0.1642 - val_accuracy: 0.9509
Epoch 4/10
 -> id = 3  Epoch: 2   accuracy: 0.96922916  val_acc: 0.97391665
48000/48000 - 97s - loss: 0.1021 - accuracy: 0.9692 - val_loss: 0.0869 - val_accuracy: 0.9739
Epoch 4/10
 -> id = 13  Epoch: 2   accuracy: 0.96552086  val_acc: 0.9691667
48000/48000 - 106s - loss: 0.1108 - accuracy: 0.9655 - val_loss: 0.1109 - val_accuracy: 0.9692
Epoch 4/10
 -> id = 11  Epoch: 1   accuracy: 0.95295835  val_acc: 0.93291664
48000/48000 - 141s - loss: 0.1610 - accuracy: 0.9530 - val_loss: 0.2241 - val_accuracy: 0.9329
Epoch 3/10
 -> id = 10  Epoch: 3   accuracy: 0.96610415  val_acc: 0.96125
48000/48000 - 90s - loss: 0.1179 - accuracy: 0.9661 - val_loss: 0.1305 - val_accuracy: 0.9613
Epoch 5/10
 -> id = 1  Epoch: 3   accuracy: 0.9786875  val_acc: 0.973
48000/48000 - 81s - loss: 0.0681 - accuracy: 0.9787 - val_loss: 0.0878 - val_accuracy: 0.9730
Epoch 5/10
 -> id = 0  Epoch: 3   accuracy: 0.97747916  val_acc: 0.97475
48000/48000 - 87s - loss: 0.0720 - accuracy: 0.9775 - val_loss: 0.0847 - val_accuracy: 0.9747
Epoch 5/10
 -> id = 16  Epoch: 3   accuracy: 0.9647083  val_acc: 0.965
48000/48000 - 97s - loss: 0.1194 - accuracy: 0.9647 - val_loss: 0.1234 - val_accuracy: 0.9650
Epoch 5/10
 -> id = 19  Epoch: 1   accuracy: 0.9666042  val_acc: 0.96458334
48000/48000 - 153s - loss: 0.1180 - accuracy: 0.9666 - val_loss: 0.1297 - val_accuracy: 0.9646
Epoch 3/10
 -> id = 15  Epoch: 2   accuracy: 0.976125  val_acc: 0.97041667
48000/48000 - 107s - loss: 0.0781 - accuracy: 0.9761 - val_loss: 0.1148 - val_accuracy: 0.9704
Epoch 4/10
 -> id = 8  Epoch: 1   accuracy: 0.66875  val_acc: 0.927
48000/48000 - 155s - loss: 1.5847 - accuracy: 0.6687 - val_loss: 1.3456 - val_accuracy: 0.9270
Epoch 3/10
 -> id = 4  Epoch: 3   accuracy: 0.97814584  val_acc: 0.9744167
48000/48000 - 82s - loss: 0.0701 - accuracy: 0.9781 - val_loss: 0.0823 - val_accuracy: 0.9744
Epoch 5/10
 -> id = 18  Epoch: 2   accuracy: 0.9611875  val_acc: 0.9738333
48000/48000 - 107s - loss: 0.1404 - accuracy: 0.9612 - val_loss: 0.1054 - val_accuracy: 0.9738
Epoch 4/10
 -> id = 2  Epoch: 1   accuracy: 0.92920834  val_acc: 0.95741665
48000/48000 - 165s - loss: 0.2490 - accuracy: 0.9292 - val_loss: 0.1452 - val_accuracy: 0.9574
Epoch 3/10
 -> id = 9  Epoch: 2   accuracy: 0.98645836  val_acc: 0.9713333
48000/48000 - 106s - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.0981 - val_accuracy: 0.9713
Epoch 4/10
 -> id = 6  Epoch: 2   accuracy: 0.9517083  val_acc: 0.9573333
48000/48000 - 115s - loss: 0.1553 - accuracy: 0.9517 - val_loss: 0.1382 - val_accuracy: 0.9573
Epoch 4/10
 -> id = 14  Epoch: 2   accuracy: 0.96489584  val_acc: 0.966
48000/48000 - 115s - loss: 0.1159 - accuracy: 0.9649 - val_loss: 0.1173 - val_accuracy: 0.9660
Epoch 4/10
 -> id = 7  Epoch: 3   accuracy: 0.9564375  val_acc: 0.9579167
48000/48000 - 92s - loss: 0.1448 - accuracy: 0.9564 - val_loss: 0.1458 - val_accuracy: 0.9579
Epoch 5/10
 -> id = 3  Epoch: 3   accuracy: 0.974875  val_acc: 0.97508335
48000/48000 - 89s - loss: 0.0818 - accuracy: 0.9749 - val_loss: 0.0825 - val_accuracy: 0.9751
Epoch 5/10
 -> id = 5  Epoch: 2   accuracy: 0.92845833  val_acc: 0.94175
48000/48000 - 128s - loss: 0.2577 - accuracy: 0.9285 - val_loss: 0.2078 - val_accuracy: 0.9417
Epoch 4/10
 -> id = 12  Epoch: 1   accuracy: 0.55747914  val_acc: 0.7875
48000/48000 - 175s - loss: 1.1870 - accuracy: 0.5575 - val_loss: 0.6190 - val_accuracy: 0.7875
Epoch 3/10
 -> id = 17  Epoch: 1   accuracy: 0.95533335  val_acc: 0.9605
48000/48000 - 176s - loss: 0.1677 - accuracy: 0.9553 - val_loss: 0.2152 - val_accuracy: 0.9605
Epoch 3/10
 -> id = 13  Epoch: 3   accuracy: 0.97641665  val_acc: 0.9705833
48000/48000 - 89s - loss: 0.0756 - accuracy: 0.9764 - val_loss: 0.1035 - val_accuracy: 0.9706
Epoch 5/10
 -> id = 10  Epoch: 4   accuracy: 0.973625  val_acc: 0.9644167
48000/48000 - 82s - loss: 0.0932 - accuracy: 0.9736 - val_loss: 0.1173 - val_accuracy: 0.9644
Epoch 6/10
 -> id = 0  Epoch: 4   accuracy: 0.98097914  val_acc: 0.9766667
48000/48000 - 78s - loss: 0.0602 - accuracy: 0.9810 - val_loss: 0.0777 - val_accuracy: 0.9767
Epoch 6/10
 -> id = 1  Epoch: 4   accuracy: 0.9808125  val_acc: 0.97491664
48000/48000 - 84s - loss: 0.0583 - accuracy: 0.9808 - val_loss: 0.0822 - val_accuracy: 0.9749
Epoch 6/10
 -> id = 16  Epoch: 4   accuracy: 0.9727708  val_acc: 0.96725
48000/48000 - 87s - loss: 0.0914 - accuracy: 0.9728 - val_loss: 0.1120 - val_accuracy: 0.9672
Epoch 6/10
 -> id = 4  Epoch: 4   accuracy: 0.98160416  val_acc: 0.977
48000/48000 - 82s - loss: 0.0586 - accuracy: 0.9816 - val_loss: 0.0760 - val_accuracy: 0.9770
Epoch 6/10
 -> id = 11  Epoch: 2   accuracy: 0.9670417  val_acc: 0.94741666
48000/48000 - 138s - loss: 0.1100 - accuracy: 0.9670 - val_loss: 0.1846 - val_accuracy: 0.9474
Epoch 4/10
 -> id = 15  Epoch: 3   accuracy: 0.982375  val_acc: 0.968
48000/48000 - 109s - loss: 0.0584 - accuracy: 0.9824 - val_loss: 0.1312 - val_accuracy: 0.9680
Epoch 5/10
 -> id = 18  Epoch: 3   accuracy: 0.97054166  val_acc: 0.97658336
48000/48000 - 104s - loss: 0.1025 - accuracy: 0.9705 - val_loss: 0.1016 - val_accuracy: 0.9766
Epoch 5/10
 -> id = 7  Epoch: 4   accuracy: 0.96475  val_acc: 0.96283334
48000/48000 - 101s - loss: 0.1183 - accuracy: 0.9647 - val_loss: 0.1237 - val_accuracy: 0.9628
Epoch 6/10
 -> id = 9  Epoch: 3   accuracy: 0.9900417  val_acc: 0.97225
48000/48000 - 109s - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.0923 - val_accuracy: 0.9722
Epoch 5/10
 -> id = 6  Epoch: 3   accuracy: 0.9616042  val_acc: 0.9619167
48000/48000 - 114s - loss: 0.1192 - accuracy: 0.9616 - val_loss: 0.1295 - val_accuracy: 0.9619
Epoch 5/10
 -> id = 3  Epoch: 4   accuracy: 0.97779167  val_acc: 0.97466666
48000/48000 - 98s - loss: 0.0713 - accuracy: 0.9778 - val_loss: 0.0829 - val_accuracy: 0.9747
Epoch 6/10
 -> id = 14  Epoch: 3   accuracy: 0.9743125  val_acc: 0.96716666
48000/48000 - 114s - loss: 0.0851 - accuracy: 0.9743 - val_loss: 0.1077 - val_accuracy: 0.9672
Epoch 5/10
 -> id = 0  Epoch: 5   accuracy: 0.9833958  val_acc: 0.9795
48000/48000 - 74s - loss: 0.0525 - accuracy: 0.9834 - val_loss: 0.0655 - val_accuracy: 0.9795
Epoch 7/10
 -> id = 19  Epoch: 2   accuracy: 0.9763333  val_acc: 0.97141665
48000/48000 - 151s - loss: 0.0817 - accuracy: 0.9763 - val_loss: 0.1014 - val_accuracy: 0.9714
Epoch 4/10
 -> id = 10  Epoch: 5   accuracy: 0.97975  val_acc: 0.96966666
48000/48000 - 92s - loss: 0.0747 - accuracy: 0.9797 - val_loss: 0.1024 - val_accuracy: 0.9697
Epoch 7/10
 -> id = 1  Epoch: 5   accuracy: 0.9832917  val_acc: 0.9776667
48000/48000 - 80s - loss: 0.0496 - accuracy: 0.9833 - val_loss: 0.0769 - val_accuracy: 0.9777
Epoch 7/10
 -> id = 13  Epoch: 4   accuracy: 0.982375  val_acc: 0.97433335
48000/48000 - 98s - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.0929 - val_accuracy: 0.9743
Epoch 6/10
 -> id = 8  Epoch: 2   accuracy: 0.681625  val_acc: 0.93916667
48000/48000 - 155s - loss: 1.3061 - accuracy: 0.6816 - val_loss: 1.0577 - val_accuracy: 0.9392
Epoch 4/10
 -> id = 4  Epoch: 5   accuracy: 0.98229164  val_acc: 0.9765
48000/48000 - 76s - loss: 0.0535 - accuracy: 0.9823 - val_loss: 0.0813 - val_accuracy: 0.9765
Epoch 7/10
 -> id = 5  Epoch: 3   accuracy: 0.9480208  val_acc: 0.9565833
48000/48000 - 127s - loss: 0.1828 - accuracy: 0.9480 - val_loss: 0.1577 - val_accuracy: 0.9566
Epoch 5/10
 -> id = 16  Epoch: 5   accuracy: 0.9785208  val_acc: 0.96541667
48000/48000 - 91s - loss: 0.0713 - accuracy: 0.9785 - val_loss: 0.1127 - val_accuracy: 0.9654
Epoch 7/10
 -> id = 2  Epoch: 2   accuracy: 0.948875  val_acc: 0.9630833
48000/48000 - 167s - loss: 0.1732 - accuracy: 0.9489 - val_loss: 0.1321 - val_accuracy: 0.9631
Epoch 4/10
 -> id = 7  Epoch: 5   accuracy: 0.9698542  val_acc: 0.96425
48000/48000 - 90s - loss: 0.0983 - accuracy: 0.9699 - val_loss: 0.1205 - val_accuracy: 0.9643
Epoch 7/10
 -> id = 12  Epoch: 2   accuracy: 0.6135625  val_acc: 0.72216666
48000/48000 - 173s - loss: 1.0554 - accuracy: 0.6136 - val_loss: 0.6931 - val_accuracy: 0.7222
Epoch 4/10
 -> id = 18  Epoch: 4   accuracy: 0.97577083  val_acc: 0.97391665
48000/48000 - 104s - loss: 0.0843 - accuracy: 0.9758 - val_loss: 0.1175 - val_accuracy: 0.9739
Epoch 6/10
 -> id = 17  Epoch: 2   accuracy: 0.9701875  val_acc: 0.968
48000/48000 - 171s - loss: 0.1112 - accuracy: 0.9702 - val_loss: 0.1158 - val_accuracy: 0.9680
Epoch 4/10
 -> id = 9  Epoch: 4   accuracy: 0.99214584  val_acc: 0.9738333
48000/48000 - 97s - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.0938 - val_accuracy: 0.9738
Epoch 6/10
 -> id = 15  Epoch: 4   accuracy: 0.9859167  val_acc: 0.96975
48000/48000 - 112s - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.1322 - val_accuracy: 0.9697
Epoch 6/10
 -> id = 0  Epoch: 6   accuracy: 0.98454165  val_acc: 0.97908336
48000/48000 - 81s - loss: 0.0479 - accuracy: 0.9845 - val_loss: 0.0705 - val_accuracy: 0.9791
Epoch 8/10
 -> id = 3  Epoch: 5   accuracy: 0.98054165  val_acc: 0.9765
48000/48000 - 95s - loss: 0.0617 - accuracy: 0.9805 - val_loss: 0.0755 - val_accuracy: 0.9765
Epoch 7/10
 -> id = 1  Epoch: 6   accuracy: 0.98464584  val_acc: 0.9784167
48000/48000 - 83s - loss: 0.0470 - accuracy: 0.9846 - val_loss: 0.0765 - val_accuracy: 0.9784
Epoch 8/10
 -> id = 6  Epoch: 4   accuracy: 0.96775  val_acc: 0.9701667
48000/48000 - 109s - loss: 0.1011 - accuracy: 0.9678 - val_loss: 0.1037 - val_accuracy: 0.9702
Epoch 6/10
 -> id = 4  Epoch: 6   accuracy: 0.985375  val_acc: 0.97833335
48000/48000 - 80s - loss: 0.0465 - accuracy: 0.9854 - val_loss: 0.0750 - val_accuracy: 0.9783
Epoch 8/10
 -> id = 10  Epoch: 6   accuracy: 0.98333335  val_acc: 0.9715833
48000/48000 - 92s - loss: 0.0602 - accuracy: 0.9833 - val_loss: 0.0943 - val_accuracy: 0.9716
Epoch 8/10
 -> id = 14  Epoch: 4   accuracy: 0.9814375  val_acc: 0.97316664
48000/48000 - 115s - loss: 0.0609 - accuracy: 0.9814 - val_loss: 0.0947 - val_accuracy: 0.9732
Epoch 6/10
 -> id = 13  Epoch: 5   accuracy: 0.9864375  val_acc: 0.97541666
48000/48000 - 94s - loss: 0.0427 - accuracy: 0.9864 - val_loss: 0.0904 - val_accuracy: 0.9754
Epoch 7/10
 -> id = 11  Epoch: 3   accuracy: 0.974625  val_acc: 0.92791665
48000/48000 - 143s - loss: 0.0826 - accuracy: 0.9746 - val_loss: 0.2828 - val_accuracy: 0.9279
Epoch 5/10
 -> id = 16  Epoch: 6   accuracy: 0.9814583  val_acc: 0.96708333
48000/48000 - 99s - loss: 0.0595 - accuracy: 0.9815 - val_loss: 0.1120 - val_accuracy: 0.9671
Epoch 8/10
 -> id = 5  Epoch: 4   accuracy: 0.959125  val_acc: 0.95608336
48000/48000 - 134s - loss: 0.1450 - accuracy: 0.9591 - val_loss: 0.1553 - val_accuracy: 0.9561
Epoch 6/10
 -> id = 0  Epoch: 7   accuracy: 0.9855833  val_acc: 0.97675
48000/48000 - 81s - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.0780 - val_accuracy: 0.9768
Epoch 9/10
 -> id = 7  Epoch: 6   accuracy: 0.97410417  val_acc: 0.96675
48000/48000 - 98s - loss: 0.0848 - accuracy: 0.9741 - val_loss: 0.1105 - val_accuracy: 0.9668
Epoch 8/10
 -> id = 19  Epoch: 3   accuracy: 0.9819375  val_acc: 0.9711667
48000/48000 - 161s - loss: 0.0580 - accuracy: 0.9819 - val_loss: 0.1216 - val_accuracy: 0.9712
Epoch 5/10
 -> id = 8  Epoch: 3   accuracy: 0.69083333  val_acc: 0.94708335
48000/48000 - 155s - loss: 1.1306 - accuracy: 0.6908 - val_loss: 0.8518 - val_accuracy: 0.9471
Epoch 5/10
 -> id = 18  Epoch: 5   accuracy: 0.98085415  val_acc: 0.97725
48000/48000 - 104s - loss: 0.0704 - accuracy: 0.9809 - val_loss: 0.0932 - val_accuracy: 0.9772
Epoch 7/10
 -> id = 1  Epoch: 7   accuracy: 0.9866667  val_acc: 0.9803333
48000/48000 - 84s - loss: 0.0418 - accuracy: 0.9867 - val_loss: 0.0672 - val_accuracy: 0.9803
Epoch 9/10
 -> id = 3  Epoch: 6   accuracy: 0.98191667  val_acc: 0.9785
48000/48000 - 96s - loss: 0.0558 - accuracy: 0.9819 - val_loss: 0.0755 - val_accuracy: 0.9785
Epoch 8/10
 -> id = 4  Epoch: 7   accuracy: 0.98560417  val_acc: 0.9799167
48000/48000 - 91s - loss: 0.0446 - accuracy: 0.9856 - val_loss: 0.0710 - val_accuracy: 0.9799
Epoch 9/10
 -> id = 15  Epoch: 5   accuracy: 0.9871042  val_acc: 0.97525
48000/48000 - 111s - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.1105 - val_accuracy: 0.9753
Epoch 7/10
 -> id = 9  Epoch: 5   accuracy: 0.99335414  val_acc: 0.97066665
48000/48000 - 116s - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.1058 - val_accuracy: 0.9707
Epoch 7/10
 -> id = 10  Epoch: 7   accuracy: 0.98683333  val_acc: 0.97375
48000/48000 - 96s - loss: 0.0490 - accuracy: 0.9868 - val_loss: 0.0890 - val_accuracy: 0.9737
Epoch 9/10
 -> id = 2  Epoch: 3   accuracy: 0.95816666  val_acc: 0.9715833
48000/48000 - 175s - loss: 0.1394 - accuracy: 0.9582 - val_loss: 0.1015 - val_accuracy: 0.9716
Epoch 5/10
 -> id = 13  Epoch: 6   accuracy: 0.99102086  val_acc: 0.97566664
48000/48000 - 106s - loss: 0.0292 - accuracy: 0.9910 - val_loss: 0.0853 - val_accuracy: 0.9757
Epoch 8/10
 -> id = 6  Epoch: 5   accuracy: 0.9740833  val_acc: 0.9640833
48000/48000 - 118s - loss: 0.0798 - accuracy: 0.9741 - val_loss: 0.1331 - val_accuracy: 0.9641
Epoch 7/10
 -> id = 14  Epoch: 5   accuracy: 0.9859167  val_acc: 0.97333336
48000/48000 - 120s - loss: 0.0465 - accuracy: 0.9859 - val_loss: 0.0955 - val_accuracy: 0.9733
Epoch 7/10
 -> id = 16  Epoch: 7   accuracy: 0.98627084  val_acc: 0.9709167
48000/48000 - 98s - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.0949 - val_accuracy: 0.9709
Epoch 9/10
 -> id = 0  Epoch: 8   accuracy: 0.9865  val_acc: 0.97866666
48000/48000 - 80s - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0724 - val_accuracy: 0.9787
Epoch 10/10
 -> id = 12  Epoch: 3   accuracy: 0.6498542  val_acc: 0.8315833
48000/48000 - 178s - loss: 0.9629 - accuracy: 0.6499 - val_loss: 0.4883 - val_accuracy: 0.8316
Epoch 5/10
 -> id = 11  Epoch: 4   accuracy: 0.98066664  val_acc: 0.95275
48000/48000 - 144s - loss: 0.0630 - accuracy: 0.9807 - val_loss: 0.1884 - val_accuracy: 0.9528
Epoch 6/10
 -> id = 1  Epoch: 8   accuracy: 0.98725  val_acc: 0.9785
48000/48000 - 78s - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.0755 - val_accuracy: 0.9785
Epoch 10/10
 -> id = 17  Epoch: 3   accuracy: 0.9764792  val_acc: 0.96891665
48000/48000 - 183s - loss: 0.0851 - accuracy: 0.9765 - val_loss: 0.1116 - val_accuracy: 0.9689
Epoch 5/10
 -> id = 7  Epoch: 7   accuracy: 0.97847915  val_acc: 0.9709167
48000/48000 - 98s - loss: 0.0715 - accuracy: 0.9785 - val_loss: 0.0988 - val_accuracy: 0.9709
Epoch 9/10
 -> id = 4  Epoch: 8   accuracy: 0.987625  val_acc: 0.9805
48000/48000 - 81s - loss: 0.0391 - accuracy: 0.9876 - val_loss: 0.0714 - val_accuracy: 0.9805
Epoch 10/10
 -> id = 3  Epoch: 7   accuracy: 0.9841875  val_acc: 0.9773333
48000/48000 - 95s - loss: 0.0488 - accuracy: 0.9842 - val_loss: 0.0771 - val_accuracy: 0.9773
Epoch 9/10
 -> id = 10  Epoch: 8   accuracy: 0.98972917  val_acc: 0.97391665
48000/48000 - 82s - loss: 0.0396 - accuracy: 0.9897 - val_loss: 0.0864 - val_accuracy: 0.9739
Epoch 10/10
 -> id = 18  Epoch: 6   accuracy: 0.9828542  val_acc: 0.9770833
48000/48000 - 101s - loss: 0.0602 - accuracy: 0.9829 - val_loss: 0.0897 - val_accuracy: 0.9771
Epoch 8/10
 -> id = 5  Epoch: 5   accuracy: 0.96522915  val_acc: 0.9661667
48000/48000 - 130s - loss: 0.1206 - accuracy: 0.9652 - val_loss: 0.1225 - val_accuracy: 0.9662
Epoch 7/10
 -> id = 9  Epoch: 6   accuracy: 0.9938958  val_acc: 0.97391665
48000/48000 - 108s - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.0982 - val_accuracy: 0.9739
Epoch 8/10
 -> id = 15  Epoch: 6   accuracy: 0.9890625  val_acc: 0.9715
48000/48000 - 112s - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.1263 - val_accuracy: 0.9715
Epoch 8/10
 -> id = 16  Epoch: 8   accuracy: 0.9895625  val_acc: 0.97391665
48000/48000 - 91s - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.0938 - val_accuracy: 0.9739
Epoch 10/10
 -> id = 13  Epoch: 7   accuracy: 0.9922708  val_acc: 0.97508335
48000/48000 - 103s - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0950 - val_accuracy: 0.9751
Epoch 9/10
 -> id = 19  Epoch: 4   accuracy: 0.984625  val_acc: 0.9719167
48000/48000 - 154s - loss: 0.0512 - accuracy: 0.9846 - val_loss: 0.1184 - val_accuracy: 0.9719
Epoch 6/10
 -> id = 8  Epoch: 4   accuracy: 0.6972708  val_acc: 0.95358336
48000/48000 - 154s - loss: 1.0228 - accuracy: 0.6973 - val_loss: 0.7075 - val_accuracy: 0.9536
Epoch 6/10
 -> id = 6  Epoch: 6   accuracy: 0.978125  val_acc: 0.972
48000/48000 - 111s - loss: 0.0680 - accuracy: 0.9781 - val_loss: 0.0984 - val_accuracy: 0.9720
Epoch 8/10
 -> id = 0  Epoch: 9   accuracy: 0.98672915  val_acc: 0.9784167
48000/48000 - 85s - loss: 0.0399 - accuracy: 0.9867 - val_loss: 0.0743 - val_accuracy: 0.9784
 -> id = 1  Epoch: 9   accuracy: 0.98716664  val_acc: 0.9805
48000/48000 - 83s - loss: 0.0373 - accuracy: 0.9872 - val_loss: 0.0741 - val_accuracy: 0.9805
 -> id = 14  Epoch: 6   accuracy: 0.99070835  val_acc: 0.97175
48000/48000 - 115s - loss: 0.0327 - accuracy: 0.9907 - val_loss: 0.0918 - val_accuracy: 0.9718
Epoch 8/10
 -> id = 4  Epoch: 9   accuracy: 0.987625  val_acc: 0.97933334
48000/48000 - 82s - loss: 0.0374 - accuracy: 0.9876 - val_loss: 0.0726 - val_accuracy: 0.9793
 -> id = 7  Epoch: 8   accuracy: 0.98066664  val_acc: 0.9709167
48000/48000 - 91s - loss: 0.0622 - accuracy: 0.9807 - val_loss: 0.0974 - val_accuracy: 0.9709
Epoch 10/10
 -> id = 10  Epoch: 9   accuracy: 0.9925  val_acc: 0.97466666
48000/48000 - 85s - loss: 0.0320 - accuracy: 0.9925 - val_loss: 0.0829 - val_accuracy: 0.9747
 -> id = 3  Epoch: 8   accuracy: 0.98539585  val_acc: 0.97891665
48000/48000 - 89s - loss: 0.0453 - accuracy: 0.9854 - val_loss: 0.0745 - val_accuracy: 0.9789
Epoch 10/10
 -> id = 18  Epoch: 7   accuracy: 0.98629165  val_acc: 0.97816664
48000/48000 - 98s - loss: 0.0504 - accuracy: 0.9863 - val_loss: 0.1005 - val_accuracy: 0.9782
Epoch 9/10
 -> id = 2  Epoch: 4   accuracy: 0.96566665  val_acc: 0.9705833
48000/48000 - 168s - loss: 0.1186 - accuracy: 0.9657 - val_loss: 0.1040 - val_accuracy: 0.9706
Epoch 6/10
 -> id = 11  Epoch: 5   accuracy: 0.9830625  val_acc: 0.75575
48000/48000 - 132s - loss: 0.0528 - accuracy: 0.9831 - val_loss: 1.0824 - val_accuracy: 0.7558
Epoch 7/10
 -> id = 9  Epoch: 7   accuracy: 0.9946667  val_acc: 0.97491664
48000/48000 - 94s - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0971 - val_accuracy: 0.9749
Epoch 9/10
 -> id = 15  Epoch: 7   accuracy: 0.99052083  val_acc: 0.97175
48000/48000 - 98s - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.1256 - val_accuracy: 0.9718
Epoch 9/10
 -> id = 16  Epoch: 9   accuracy: 0.9918333  val_acc: 0.9751667
48000/48000 - 86s - loss: 0.0281 - accuracy: 0.9918 - val_loss: 0.0856 - val_accuracy: 0.9752
 -> id = 5  Epoch: 6   accuracy: 0.97120833  val_acc: 0.96958333
 -> id = 13  Epoch: 8   accuracy: 0.99354166  val_acc: 0.9781666448000/48000 - 118s - loss: 0.0996 - accuracy: 0.9712 - val_loss: 0.1163 - val_accuracy: 0.9696

Epoch 8/10
48000/48000 - 88s - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0889 - val_accuracy: 0.9782
Epoch 10/10
 -> id = 12  Epoch: 4   accuracy: 0.66772914  val_acc: 0.847
48000/48000 - 170s - loss: 0.9157 - accuracy: 0.6677 - val_loss: 0.4808 - val_accuracy: 0.8470
Epoch 6/10
 -> id = 17  Epoch: 4   accuracy: 0.98152083  val_acc: 0.97175
48000/48000 - 170s - loss: 0.0677 - accuracy: 0.9815 - val_loss: 0.1061 - val_accuracy: 0.9718
Epoch 6/10
 -> id = 6  Epoch: 7   accuracy: 0.98095834  val_acc: 0.9730833
48000/48000 - 100s - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0981 - val_accuracy: 0.9731
Epoch 9/10
 -> id = 7  Epoch: 9   accuracy: 0.9832917  val_acc: 0.97108334
48000/48000 - 76s - loss: 0.0531 - accuracy: 0.9833 - val_loss: 0.0940 - val_accuracy: 0.9711
 -> id = 3  Epoch: 9   accuracy: 0.986125  val_acc: 0.9795833
48000/48000 - 72s - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.0724 - val_accuracy: 0.9796
 -> id = 14  Epoch: 7   accuracy: 0.9921042  val_acc: 0.97358334
48000/48000 - 100s - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.0900 - val_accuracy: 0.9736
Epoch 9/10
 -> id = 19  Epoch: 5   accuracy: 0.98627084  val_acc: 0.9776667
48000/48000 - 142s - loss: 0.0460 - accuracy: 0.9863 - val_loss: 0.1046 - val_accuracy: 0.9777
Epoch 7/10
 -> id = 8  Epoch: 5   accuracy: 0.698875  val_acc: 0.95058334
48000/48000 - 141s - loss: 0.9626 - accuracy: 0.6989 - val_loss: 0.6230 - val_accuracy: 0.9506
Epoch 7/10
 -> id = 18  Epoch: 8   accuracy: 0.986625  val_acc: 0.97775
48000/48000 - 89s - loss: 0.0470 - accuracy: 0.9866 - val_loss: 0.1041 - val_accuracy: 0.9778
Epoch 10/10
 -> id = 9  Epoch: 8   accuracy: 0.9952083  val_acc: 0.9755
48000/48000 - 84s - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.1054 - val_accuracy: 0.9755
Epoch 10/10
 -> id = 13  Epoch: 9   accuracy: 0.9940417  val_acc: 0.97683334
48000/48000 - 75s - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0959 - val_accuracy: 0.9768
 -> id = 15  Epoch: 8   accuracy: 0.9915417  val_acc: 0.97241664
48000/48000 - 90s - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.1387 - val_accuracy: 0.9724
Epoch 10/10
 -> id = 5  Epoch: 7   accuracy: 0.9759375  val_acc: 0.9658333
48000/48000 - 104s - loss: 0.0835 - accuracy: 0.9759 - val_loss: 0.1231 - val_accuracy: 0.9658
Epoch 9/10
 -> id = 11  Epoch: 6   accuracy: 0.985875  val_acc: 0.92975
48000/48000 - 124s - loss: 0.0437 - accuracy: 0.9859 - val_loss: 0.3107 - val_accuracy: 0.9298
Epoch 8/10
 -> id = 6  Epoch: 8   accuracy: 0.9828125  val_acc: 0.9766667
48000/48000 - 88s - loss: 0.0541 - accuracy: 0.9828 - val_loss: 0.0907 - val_accuracy: 0.9767
Epoch 10/10
 -> id = 14  Epoch: 8   accuracy: 0.9947917  val_acc: 0.97575
48000/48000 - 90s - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.0778 - val_accuracy: 0.9758
Epoch 10/10
 -> id = 2  Epoch: 5   accuracy: 0.96977085  val_acc: 0.97391665
48000/48000 - 152s - loss: 0.1038 - accuracy: 0.9698 - val_loss: 0.0892 - val_accuracy: 0.9739
Epoch 7/10
 -> id = 18  Epoch: 9   accuracy: 0.98802084  val_acc: 0.97775
48000/48000 - 83s - loss: 0.0410 - accuracy: 0.9880 - val_loss: 0.1112 - val_accuracy: 0.9778
 -> id = 9  Epoch: 9   accuracy: 0.994625  val_acc: 0.97866666
48000/48000 - 79s - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.0830 - val_accuracy: 0.9787
 -> id = 15  Epoch: 9   accuracy: 0.992625  val_acc: 0.9774167
48000/48000 - 78s - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.1125 - val_accuracy: 0.9774
 -> id = 12  Epoch: 5   accuracy: 0.6791875  val_acc: 0.82383335
48000/48000 - 155s - loss: 0.8920 - accuracy: 0.6792 - val_loss: 0.5198 - val_accuracy: 0.8238
Epoch 7/10
 -> id = 17  Epoch: 5   accuracy: 0.98483336  val_acc: 0.96933335
48000/48000 - 155s - loss: 0.0564 - accuracy: 0.9848 - val_loss: 0.1221 - val_accuracy: 0.9693
Epoch 7/10
 -> id = 19  Epoch: 6   accuracy: 0.98879164  val_acc: 0.97291666
48000/48000 - 124s - loss: 0.0374 - accuracy: 0.9888 - val_loss: 0.1288 - val_accuracy: 0.9729
Epoch 8/10
 -> id = 6  Epoch: 9   accuracy: 0.98485416  val_acc: 0.97783333
48000/48000 - 74s - loss: 0.0445 - accuracy: 0.9849 - val_loss: 0.0883 - val_accuracy: 0.9778
 -> id = 8  Epoch: 6   accuracy: 0.7020208  val_acc: 0.95558333
48000/48000 - 126s - loss: 0.9175 - accuracy: 0.7020 - val_loss: 0.5369 - val_accuracy: 0.9556
Epoch 8/10
 -> id = 5  Epoch: 8   accuracy: 0.9784375  val_acc: 0.97141665
48000/48000 - 89s - loss: 0.0729 - accuracy: 0.9784 - val_loss: 0.1041 - val_accuracy: 0.9714
Epoch 10/10
 -> id = 14  Epoch: 9   accuracy: 0.9963958  val_acc: 0.97683334
48000/48000 - 71s - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.0800 - val_accuracy: 0.9768
 -> id = 11  Epoch: 7   accuracy: 0.9874167  val_acc: 0.94116664
48000/48000 - 106s - loss: 0.0412 - accuracy: 0.9874 - val_loss: 0.2473 - val_accuracy: 0.9412
Epoch 9/10
 -> id = 2  Epoch: 6   accuracy: 0.9736875  val_acc: 0.97641665
48000/48000 - 123s - loss: 0.0914 - accuracy: 0.9737 - val_loss: 0.0847 - val_accuracy: 0.9764
Epoch 8/10
 -> id = 5  Epoch: 9   accuracy: 0.98141664  val_acc: 0.97241664
48000/48000 - 72s - loss: 0.0634 - accuracy: 0.9814 - val_loss: 0.0998 - val_accuracy: 0.9724
 -> id = 19  Epoch: 7   accuracy: 0.99189585  val_acc: 0.9770833
48000/48000 - 97s - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.1063 - val_accuracy: 0.9771
Epoch 9/10
 -> id = 8  Epoch: 7   accuracy: 0.705625  val_acc: 0.9595
48000/48000 - 99s - loss: 0.8879 - accuracy: 0.7056 - val_loss: 0.4755 - val_accuracy: 0.9595
Epoch 9/10
 -> id = 12  Epoch: 6   accuracy: 0.69120836  val_acc: 0.72108334
48000/48000 - 122s - loss: 0.8720 - accuracy: 0.6912 - val_loss: 0.7003 - val_accuracy: 0.7211
Epoch 8/10
 -> id = 11  Epoch: 8   accuracy: 0.989125  val_acc: 0.9095
48000/48000 - 86s - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.4276 - val_accuracy: 0.9095
Epoch 10/10
 -> id = 17  Epoch: 6   accuracy: 0.9873958  val_acc: 0.9690833
48000/48000 - 121s - loss: 0.0455 - accuracy: 0.9874 - val_loss: 0.1184 - val_accuracy: 0.9691
Epoch 8/10
 -> id = 2  Epoch: 7   accuracy: 0.975375  val_acc: 0.9755833
48000/48000 - 96s - loss: 0.0822 - accuracy: 0.9754 - val_loss: 0.0921 - val_accuracy: 0.9756
Epoch 9/10
 -> id = 19  Epoch: 8   accuracy: 0.9915625  val_acc: 0.97325
48000/48000 - 83s - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.1288 - val_accuracy: 0.9732
Epoch 10/10
 -> id = 8  Epoch: 8   accuracy: 0.7099792  val_acc: 0.9601667
48000/48000 - 85s - loss: 0.8600 - accuracy: 0.7100 - val_loss: 0.4288 - val_accuracy: 0.9602
Epoch 10/10
 -> id = 11  Epoch: 9   accuracy: 0.989875  val_acc: 0.93591666
48000/48000 - 79s - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.2957 - val_accuracy: 0.9359
 -> id = 12  Epoch: 7   accuracy: 0.7095  val_acc: 0.7905833
48000/48000 - 105s - loss: 0.8433 - accuracy: 0.7095 - val_loss: 0.5922 - val_accuracy: 0.7906
Epoch 9/10
 -> id = 17  Epoch: 7   accuracy: 0.98908335  val_acc: 0.9725
48000/48000 - 104s - loss: 0.0385 - accuracy: 0.9891 - val_loss: 0.1172 - val_accuracy: 0.9725
Epoch 9/10
 -> id = 2  Epoch: 8   accuracy: 0.9771042  val_acc: 0.97541666
48000/48000 - 85s - loss: 0.0739 - accuracy: 0.9771 - val_loss: 0.0852 - val_accuracy: 0.9754
Epoch 10/10
 -> id = 19  Epoch: 9   accuracy: 0.9925  val_acc: 0.9776667
48000/48000 - 74s - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.1164 - val_accuracy: 0.9777
 -> id = 8  Epoch: 9   accuracy: 0.714625  val_acc: 0.9583333
48000/48000 - 71s - loss: 0.8389 - accuracy: 0.7146 - val_loss: 0.4040 - val_accuracy: 0.9583
 -> id = 12  Epoch: 8   accuracy: 0.71729165  val_acc: 0.85158336
48000/48000 - 74s - loss: 0.8214 - accuracy: 0.7173 - val_loss: 0.5324 - val_accuracy: 0.8516
Epoch 10/10
 -> id = 17  Epoch: 8   accuracy: 0.9904375  val_acc: 0.97275
48000/48000 - 72s - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.1160 - val_accuracy: 0.9728
Epoch 10/10
 -> id = 2  Epoch: 9   accuracy: 0.9801667  val_acc: 0.97608334
48000/48000 - 54s - loss: 0.0654 - accuracy: 0.9802 - val_loss: 0.0897 - val_accuracy: 0.9761
 -> id = 12  Epoch: 9   accuracy: 0.72702086  val_acc: 0.83925
48000/48000 - 41s - loss: 0.8082 - accuracy: 0.7270 - val_loss: 0.5378 - val_accuracy: 0.8393
 -> id = 17  Epoch: 9   accuracy: 0.992125  val_acc: 0.97433335
48000/48000 - 38s - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.1055 - val_accuracy: 0.9743
 id = 1  val_accuracy = 0.9804999828338623
 id = 3  val_accuracy = 0.9795833230018616
 id = 4  val_accuracy = 0.9793333411216736
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  3   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Model: "model_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_227 (Dense)            (None, 1108)              869780
_________________________________________________________________
activation_166 (Activation)  (None, 1108)              0
_________________________________________________________________
dropout_83 (Dropout)         (None, 1108)              0
_________________________________________________________________
batch_normalization_81 (Batc (None, 1108)              4432
_________________________________________________________________
dense_228 (Dense)            (None, 10)                11090
=================================================================
Total params: 885,302
Trainable params: 883,086
Non-trainable params: 2,216
_________________________________________________________________
None
Model: "model_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_229 (Dense)            (None, 585)               459225
_________________________________________________________________
activation_167 (Activation)  (None, 585)               0
_________________________________________________________________
dropout_84 (Dropout)         (None, 585)               0
_________________________________________________________________
batch_normalization_82 (Batc (None, 585)               2340
_________________________________________________________________
dense_230 (Dense)            (None, 10)                5860
=================================================================
Total params: 467,425
Trainable params: 466,255
Non-trainable params: 1,170
_________________________________________________________________
None
Model: "model_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_231 (Dense)            (None, 986)               774010
_________________________________________________________________
activation_168 (Activation)  (None, 986)               0
_________________________________________________________________
dropout_85 (Dropout)         (None, 986)               0
_________________________________________________________________
batch_normalization_83 (Batc (None, 986)               3944
_________________________________________________________________
dense_232 (Dense)            (None, 10)                9870
=================================================================
Total params: 787,824
Trainable params: 785,852
Non-trainable params: 1,972
_________________________________________________________________
None
Model: "model_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_233 (Dense)            (None, 1211)              950635
_________________________________________________________________
activation_169 (Activation)  (None, 1211)              0
_________________________________________________________________
dropout_86 (Dropout)         (None, 1211)              0
_________________________________________________________________
batch_normalization_84 (Batc (None, 1211)              4844
_________________________________________________________________
dense_234 (Dense)            (None, 10)                12120
=================================================================
Total params: 967,599
Trainable params: 965,177
Non-trainable params: 2,422
_________________________________________________________________
None
Model: "model_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_235 (Dense)            (None, 389)               305365
_________________________________________________________________
activation_170 (Activation)  (None, 389)               0
_________________________________________________________________
dropout_87 (Dropout)         (None, 389)               0
_________________________________________________________________
batch_normalization_85 (Batc (None, 389)               1556
_________________________________________________________________
dense_236 (Dense)            (None, 10)                3900
=================================================================
Total params: 310,821
Trainable params: 310,043
Non-trainable params: 778
_________________________________________________________________
None
Model: "model_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_237 (Dense)            (None, 1110)              871350
_________________________________________________________________
activation_171 (Activation)  (None, 1110)              0
_________________________________________________________________
batch_normalization_86 (Batc (None, 1110)              4440
_________________________________________________________________
dense_238 (Dense)            (None, 10)                11110
=================================================================
Total params: 886,900
Trainable params: 884,680
Non-trainable params: 2,220
_________________________________________________________________
None
Model: "model_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_239 (Dense)            (None, 1540)              1208900
_________________________________________________________________
activation_172 (Activation)  (None, 1540)              0
_________________________________________________________________
dropout_88 (Dropout)         (None, 1540)              0
_________________________________________________________________
batch_normalization_87 (Batc (None, 1540)              6160
_________________________________________________________________
dense_240 (Dense)            (None, 10)                15410
=================================================================
Total params: 1,230,470
Trainable params: 1,227,390
Non-trainable params: 3,080
_________________________________________________________________
None
Model: "model_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_241 (Dense)            (None, 310)               243350
_________________________________________________________________
activation_173 (Activation)  (None, 310)               0
_________________________________________________________________
dropout_89 (Dropout)         (None, 310)               0
_________________________________________________________________
dense_242 (Dense)            (None, 10)                3110
=================================================================
Total params: 246,460
Trainable params: 246,460
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_243 (Dense)            (None, 1840)              1444400
_________________________________________________________________
activation_174 (Activation)  (None, 1840)              0
_________________________________________________________________
dropout_90 (Dropout)         (None, 1840)              0
_________________________________________________________________
batch_normalization_88 (Batc (None, 1840)              7360
_________________________________________________________________
dense_244 (Dense)            (None, 10)                18410
=================================================================
Total params: 1,470,170
Trainable params: 1,466,490
Non-trainable params: 3,680
_________________________________________________________________
None
Model: "model_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_245 (Dense)            (None, 550)               431750
_________________________________________________________________
activation_175 (Activation)  (None, 550)               0
_________________________________________________________________
dropout_91 (Dropout)         (None, 550)               0
_________________________________________________________________
dense_246 (Dense)            (None, 10)                5510
=================================================================
Total params: 437,260
Trainable params: 437,260
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_247 (Dense)            (None, 1520)              1193200
_________________________________________________________________
activation_176 (Activation)  (None, 1520)              0
_________________________________________________________________
batch_normalization_89 (Batc (None, 1520)              6080
_________________________________________________________________
dense_248 (Dense)            (None, 10)                15210
=================================================================
Total params: 1,214,490
Trainable params: 1,211,450
Non-trainable params: 3,040
_________________________________________________________________
None
Model: "model_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_249 (Dense)            (None, 510)               400350
_________________________________________________________________
activation_177 (Activation)  (None, 510)               0
_________________________________________________________________
batch_normalization_90 (Batc (None, 510)               2040
_________________________________________________________________
dense_250 (Dense)            (None, 10)                5110
=================================================================
Total params: 407,500
Trainable params: 406,480
Non-trainable params: 1,020
_________________________________________________________________
None
Model: "model_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_251 (Dense)            (None, 370)               290450
_________________________________________________________________
activation_178 (Activation)  (None, 370)               0
_________________________________________________________________
dropout_92 (Dropout)         (None, 370)               0
_________________________________________________________________
batch_normalization_91 (Batc (None, 370)               1480
_________________________________________________________________
dense_252 (Dense)            (None, 10)                3710
=================================================================
Total params: 295,640
Trainable params: 294,900
Non-trainable params: 740
_________________________________________________________________
None
Model: "model_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_253 (Dense)            (None, 1610)              1263850
_________________________________________________________________
activation_179 (Activation)  (None, 1610)              0
_________________________________________________________________
dropout_93 (Dropout)         (None, 1610)              0
_________________________________________________________________
dense_254 (Dense)            (None, 10)                16110
=================================================================
Total params: 1,279,960
Trainable params: 1,279,960
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_255 (Dense)            (None, 1890)              1483650
_________________________________________________________________
activation_180 (Activation)  (None, 1890)              0
_________________________________________________________________
dropout_94 (Dropout)         (None, 1890)              0
_________________________________________________________________
dense_256 (Dense)            (None, 10)                18910
=================================================================
Total params: 1,502,560
Trainable params: 1,502,560
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_257 (Dense)            (None, 120)               94200
_________________________________________________________________
activation_181 (Activation)  (None, 120)               0
_________________________________________________________________
dropout_95 (Dropout)         (None, 120)               0
_________________________________________________________________
batch_normalization_92 (Batc (None, 120)               480
_________________________________________________________________
dense_258 (Dense)            (None, 10)                1210
=================================================================
Total params: 95,890
Trainable params: 95,650
Non-trainable params: 240
_________________________________________________________________
None
Model: "model_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_259 (Dense)            (None, 1260)              989100
_________________________________________________________________
activation_182 (Activation)  (None, 1260)              0
_________________________________________________________________
dropout_96 (Dropout)         (None, 1260)              0
_________________________________________________________________
batch_normalization_93 (Batc (None, 1260)              5040
_________________________________________________________________
dense_260 (Dense)            (None, 10)                12610
=================================================================
Total params: 1,006,750
Trainable params: 1,004,230
Non-trainable params: 2,520
_________________________________________________________________
None
Model: "model_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_261 (Dense)            (None, 410)               321850
_________________________________________________________________
activation_183 (Activation)  (None, 410)               0
_________________________________________________________________
dropout_97 (Dropout)         (None, 410)               0
_________________________________________________________________
dense_262 (Dense)            (None, 10)                4110
=================================================================
Total params: 325,960
Trainable params: 325,960
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_263 (Dense)            (None, 170)               133450
_________________________________________________________________
activation_184 (Activation)  (None, 170)               0
_________________________________________________________________
dropout_98 (Dropout)         (None, 170)               0
_________________________________________________________________
batch_normalization_94 (Batc (None, 170)               680
_________________________________________________________________
dense_264 (Dense)            (None, 10)                1710
=================================================================
Total params: 135,840
Trainable params: 135,500
Non-trainable params: 340
_________________________________________________________________
None
Model: "model_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_265 (Dense)            (None, 1630)              1279550
_________________________________________________________________
activation_185 (Activation)  (None, 1630)              0
_________________________________________________________________
dropout_99 (Dropout)         (None, 1630)              0
_________________________________________________________________
dense_266 (Dense)            (None, 10)                16310
=================================================================
Total params: 1,295,860
Trainable params: 1,295,860
Non-trainable params: 0
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesEpoch 1/10

Train on 48000 samples, validate on 12000 samples
Epoch 1/10Epoch 1/10
Train on 48000 samples, validate on 12000 samples

Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples

Epoch 1/10
Epoch 1/10
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samplesEpoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples

Epoch 1/10
Epoch 1/10
 -> id = 17  Epoch: 0   accuracy: 0.8900625  val_acc: 0.93325
48000/48000 - 36s - loss: 0.3755 - accuracy: 0.8901 - val_loss: 0.2443 - val_accuracy: 0.9333
Epoch 2/10
 -> id = 7  Epoch: 0   accuracy: 0.50514585  val_acc: 0.7895
48000/48000 - 38s - loss: 2.0020 - accuracy: 0.5051 - val_loss: 1.6440 - val_accuracy: 0.7895
Epoch 2/10
 -> id = 13  Epoch: 0   accuracy: 0.85985416  val_acc: 0.917
48000/48000 - 42s - loss: 0.4824 - accuracy: 0.8599 - val_loss: 0.2896 - val_accuracy: 0.9170
Epoch 2/10
 -> id = 9  Epoch: 0   accuracy: 0.83164585  val_acc: 0.9125
48000/48000 - 43s - loss: 0.5859 - accuracy: 0.8316 - val_loss: 0.3020 - val_accuracy: 0.9125
Epoch 2/10
 -> id = 19  Epoch: 0   accuracy: 0.8679375  val_acc: 0.9245
48000/48000 - 43s - loss: 0.4398 - accuracy: 0.8679 - val_loss: 0.2673 - val_accuracy: 0.9245
 -> id = 14  Epoch: 0   accuracy: 0.8970625  val_acc: 0.93133336Epoch 2/10

48000/48000 - 44s - loss: 0.3477 - accuracy: 0.8971 - val_loss: 0.2401 - val_accuracy: 0.9313
Epoch 2/10
 -> id = 18  Epoch: 0   accuracy: 0.89275  val_acc: 0.9561667
48000/48000 - 46s - loss: 0.3535 - accuracy: 0.8928 - val_loss: 0.1934 - val_accuracy: 0.9562
Epoch 2/10
 -> id = 15  Epoch: 0   accuracy: 0.8041667  val_acc: 0.92258334
48000/48000 - 47s - loss: 0.6323 - accuracy: 0.8042 - val_loss: 0.3317 - val_accuracy: 0.9226
Epoch 2/10
 -> id = 11  Epoch: 0   accuracy: 0.885625  val_acc: 0.93575
48000/48000 - 50s - loss: 0.5018 - accuracy: 0.8856 - val_loss: 1.2417 - val_accuracy: 0.9358
Epoch 2/10
 -> id = 1  Epoch: 0   accuracy: 0.9139792  val_acc: 0.963
48000/48000 - 51s - loss: 0.2846 - accuracy: 0.9140 - val_loss: 0.1495 - val_accuracy: 0.9630
Epoch 2/10
 -> id = 12  Epoch: 0   accuracy: 0.87210417  val_acc: 0.9291667
48000/48000 - 52s - loss: 0.4259 - accuracy: 0.8721 - val_loss: 0.2539 - val_accuracy: 0.9292
Epoch 2/10
 -> id = 4  Epoch: 0   accuracy: 0.904  val_acc: 0.9601667
48000/48000 - 53s - loss: 0.3192 - accuracy: 0.9040 - val_loss: 0.1570 - val_accuracy: 0.9602
Epoch 2/10
 -> id = 5  Epoch: 0   accuracy: 0.9089375  val_acc: 0.94158334
48000/48000 - 55s - loss: 0.3309 - accuracy: 0.9089 - val_loss: 0.2135 - val_accuracy: 0.9416
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.89635414  val_acc: 0.93675
 -> id = 0  Epoch: 0   accuracy: 0.9244583  val_acc: 0.96358335
48000/48000 - 58s - loss: 0.2487 - accuracy: 0.9245 - val_loss: 0.1441 - val_accuracy: 0.9636
48000/48000 - 58s - loss: 0.3718 - accuracy: 0.8964 - val_loss: 0.2274 - val_accuracy: 0.9367
Epoch 2/10
Epoch 2/10
 -> id = 2  Epoch: 0   accuracy: 0.92235416  val_acc: 0.9636667
48000/48000 - 59s - loss: 0.2538 - accuracy: 0.9224 - val_loss: 0.1434 - val_accuracy: 0.9637
Epoch 2/10
 -> id = 10  Epoch: 0   accuracy: 0.874  val_acc: 0.93675
48000/48000 - 60s - loss: 0.5236 - accuracy: 0.8740 - val_loss: 1.2580 - val_accuracy: 0.9367
Epoch 2/10
 -> id = 3  Epoch: 0   accuracy: 0.926375  val_acc: 0.9635
48000/48000 - 62s - loss: 0.2461 - accuracy: 0.9264 - val_loss: 0.1419 - val_accuracy: 0.9635
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.8585  val_acc: 0.92433333
48000/48000 - 64s - loss: 0.4701 - accuracy: 0.8585 - val_loss: 0.2605 - val_accuracy: 0.9243
Epoch 2/10
 -> id = 17  Epoch: 1   accuracy: 0.9320625  val_acc: 0.94458336
48000/48000 - 28s - loss: 0.2330 - accuracy: 0.9321 - val_loss: 0.1978 - val_accuracy: 0.9446
Epoch 3/10
 -> id = 8  Epoch: 0   accuracy: 0.8557708  val_acc: 0.91275
48000/48000 - 67s - loss: 0.4962 - accuracy: 0.8558 - val_loss: 0.3028 - val_accuracy: 0.9128
Epoch 2/10
 -> id = 7  Epoch: 1   accuracy: 0.49016666  val_acc: 0.87091666
48000/48000 - 32s - loss: 1.5991 - accuracy: 0.4902 - val_loss: 1.3046 - val_accuracy: 0.8709
Epoch 3/10
 -> id = 15  Epoch: 1   accuracy: 0.901125  val_acc: 0.93541664
48000/48000 - 26s - loss: 0.3299 - accuracy: 0.9011 - val_loss: 0.2258 - val_accuracy: 0.9354
Epoch 3/10
 -> id = 18  Epoch: 1   accuracy: 0.954  val_acc: 0.9633333
48000/48000 - 27s - loss: 0.1585 - accuracy: 0.9540 - val_loss: 0.1292 - val_accuracy: 0.9633
Epoch 3/10
 -> id = 9  Epoch: 1   accuracy: 0.9101667  val_acc: 0.9285
48000/48000 - 33s - loss: 0.3077 - accuracy: 0.9102 - val_loss: 0.2506 - val_accuracy: 0.9285
Epoch 3/10
 -> id = 19  Epoch: 1   accuracy: 0.921625  val_acc: 0.93833333
48000/48000 - 34s - loss: 0.2642 - accuracy: 0.9216 - val_loss: 0.2153 - val_accuracy: 0.9383
Epoch 3/10
 -> id = 1  Epoch: 1   accuracy: 0.9604375  val_acc: 0.9705
48000/48000 - 30s - loss: 0.1307 - accuracy: 0.9604 - val_loss: 0.0972 - val_accuracy: 0.9705
Epoch 3/10
 -> id = 13  Epoch: 1   accuracy: 0.9139375  val_acc: 0.9328333
48000/48000 - 38s - loss: 0.2932 - accuracy: 0.9139 - val_loss: 0.2412 - val_accuracy: 0.9328
Epoch 3/10
 -> id = 14  Epoch: 1   accuracy: 0.9351042  val_acc: 0.952
48000/48000 - 39s - loss: 0.2216 - accuracy: 0.9351 - val_loss: 0.1724 - val_accuracy: 0.9520
Epoch 3/10
 -> id = 11  Epoch: 1   accuracy: 0.9597292  val_acc: 0.96358335
48000/48000 - 35s - loss: 0.1374 - accuracy: 0.9597 - val_loss: 0.1525 - val_accuracy: 0.9636
Epoch 3/10
 -> id = 4  Epoch: 1   accuracy: 0.95677084  val_acc: 0.9688333
48000/48000 - 33s - loss: 0.1476 - accuracy: 0.9568 - val_loss: 0.1050 - val_accuracy: 0.9688
Epoch 3/10
 -> id = 12  Epoch: 1   accuracy: 0.913125  val_acc: 0.938
48000/48000 - 35s - loss: 0.2915 - accuracy: 0.9131 - val_loss: 0.2157 - val_accuracy: 0.9380
Epoch 3/10
 -> id = 5  Epoch: 1   accuracy: 0.9548125  val_acc: 0.95608336
48000/48000 - 40s - loss: 0.1500 - accuracy: 0.9548 - val_loss: 0.1424 - val_accuracy: 0.9561
Epoch 3/10
 -> id = 6  Epoch: 1   accuracy: 0.936375  val_acc: 0.9540833
48000/48000 - 38s - loss: 0.2094 - accuracy: 0.9364 - val_loss: 0.1633 - val_accuracy: 0.9541
Epoch 3/10
 -> id = 17  Epoch: 2   accuracy: 0.9477292  val_acc: 0.95625
48000/48000 - 34s - loss: 0.1754 - accuracy: 0.9477 - val_loss: 0.1570 - val_accuracy: 0.9563
Epoch 4/10
 -> id = 0  Epoch: 1   accuracy: 0.965875  val_acc: 0.97075
48000/48000 - 42s - loss: 0.1122 - accuracy: 0.9659 - val_loss: 0.0927 - val_accuracy: 0.9707
Epoch 3/10
 -> id = 15  Epoch: 2   accuracy: 0.9226875  val_acc: 0.94825
48000/48000 - 27s - loss: 0.2602 - accuracy: 0.9227 - val_loss: 0.1839 - val_accuracy: 0.9482
Epoch 4/10
 -> id = 18  Epoch: 2   accuracy: 0.9658125  val_acc: 0.971
48000/48000 - 27s - loss: 0.1169 - accuracy: 0.9658 - val_loss: 0.1012 - val_accuracy: 0.9710
Epoch 4/10
 -> id = 2  Epoch: 1   accuracy: 0.9655  val_acc: 0.97033334
48000/48000 - 43s - loss: 0.1153 - accuracy: 0.9655 - val_loss: 0.0961 - val_accuracy: 0.9703
Epoch 3/10
 -> id = 7  Epoch: 2   accuracy: 0.54152083  val_acc: 0.90783334
48000/48000 - 32s - loss: 1.4206 - accuracy: 0.5415 - val_loss: 1.0868 - val_accuracy: 0.9078
Epoch 4/10
 -> id = 10  Epoch: 1   accuracy: 0.9642917  val_acc: 0.966
48000/48000 - 45s - loss: 0.1244 - accuracy: 0.9643 - val_loss: 0.1460 - val_accuracy: 0.9660
Epoch 3/10
 -> id = 3  Epoch: 1   accuracy: 0.96622914  val_acc: 0.97025
48000/48000 - 43s - loss: 0.1111 - accuracy: 0.9662 - val_loss: 0.1017 - val_accuracy: 0.9703
Epoch 3/10
 -> id = 16  Epoch: 1   accuracy: 0.9186875  val_acc: 0.95091665
48000/48000 - 44s - loss: 0.2752 - accuracy: 0.9187 - val_loss: 0.1746 - val_accuracy: 0.9509
Epoch 3/10
 -> id = 9  Epoch: 2   accuracy: 0.9263125  val_acc: 0.9410833
48000/48000 - 35s - loss: 0.2519 - accuracy: 0.9263 - val_loss: 0.2117 - val_accuracy: 0.9411
Epoch 4/10
 -> id = 1  Epoch: 2   accuracy: 0.9714375  val_acc: 0.9719167
48000/48000 - 32s - loss: 0.0976 - accuracy: 0.9714 - val_loss: 0.0988 - val_accuracy: 0.9719
Epoch 4/10
 -> id = 19  Epoch: 2   accuracy: 0.94079167  val_acc: 0.9489167
48000/48000 - 35s - loss: 0.1987 - accuracy: 0.9408 - val_loss: 0.1793 - val_accuracy: 0.9489
Epoch 4/10
 -> id = 4  Epoch: 2   accuracy: 0.96610415  val_acc: 0.9705
48000/48000 - 32s - loss: 0.1131 - accuracy: 0.9661 - val_loss: 0.0940 - val_accuracy: 0.9705
Epoch 4/10
 -> id = 8  Epoch: 1   accuracy: 0.904625  val_acc: 0.939
48000/48000 - 52s - loss: 0.3280 - accuracy: 0.9046 - val_loss: 0.2231 - val_accuracy: 0.9390
Epoch 3/10
 -> id = 13  Epoch: 2   accuracy: 0.9279583  val_acc: 0.9400833
48000/48000 - 40s - loss: 0.2432 - accuracy: 0.9280 - val_loss: 0.2109 - val_accuracy: 0.9401
Epoch 4/10
 -> id = 14  Epoch: 2   accuracy: 0.9499583  val_acc: 0.9546667
48000/48000 - 40s - loss: 0.1708 - accuracy: 0.9500 - val_loss: 0.1541 - val_accuracy: 0.9547
Epoch 4/10
 -> id = 11  Epoch: 2   accuracy: 0.973625  val_acc: 0.96933335
48000/48000 - 38s - loss: 0.0926 - accuracy: 0.9736 - val_loss: 0.1012 - val_accuracy: 0.9693
Epoch 4/10
 -> id = 12  Epoch: 2   accuracy: 0.92647916  val_acc: 0.9455
48000/48000 - 36s - loss: 0.2493 - accuracy: 0.9265 - val_loss: 0.1919 - val_accuracy: 0.9455
Epoch 4/10
 -> id = 15  Epoch: 3   accuracy: 0.9345  val_acc: 0.955
48000/48000 - 27s - loss: 0.2213 - accuracy: 0.9345 - val_loss: 0.1590 - val_accuracy: 0.9550
Epoch 5/10
 -> id = 18  Epoch: 3   accuracy: 0.9727708  val_acc: 0.97083336
48000/48000 - 27s - loss: 0.0917 - accuracy: 0.9728 - val_loss: 0.0972 - val_accuracy: 0.9708
Epoch 5/10
 -> id = 17  Epoch: 3   accuracy: 0.9583333  val_acc: 0.964
48000/48000 - 33s - loss: 0.1407 - accuracy: 0.9583 - val_loss: 0.1287 - val_accuracy: 0.9640
Epoch 5/10
 -> id = 6  Epoch: 2   accuracy: 0.9513125  val_acc: 0.9555
48000/48000 - 39s - loss: 0.1593 - accuracy: 0.9513 - val_loss: 0.1485 - val_accuracy: 0.9555
Epoch 4/10
 -> id = 5  Epoch: 2   accuracy: 0.96741664  val_acc: 0.9611667
48000/48000 - 41s - loss: 0.1044 - accuracy: 0.9674 - val_loss: 0.1287 - val_accuracy: 0.9612
Epoch 4/10
 -> id = 7  Epoch: 3   accuracy: 0.56339586  val_acc: 0.9159167
48000/48000 - 35s - loss: 1.3125 - accuracy: 0.5634 - val_loss: 0.9248 - val_accuracy: 0.9159
Epoch 5/10
 -> id = 0  Epoch: 2   accuracy: 0.9740833  val_acc: 0.973
48000/48000 - 41s - loss: 0.0847 - accuracy: 0.9741 - val_loss: 0.0892 - val_accuracy: 0.9730
Epoch 4/10
 -> id = 1  Epoch: 3   accuracy: 0.97639585  val_acc: 0.97725
48000/48000 - 30s - loss: 0.0775 - accuracy: 0.9764 - val_loss: 0.0787 - val_accuracy: 0.9772
Epoch 5/10
 -> id = 2  Epoch: 2   accuracy: 0.9731042  val_acc: 0.9741667
48000/48000 - 42s - loss: 0.0868 - accuracy: 0.9731 - val_loss: 0.0856 - val_accuracy: 0.9742
Epoch 4/10
 -> id = 9  Epoch: 3   accuracy: 0.9397708  val_acc: 0.95025
48000/48000 - 35s - loss: 0.2078 - accuracy: 0.9398 - val_loss: 0.1798 - val_accuracy: 0.9503
Epoch 5/10
 -> id = 19  Epoch: 3   accuracy: 0.9536458  val_acc: 0.9598333
48000/48000 - 34s - loss: 0.1550 - accuracy: 0.9536 - val_loss: 0.1397 - val_accuracy: 0.9598
Epoch 5/10
 -> id = 10  Epoch: 2   accuracy: 0.9763542  val_acc: 0.9705833
48000/48000 - 43s - loss: 0.0825 - accuracy: 0.9764 - val_loss: 0.0958 - val_accuracy: 0.9706
Epoch 4/10
 -> id = 3  Epoch: 2   accuracy: 0.97533333  val_acc: 0.9759167
48000/48000 - 43s - loss: 0.0818 - accuracy: 0.9753 - val_loss: 0.0816 - val_accuracy: 0.9759
Epoch 4/10
 -> id = 4  Epoch: 3   accuracy: 0.97108334  val_acc: 0.97475
48000/48000 - 33s - loss: 0.0938 - accuracy: 0.9711 - val_loss: 0.0834 - val_accuracy: 0.9747
Epoch 5/10
 -> id = 16  Epoch: 2   accuracy: 0.9417292  val_acc: 0.95933336
48000/48000 - 44s - loss: 0.1924 - accuracy: 0.9417 - val_loss: 0.1425 - val_accuracy: 0.9593
Epoch 4/10
 -> id = 18  Epoch: 4   accuracy: 0.97725  val_acc: 0.97083336
48000/48000 - 26s - loss: 0.0757 - accuracy: 0.9772 - val_loss: 0.0932 - val_accuracy: 0.9708
Epoch 6/10
 -> id = 15  Epoch: 4   accuracy: 0.9452292  val_acc: 0.95916665
48000/48000 - 28s - loss: 0.1885 - accuracy: 0.9452 - val_loss: 0.1395 - val_accuracy: 0.9592
Epoch 6/10
 -> id = 12  Epoch: 3   accuracy: 0.9344375  val_acc: 0.94958335
48000/48000 - 34s - loss: 0.2234 - accuracy: 0.9344 - val_loss: 0.1751 - val_accuracy: 0.9496
Epoch 5/10
 -> id = 13  Epoch: 3   accuracy: 0.9418125  val_acc: 0.95166665
48000/48000 - 39s - loss: 0.1974 - accuracy: 0.9418 - val_loss: 0.1750 - val_accuracy: 0.9517
Epoch 5/10
 -> id = 11  Epoch: 3   accuracy: 0.9805625  val_acc: 0.97083336
48000/48000 - 38s - loss: 0.0681 - accuracy: 0.9806 - val_loss: 0.0974 - val_accuracy: 0.9708
Epoch 5/10
 -> id = 14  Epoch: 3   accuracy: 0.95664585  val_acc: 0.959
48000/48000 - 41s - loss: 0.1424 - accuracy: 0.9566 - val_loss: 0.1444 - val_accuracy: 0.9590
Epoch 5/10
 -> id = 17  Epoch: 4   accuracy: 0.966375  val_acc: 0.9676667
48000/48000 - 33s - loss: 0.1147 - accuracy: 0.9664 - val_loss: 0.1167 - val_accuracy: 0.9677
Epoch 6/10
 -> id = 8  Epoch: 2   accuracy: 0.9289375  val_acc: 0.95033336
48000/48000 - 50s - loss: 0.2386 - accuracy: 0.9289 - val_loss: 0.1765 - val_accuracy: 0.9503
Epoch 4/10
 -> id = 7  Epoch: 4   accuracy: 0.5788125  val_acc: 0.92025
48000/48000 - 33s - loss: 1.2467 - accuracy: 0.5788 - val_loss: 0.8176 - val_accuracy: 0.9202
Epoch 6/10
 -> id = 6  Epoch: 3   accuracy: 0.95875  val_acc: 0.95875
48000/48000 - 40s - loss: 0.1311 - accuracy: 0.9588 - val_loss: 0.1423 - val_accuracy: 0.9588
Epoch 5/10
 -> id = 1  Epoch: 4   accuracy: 0.9789375  val_acc: 0.97508335
48000/48000 - 31s - loss: 0.0696 - accuracy: 0.9789 - val_loss: 0.0817 - val_accuracy: 0.9751
Epoch 6/10
 -> id = 5  Epoch: 3   accuracy: 0.97685415  val_acc: 0.9669167
48000/48000 - 40s - loss: 0.0764 - accuracy: 0.9769 - val_loss: 0.1119 - val_accuracy: 0.9669
Epoch 5/10
 -> id = 15  Epoch: 5   accuracy: 0.95102084  val_acc: 0.9640833
48000/48000 - 26s - loss: 0.1667 - accuracy: 0.9510 - val_loss: 0.1280 - val_accuracy: 0.9641
Epoch 7/10
 -> id = 18  Epoch: 5   accuracy: 0.98008335  val_acc: 0.9741667
48000/48000 - 27s - loss: 0.0651 - accuracy: 0.9801 - val_loss: 0.0860 - val_accuracy: 0.9742
Epoch 7/10
 -> id = 19  Epoch: 4   accuracy: 0.9615833  val_acc: 0.9658333
48000/48000 - 35s - loss: 0.1252 - accuracy: 0.9616 - val_loss: 0.1184 - val_accuracy: 0.9658
Epoch 6/10
 -> id = 0  Epoch: 3   accuracy: 0.9784375  val_acc: 0.9773333
48000/48000 - 42s - loss: 0.0682 - accuracy: 0.9784 - val_loss: 0.0789 - val_accuracy: 0.9773
Epoch 5/10
 -> id = 9  Epoch: 4   accuracy: 0.94872916  val_acc: 0.95633334
48000/48000 - 37s - loss: 0.1754 - accuracy: 0.9487 - val_loss: 0.1554 - val_accuracy: 0.9563
Epoch 6/10
 -> id = 2  Epoch: 3   accuracy: 0.97866666  val_acc: 0.97783333
48000/48000 - 41s - loss: 0.0694 - accuracy: 0.9787 - val_loss: 0.0752 - val_accuracy: 0.9778
Epoch 5/10
 -> id = 4  Epoch: 4   accuracy: 0.9749375  val_acc: 0.9751667
48000/48000 - 35s - loss: 0.0809 - accuracy: 0.9749 - val_loss: 0.0798 - val_accuracy: 0.9752
Epoch 6/10
 -> id = 12  Epoch: 4   accuracy: 0.9386875  val_acc: 0.95416665
48000/48000 - 35s - loss: 0.2023 - accuracy: 0.9387 - val_loss: 0.1635 - val_accuracy: 0.9542
Epoch 6/10
 -> id = 3  Epoch: 3   accuracy: 0.9788542  val_acc: 0.977
48000/48000 - 45s - loss: 0.0676 - accuracy: 0.9789 - val_loss: 0.0799 - val_accuracy: 0.9770
Epoch 5/10
 -> id = 10  Epoch: 3   accuracy: 0.98233336  val_acc: 0.9734167
48000/48000 - 47s - loss: 0.0597 - accuracy: 0.9823 - val_loss: 0.0919 - val_accuracy: 0.9734
Epoch 5/10
 -> id = 16  Epoch: 3   accuracy: 0.9548125  val_acc: 0.96533334
48000/48000 - 45s - loss: 0.1499 - accuracy: 0.9548 - val_loss: 0.1179 - val_accuracy: 0.9653
Epoch 5/10
 -> id = 17  Epoch: 5   accuracy: 0.97108334  val_acc: 0.9665
48000/48000 - 33s - loss: 0.0973 - accuracy: 0.9711 - val_loss: 0.1105 - val_accuracy: 0.9665
Epoch 7/10
 -> id = 11  Epoch: 4   accuracy: 0.9853125  val_acc: 0.97358334
48000/48000 - 38s - loss: 0.0524 - accuracy: 0.9853 - val_loss: 0.0864 - val_accuracy: 0.9736
Epoch 6/10
 -> id = 13  Epoch: 4   accuracy: 0.95152086  val_acc: 0.9586667
48000/48000 - 41s - loss: 0.1634 - accuracy: 0.9515 - val_loss: 0.1507 - val_accuracy: 0.9587
Epoch 6/10
 -> id = 14  Epoch: 4   accuracy: 0.96327084  val_acc: 0.96433336
48000/48000 - 41s - loss: 0.1192 - accuracy: 0.9633 - val_loss: 0.1265 - val_accuracy: 0.9643
Epoch 6/10
 -> id = 7  Epoch: 5   accuracy: 0.6180417  val_acc: 0.9234167
48000/48000 - 35s - loss: 1.1968 - accuracy: 0.6180 - val_loss: 0.7408 - val_accuracy: 0.9234
Epoch 7/10
 -> id = 1  Epoch: 5   accuracy: 0.98041666  val_acc: 0.9755833
48000/48000 - 33s - loss: 0.0618 - accuracy: 0.9804 - val_loss: 0.0775 - val_accuracy: 0.9756
Epoch 7/10
 -> id = 18  Epoch: 6   accuracy: 0.98152083  val_acc: 0.97358334
48000/48000 - 28s - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.0850 - val_accuracy: 0.9736
Epoch 8/10
 -> id = 15  Epoch: 6   accuracy: 0.9551042  val_acc: 0.9669167
48000/48000 - 29s - loss: 0.1495 - accuracy: 0.9551 - val_loss: 0.1171 - val_accuracy: 0.9669
Epoch 8/10
 -> id = 6  Epoch: 4   accuracy: 0.9661875  val_acc: 0.96425
48000/48000 - 38s - loss: 0.1087 - accuracy: 0.9662 - val_loss: 0.1198 - val_accuracy: 0.9643
Epoch 6/10
 -> id = 19  Epoch: 5   accuracy: 0.9686458  val_acc: 0.96758336
48000/48000 - 33s - loss: 0.1036 - accuracy: 0.9686 - val_loss: 0.1085 - val_accuracy: 0.9676
Epoch 7/10
 -> id = 5  Epoch: 4   accuracy: 0.98070836  val_acc: 0.96958333
48000/48000 - 41s - loss: 0.0616 - accuracy: 0.9807 - val_loss: 0.1012 - val_accuracy: 0.9696
Epoch 6/10
 -> id = 8  Epoch: 3   accuracy: 0.94535416  val_acc: 0.9604167
48000/48000 - 50s - loss: 0.1817 - accuracy: 0.9454 - val_loss: 0.1398 - val_accuracy: 0.9604
Epoch 5/10
 -> id = 4  Epoch: 5   accuracy: 0.97727084  val_acc: 0.97725
48000/48000 - 34s - loss: 0.0723 - accuracy: 0.9773 - val_loss: 0.0777 - val_accuracy: 0.9772
Epoch 7/10
 -> id = 9  Epoch: 5   accuracy: 0.956125  val_acc: 0.9601667
48000/48000 - 37s - loss: 0.1515 - accuracy: 0.9561 - val_loss: 0.1413 - val_accuracy: 0.9602
Epoch 7/10
 -> id = 0  Epoch: 4   accuracy: 0.98129165  val_acc: 0.9769167
48000/48000 - 42s - loss: 0.0586 - accuracy: 0.9813 - val_loss: 0.0781 - val_accuracy: 0.9769
Epoch 6/10
 -> id = 2  Epoch: 4   accuracy: 0.98072916  val_acc: 0.97675
48000/48000 - 43s - loss: 0.0617 - accuracy: 0.9807 - val_loss: 0.0767 - val_accuracy: 0.9768
Epoch 6/10
 -> id = 12  Epoch: 5   accuracy: 0.94308335  val_acc: 0.95891666
48000/48000 - 35s - loss: 0.1879 - accuracy: 0.9431 - val_loss: 0.1460 - val_accuracy: 0.9589
Epoch 7/10
 -> id = 17  Epoch: 6   accuracy: 0.975625  val_acc: 0.9695
48000/48000 - 35s - loss: 0.0832 - accuracy: 0.9756 - val_loss: 0.1025 - val_accuracy: 0.9695
Epoch 8/10
 -> id = 11  Epoch: 5   accuracy: 0.9887292  val_acc: 0.97358334
48000/48000 - 36s - loss: 0.0411 - accuracy: 0.9887 - val_loss: 0.0894 - val_accuracy: 0.9736
Epoch 7/10
 -> id = 15  Epoch: 7   accuracy: 0.9592292  val_acc: 0.9691667
48000/48000 - 27s - loss: 0.1367 - accuracy: 0.9592 - val_loss: 0.1099 - val_accuracy: 0.9692
Epoch 9/10
 -> id = 7  Epoch: 6   accuracy: 0.6352292  val_acc: 0.92325
48000/48000 - 33s - loss: 1.1563 - accuracy: 0.6352 - val_loss: 0.7019 - val_accuracy: 0.9233
Epoch 8/10
 -> id = 3  Epoch: 4   accuracy: 0.9817917  val_acc: 0.97675
48000/48000 - 44s - loss: 0.0599 - accuracy: 0.9818 - val_loss: 0.0795 - val_accuracy: 0.9768
Epoch 6/10
 -> id = 1  Epoch: 6   accuracy: 0.9825625  val_acc: 0.97783333
48000/48000 - 31s - loss: 0.0548 - accuracy: 0.9826 - val_loss: 0.0768 - val_accuracy: 0.9778
Epoch 8/10
 -> id = 18  Epoch: 7   accuracy: 0.9835208  val_acc: 0.97566664
48000/48000 - 29s - loss: 0.0491 - accuracy: 0.9835 - val_loss: 0.0842 - val_accuracy: 0.9757
Epoch 9/10
 -> id = 10  Epoch: 4   accuracy: 0.987625  val_acc: 0.9741667
48000/48000 - 43s - loss: 0.0445 - accuracy: 0.9876 - val_loss: 0.0898 - val_accuracy: 0.9742
Epoch 6/10
 -> id = 13  Epoch: 5   accuracy: 0.95979166  val_acc: 0.961
48000/48000 - 41s - loss: 0.1360 - accuracy: 0.9598 - val_loss: 0.1370 - val_accuracy: 0.9610
Epoch 7/10
 -> id = 16  Epoch: 4   accuracy: 0.96175  val_acc: 0.96966666
48000/48000 - 44s - loss: 0.1220 - accuracy: 0.9617 - val_loss: 0.1038 - val_accuracy: 0.9697
Epoch 6/10
 -> id = 14  Epoch: 5   accuracy: 0.9684167  val_acc: 0.9630833
48000/48000 - 41s - loss: 0.1037 - accuracy: 0.9684 - val_loss: 0.1223 - val_accuracy: 0.9631
Epoch 7/10
 -> id = 6  Epoch: 5   accuracy: 0.9698542  val_acc: 0.967
48000/48000 - 39s - loss: 0.0935 - accuracy: 0.9699 - val_loss: 0.1119 - val_accuracy: 0.9670
Epoch 7/10
 -> id = 19  Epoch: 6   accuracy: 0.9741875  val_acc: 0.9685
48000/48000 - 37s - loss: 0.0861 - accuracy: 0.9742 - val_loss: 0.1027 - val_accuracy: 0.9685
Epoch 8/10
 -> id = 9  Epoch: 6   accuracy: 0.9633125  val_acc: 0.96425
48000/48000 - 35s - loss: 0.1293 - accuracy: 0.9633 - val_loss: 0.1266 - val_accuracy: 0.9643
Epoch 8/10
 -> id = 4  Epoch: 6   accuracy: 0.979875  val_acc: 0.9784167
48000/48000 - 36s - loss: 0.0645 - accuracy: 0.9799 - val_loss: 0.0734 - val_accuracy: 0.9784
Epoch 8/10
 -> id = 5  Epoch: 5   accuracy: 0.98527086  val_acc: 0.9725
48000/48000 - 43s - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.0968 - val_accuracy: 0.9725
Epoch 7/10
 -> id = 12  Epoch: 6   accuracy: 0.94610417  val_acc: 0.95858335
48000/48000 - 34s - loss: 0.1751 - accuracy: 0.9461 - val_loss: 0.1451 - val_accuracy: 0.9586
Epoch 8/10
 -> id = 15  Epoch: 8   accuracy: 0.9630833  val_acc: 0.97175
48000/48000 - 28s - loss: 0.1242 - accuracy: 0.9631 - val_loss: 0.1018 - val_accuracy: 0.9718
Epoch 10/10
 -> id = 0  Epoch: 5   accuracy: 0.98325  val_acc: 0.97858334
48000/48000 - 41s - loss: 0.0521 - accuracy: 0.9833 - val_loss: 0.0756 - val_accuracy: 0.9786
Epoch 7/10
 -> id = 17  Epoch: 7   accuracy: 0.97847915  val_acc: 0.97275
48000/48000 - 34s - loss: 0.0708 - accuracy: 0.9785 - val_loss: 0.0916 - val_accuracy: 0.9728
Epoch 9/10
 -> id = 18  Epoch: 8   accuracy: 0.9855833  val_acc: 0.97566664
48000/48000 - 29s - loss: 0.0458 - accuracy: 0.9856 - val_loss: 0.0874 - val_accuracy: 0.9757
Epoch 10/10
 -> id = 2  Epoch: 5   accuracy: 0.9828125  val_acc: 0.9773333
48000/48000 - 42s - loss: 0.0532 - accuracy: 0.9828 - val_loss: 0.0760 - val_accuracy: 0.9773
Epoch 7/10
 -> id = 1  Epoch: 7   accuracy: 0.9838333  val_acc: 0.97616667
48000/48000 - 32s - loss: 0.0518 - accuracy: 0.9838 - val_loss: 0.0780 - val_accuracy: 0.9762
Epoch 9/10
 -> id = 8  Epoch: 4   accuracy: 0.9581875  val_acc: 0.96683335
48000/48000 - 51s - loss: 0.1401 - accuracy: 0.9582 - val_loss: 0.1188 - val_accuracy: 0.9668
Epoch 6/10
 -> id = 11  Epoch: 6   accuracy: 0.9903542  val_acc: 0.9755833
48000/48000 - 36s - loss: 0.0336 - accuracy: 0.9904 - val_loss: 0.0870 - val_accuracy: 0.9756
Epoch 8/10
 -> id = 7  Epoch: 7   accuracy: 0.64760417  val_acc: 0.92433333
48000/48000 - 35s - loss: 1.1035 - accuracy: 0.6476 - val_loss: 0.6276 - val_accuracy: 0.9243
Epoch 9/10
 -> id = 13  Epoch: 6   accuracy: 0.966  val_acc: 0.9633333
48000/48000 - 40s - loss: 0.1153 - accuracy: 0.9660 - val_loss: 0.1261 - val_accuracy: 0.9633
Epoch 8/10
 -> id = 3  Epoch: 5   accuracy: 0.9825625  val_acc: 0.97816664
48000/48000 - 44s - loss: 0.0532 - accuracy: 0.9826 - val_loss: 0.0749 - val_accuracy: 0.9782
Epoch 7/10
 -> id = 10  Epoch: 5   accuracy: 0.99054164  val_acc: 0.9740833
48000/48000 - 45s - loss: 0.0344 - accuracy: 0.9905 - val_loss: 0.0902 - val_accuracy: 0.9741
Epoch 7/10
 -> id = 14  Epoch: 6   accuracy: 0.97225  val_acc: 0.9683333
48000/48000 - 40s - loss: 0.0889 - accuracy: 0.9722 - val_loss: 0.1144 - val_accuracy: 0.9683
Epoch 8/10
 -> id = 16  Epoch: 5   accuracy: 0.9685  val_acc: 0.97375
48000/48000 - 44s - loss: 0.1007 - accuracy: 0.9685 - val_loss: 0.0923 - val_accuracy: 0.9737
Epoch 7/10
 -> id = 19  Epoch: 7   accuracy: 0.97685415  val_acc: 0.9709167
48000/48000 - 34s - loss: 0.0726 - accuracy: 0.9769 - val_loss: 0.1009 - val_accuracy: 0.9709
Epoch 9/10
 -> id = 6  Epoch: 6   accuracy: 0.97302085  val_acc: 0.96716666
48000/48000 - 39s - loss: 0.0823 - accuracy: 0.9730 - val_loss: 0.1079 - val_accuracy: 0.9672
Epoch 8/10
 -> id = 4  Epoch: 7   accuracy: 0.98141664  val_acc: 0.97816664
48000/48000 - 36s - loss: 0.0593 - accuracy: 0.9814 - val_loss: 0.0744 - val_accuracy: 0.9782
Epoch 9/10
 -> id = 9  Epoch: 7   accuracy: 0.9666875  val_acc: 0.96575
48000/48000 - 36s - loss: 0.1142 - accuracy: 0.9667 - val_loss: 0.1162 - val_accuracy: 0.9657
Epoch 9/10
 -> id = 15  Epoch: 9   accuracy: 0.9652708  val_acc: 0.9713333
48000/48000 - 27s - loss: 0.1144 - accuracy: 0.9653 - val_loss: 0.1007 - val_accuracy: 0.9713
 -> id = 18  Epoch: 9   accuracy: 0.9866875  val_acc: 0.9774167
48000/48000 - 25s - loss: 0.0420 - accuracy: 0.9867 - val_loss: 0.0808 - val_accuracy: 0.9774
 -> id = 12  Epoch: 7   accuracy: 0.95089585  val_acc: 0.96183336
48000/48000 - 34s - loss: 0.1620 - accuracy: 0.9509 - val_loss: 0.1347 - val_accuracy: 0.9618
Epoch 9/10
 -> id = 5  Epoch: 6   accuracy: 0.989125  val_acc: 0.97075
48000/48000 - 40s - loss: 0.0353 - accuracy: 0.9891 - val_loss: 0.1000 - val_accuracy: 0.9707
Epoch 8/10
 -> id = 17  Epoch: 8   accuracy: 0.9818125  val_acc: 0.97433335
48000/48000 - 34s - loss: 0.0607 - accuracy: 0.9818 - val_loss: 0.0886 - val_accuracy: 0.9743
Epoch 10/10
 -> id = 1  Epoch: 8   accuracy: 0.98510414  val_acc: 0.979
48000/48000 - 31s - loss: 0.0471 - accuracy: 0.9851 - val_loss: 0.0762 - val_accuracy: 0.9790
Epoch 10/10
 -> id = 7  Epoch: 8   accuracy: 0.6712083  val_acc: 0.92733335
48000/48000 - 32s - loss: 1.0572 - accuracy: 0.6712 - val_loss: 0.5670 - val_accuracy: 0.9273
Epoch 10/10
 -> id = 0  Epoch: 6   accuracy: 0.98433334  val_acc: 0.97833335
48000/48000 - 42s - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.0752 - val_accuracy: 0.9783
Epoch 8/10
 -> id = 11  Epoch: 7   accuracy: 0.99302083  val_acc: 0.97625
48000/48000 - 36s - loss: 0.0259 - accuracy: 0.9930 - val_loss: 0.0850 - val_accuracy: 0.9762
Epoch 9/10
 -> id = 2  Epoch: 6   accuracy: 0.984625  val_acc: 0.97816664
48000/48000 - 43s - loss: 0.0484 - accuracy: 0.9846 - val_loss: 0.0726 - val_accuracy: 0.9782
Epoch 8/10
 -> id = 13  Epoch: 7   accuracy: 0.9705625  val_acc: 0.96825
48000/48000 - 39s - loss: 0.1002 - accuracy: 0.9706 - val_loss: 0.1094 - val_accuracy: 0.9682
Epoch 9/10
 -> id = 8  Epoch: 5   accuracy: 0.9649792  val_acc: 0.96725
48000/48000 - 51s - loss: 0.1152 - accuracy: 0.9650 - val_loss: 0.1126 - val_accuracy: 0.9672
Epoch 7/10
 -> id = 19  Epoch: 8   accuracy: 0.98020834  val_acc: 0.97508335
48000/48000 - 35s - loss: 0.0617 - accuracy: 0.9802 - val_loss: 0.0856 - val_accuracy: 0.9751
Epoch 10/10
 -> id = 3  Epoch: 6   accuracy: 0.9851875  val_acc: 0.97833335
48000/48000 - 43s - loss: 0.0458 - accuracy: 0.9852 - val_loss: 0.0738 - val_accuracy: 0.9783
Epoch 8/10
 -> id = 14  Epoch: 7   accuracy: 0.9749375  val_acc: 0.96825
48000/48000 - 40s - loss: 0.0785 - accuracy: 0.9749 - val_loss: 0.1143 - val_accuracy: 0.9682
Epoch 9/10
 -> id = 9  Epoch: 8   accuracy: 0.9710625  val_acc: 0.969
48000/48000 - 34s - loss: 0.1008 - accuracy: 0.9711 - val_loss: 0.1068 - val_accuracy: 0.9690
Epoch 10/10
 -> id = 4  Epoch: 8   accuracy: 0.981875  val_acc: 0.97925
48000/48000 - 35s - loss: 0.0564 - accuracy: 0.9819 - val_loss: 0.0738 - val_accuracy: 0.9793
Epoch 10/10
 -> id = 6  Epoch: 7   accuracy: 0.97564584  val_acc: 0.9726667
48000/48000 - 38s - loss: 0.0748 - accuracy: 0.9756 - val_loss: 0.0960 - val_accuracy: 0.9727
Epoch 9/10
 -> id = 10  Epoch: 6   accuracy: 0.9936875  val_acc: 0.97491664
48000/48000 - 44s - loss: 0.0260 - accuracy: 0.9937 - val_loss: 0.0910 - val_accuracy: 0.9749
 -> id = 16  Epoch: 6   accuracy: 0.9738125  val_acc: 0.9745
Epoch 8/1048000/48000 - 43s - loss: 0.0862 - accuracy: 0.9738 - val_loss: 0.0878 - val_accuracy: 0.9745
Epoch 8/10

 -> id = 1  Epoch: 9   accuracy: 0.98585415  val_acc: 0.97783333
48000/48000 - 28s - loss: 0.0421 - accuracy: 0.9859 - val_loss: 0.0731 - val_accuracy: 0.9778
 -> id = 12  Epoch: 8   accuracy: 0.95145833  val_acc: 0.964
48000/48000 - 34s - loss: 0.1588 - accuracy: 0.9515 - val_loss: 0.1278 - val_accuracy: 0.9640
Epoch 10/10
 -> id = 17  Epoch: 9   accuracy: 0.98375  val_acc: 0.97508335
48000/48000 - 32s - loss: 0.0538 - accuracy: 0.9837 - val_loss: 0.0852 - val_accuracy: 0.9751
 -> id = 7  Epoch: 9   accuracy: 0.6763333  val_acc: 0.9291667
48000/48000 - 33s - loss: 1.0236 - accuracy: 0.6763 - val_loss: 0.5182 - val_accuracy: 0.9292
 -> id = 5  Epoch: 7   accuracy: 0.99091667  val_acc: 0.97283334
48000/48000 - 41s - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0986 - val_accuracy: 0.9728
Epoch 9/10
 -> id = 11  Epoch: 8   accuracy: 0.9947708  val_acc: 0.9769167
48000/48000 - 34s - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.0882 - val_accuracy: 0.9769
Epoch 10/10
 -> id = 0  Epoch: 7   accuracy: 0.9857917  val_acc: 0.9801667
48000/48000 - 40s - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.0740 - val_accuracy: 0.9802
Epoch 9/10
 -> id = 2  Epoch: 7   accuracy: 0.9862292  val_acc: 0.97891665
48000/48000 - 39s - loss: 0.0439 - accuracy: 0.9862 - val_loss: 0.0741 - val_accuracy: 0.9789
Epoch 9/10
 -> id = 19  Epoch: 9   accuracy: 0.9840208  val_acc: 0.9755833
48000/48000 - 32s - loss: 0.0510 - accuracy: 0.9840 - val_loss: 0.0850 - val_accuracy: 0.9756
 -> id = 13  Epoch: 8   accuracy: 0.9748333  val_acc: 0.9695
48000/48000 - 36s - loss: 0.0848 - accuracy: 0.9748 - val_loss: 0.1032 - val_accuracy: 0.9695
Epoch 10/10
 -> id = 4  Epoch: 9   accuracy: 0.9843125  val_acc: 0.97925
48000/48000 - 31s - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.0721 - val_accuracy: 0.9793
 -> id = 9  Epoch: 9   accuracy: 0.973625  val_acc: 0.97075
48000/48000 - 31s - loss: 0.0905 - accuracy: 0.9736 - val_loss: 0.1008 - val_accuracy: 0.9707
 -> id = 12  Epoch: 9   accuracy: 0.9538125  val_acc: 0.96358335
48000/48000 - 28s - loss: 0.1473 - accuracy: 0.9538 - val_loss: 0.1276 - val_accuracy: 0.9636
 -> id = 14  Epoch: 8   accuracy: 0.9768125  val_acc: 0.97316664
48000/48000 - 36s - loss: 0.0711 - accuracy: 0.9768 - val_loss: 0.0957 - val_accuracy: 0.9732
Epoch 10/10
 -> id = 6  Epoch: 8   accuracy: 0.9789583  val_acc: 0.9705833
48000/48000 - 34s - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.0997 - val_accuracy: 0.9706
 -> id = 3  Epoch: 7   accuracy: 0.98639584  val_acc: 0.97866666
48000/48000 - 37s - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.0728 - val_accuracy: 0.9787
Epoch 10/10
Epoch 9/10
 -> id = 16  Epoch: 7   accuracy: 0.97845834  val_acc: 0.9765
48000/48000 - 37s - loss: 0.0716 - accuracy: 0.9785 - val_loss: 0.0825 - val_accuracy: 0.9765
Epoch 9/10
 -> id = 8  Epoch: 6   accuracy: 0.971125  val_acc: 0.9715833
48000/48000 - 44s - loss: 0.0946 - accuracy: 0.9711 - val_loss: 0.1018 - val_accuracy: 0.9716
Epoch 8/10
 -> id = 10  Epoch: 7   accuracy: 0.99475  val_acc: 0.97358334
48000/48000 - 38s - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.0969 - val_accuracy: 0.9736
Epoch 9/10
 -> id = 11  Epoch: 9   accuracy: 0.99614584  val_acc: 0.9755
48000/48000 - 26s - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0945 - val_accuracy: 0.9755
 -> id = 5  Epoch: 8   accuracy: 0.992625  val_acc: 0.97141665
48000/48000 - 31s - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0982 - val_accuracy: 0.9714
Epoch 10/10
 -> id = 0  Epoch: 8   accuracy: 0.9866875  val_acc: 0.9785
48000/48000 - 31s - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.0761 - val_accuracy: 0.9785
Epoch 10/10
 -> id = 2  Epoch: 8   accuracy: 0.98672915  val_acc: 0.9780833
48000/48000 - 31s - loss: 0.0408 - accuracy: 0.9867 - val_loss: 0.0744 - val_accuracy: 0.9781
Epoch 10/10
 -> id = 13  Epoch: 9   accuracy: 0.9782708  val_acc: 0.97225
48000/48000 - 27s - loss: 0.0735 - accuracy: 0.9783 - val_loss: 0.0943 - val_accuracy: 0.9722
 -> id = 14  Epoch: 9   accuracy: 0.9799375  val_acc: 0.97141665
48000/48000 - 27s - loss: 0.0622 - accuracy: 0.9799 - val_loss: 0.0973 - val_accuracy: 0.9714
 -> id = 6  Epoch: 9   accuracy: 0.98097914  val_acc: 0.97241664
48000/48000 - 29s - loss: 0.0568 - accuracy: 0.9810 - val_loss: 0.0966 - val_accuracy: 0.9724
 -> id = 3  Epoch: 8   accuracy: 0.98691666  val_acc: 0.97891665
48000/48000 - 30s - loss: 0.0398 - accuracy: 0.9869 - val_loss: 0.0759 - val_accuracy: 0.9789
Epoch 10/10
 -> id = 16  Epoch: 8   accuracy: 0.9803333  val_acc: 0.97658336
48000/48000 - 29s - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0828 - val_accuracy: 0.9766
Epoch 10/10
 -> id = 10  Epoch: 8   accuracy: 0.99616665  val_acc: 0.9745833
48000/48000 - 30s - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.0966 - val_accuracy: 0.9746
Epoch 10/10
 -> id = 5  Epoch: 9   accuracy: 0.9921875  val_acc: 0.97533333
48000/48000 - 24s - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0948 - val_accuracy: 0.9753
 -> id = 8  Epoch: 7   accuracy: 0.9738542  val_acc: 0.97325
48000/48000 - 34s - loss: 0.0837 - accuracy: 0.9739 - val_loss: 0.0952 - val_accuracy: 0.9732
Epoch 9/10
 -> id = 0  Epoch: 9   accuracy: 0.9867708  val_acc: 0.979
48000/48000 - 22s - loss: 0.0397 - accuracy: 0.9868 - val_loss: 0.0782 - val_accuracy: 0.9790
 -> id = 2  Epoch: 9   accuracy: 0.9876458  val_acc: 0.9795833
48000/48000 - 19s - loss: 0.0387 - accuracy: 0.9876 - val_loss: 0.0717 - val_accuracy: 0.9796
 -> id = 3  Epoch: 9   accuracy: 0.9880625  val_acc: 0.9795833
48000/48000 - 15s - loss: 0.0360 - accuracy: 0.9881 - val_loss: 0.0705 - val_accuracy: 0.9796
 -> id = 16  Epoch: 9   accuracy: 0.9820625  val_acc: 0.9769167
48000/48000 - 14s - loss: 0.0576 - accuracy: 0.9821 - val_loss: 0.0810 - val_accuracy: 0.9769
 -> id = 10  Epoch: 9   accuracy: 0.997125  val_acc: 0.97566664
48000/48000 - 14s - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.0939 - val_accuracy: 0.9757
 -> id = 8  Epoch: 8   accuracy: 0.9775625  val_acc: 0.97225
48000/48000 - 12s - loss: 0.0697 - accuracy: 0.9776 - val_loss: 0.0980 - val_accuracy: 0.9722
Epoch 10/10
 -> id = 8  Epoch: 9   accuracy: 0.98083335  val_acc: 0.97616667
48000/48000 - 6s - loss: 0.0601 - accuracy: 0.9808 - val_loss: 0.0869 - val_accuracy: 0.9762
 id = 2  val_accuracy= 0.9795833230018616
 id = 3  val_accuracy= 0.9795833230018616
 id = 4  val_accuracy= 0.9792500138282776
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  4   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Model: "model_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_267 (Dense)            (None, 986)               774010
_________________________________________________________________
activation_186 (Activation)  (None, 986)               0
_________________________________________________________________
dropout_100 (Dropout)        (None, 986)               0
_________________________________________________________________
batch_normalization_95 (Batc (None, 986)               3944
_________________________________________________________________
dense_268 (Dense)            (None, 10)                9870
=================================================================
Total params: 787,824
Trainable params: 785,852
Non-trainable params: 1,972
_________________________________________________________________
None
Model: "model_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_269 (Dense)            (None, 1211)              950635
_________________________________________________________________
activation_187 (Activation)  (None, 1211)              0
_________________________________________________________________
dropout_101 (Dropout)        (None, 1211)              0
_________________________________________________________________
batch_normalization_96 (Batc (None, 1211)              4844
_________________________________________________________________
dense_270 (Dense)            (None, 10)                12120
=================================================================
Total params: 967,599
Trainable params: 965,177
Non-trainable params: 2,422
_________________________________________________________________
None
Model: "model_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_271 (Dense)            (None, 389)               305365
_________________________________________________________________
activation_188 (Activation)  (None, 389)               0
_________________________________________________________________
dropout_102 (Dropout)        (None, 389)               0
_________________________________________________________________
batch_normalization_97 (Batc (None, 389)               1556
_________________________________________________________________
dense_272 (Dense)            (None, 10)                3900
=================================================================
Total params: 310,821
Trainable params: 310,043
Non-trainable params: 778
_________________________________________________________________
None
Model: "model_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_273 (Dense)            (None, 764)               599740
_________________________________________________________________
activation_189 (Activation)  (None, 764)               0
_________________________________________________________________
dropout_103 (Dropout)        (None, 764)               0
_________________________________________________________________
batch_normalization_98 (Batc (None, 764)               3056
_________________________________________________________________
dense_274 (Dense)            (None, 10)                7650
=================================================================
Total params: 610,446
Trainable params: 608,918
Non-trainable params: 1,528
_________________________________________________________________
None
Model: "model_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_275 (Dense)            (None, 1525)              1197125
_________________________________________________________________
activation_190 (Activation)  (None, 1525)              0
_________________________________________________________________
dropout_104 (Dropout)        (None, 1525)              0
_________________________________________________________________
batch_normalization_99 (Batc (None, 1525)              6100
_________________________________________________________________
dense_276 (Dense)            (None, 10)                15260
=================================================================
Total params: 1,218,485
Trainable params: 1,215,435
Non-trainable params: 3,050
_________________________________________________________________
None
Model: "model_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_277 (Dense)            (None, 540)               423900
_________________________________________________________________
activation_191 (Activation)  (None, 540)               0
_________________________________________________________________
batch_normalization_100 (Bat (None, 540)               2160
_________________________________________________________________
dense_278 (Dense)            (None, 10)                5410
=================================================================
Total params: 431,470
Trainable params: 430,390
Non-trainable params: 1,080
_________________________________________________________________
None
Model: "model_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_279 (Dense)            (None, 410)               321850
_________________________________________________________________
activation_192 (Activation)  (None, 410)               0
_________________________________________________________________
batch_normalization_101 (Bat (None, 410)               1640
_________________________________________________________________
dense_280 (Dense)            (None, 10)                4110
=================================================================
Total params: 327,600
Trainable params: 326,780
Non-trainable params: 820
_________________________________________________________________
None
Model: "model_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_281 (Dense)            (None, 40)                31400
_________________________________________________________________
activation_193 (Activation)  (None, 40)                0
_________________________________________________________________
batch_normalization_102 (Bat (None, 40)                160
_________________________________________________________________
dense_282 (Dense)            (None, 10)                410
=================================================================
Total params: 31,970
Trainable params: 31,890
Non-trainable params: 80
_________________________________________________________________
None
Model: "model_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_283 (Dense)            (None, 210)               164850
_________________________________________________________________
activation_194 (Activation)  (None, 210)               0
_________________________________________________________________
dropout_105 (Dropout)        (None, 210)               0
_________________________________________________________________
batch_normalization_103 (Bat (None, 210)               840
_________________________________________________________________
dense_284 (Dense)            (None, 10)                2110
=================================================================
Total params: 167,800
Trainable params: 167,380
Non-trainable params: 420
_________________________________________________________________
None
Model: "model_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_285 (Dense)            (None, 670)               525950
_________________________________________________________________
activation_195 (Activation)  (None, 670)               0
_________________________________________________________________
dense_286 (Dense)            (None, 10)                6710
=================================================================
Total params: 532,660
Trainable params: 532,660
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_287 (Dense)            (None, 1540)              1208900
_________________________________________________________________
activation_196 (Activation)  (None, 1540)              0
_________________________________________________________________
dropout_106 (Dropout)        (None, 1540)              0
_________________________________________________________________
dense_288 (Dense)            (None, 10)                15410
=================================================================
Total params: 1,224,310
Trainable params: 1,224,310
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_289 (Dense)            (None, 1050)              824250
_________________________________________________________________
activation_197 (Activation)  (None, 1050)              0
_________________________________________________________________
dense_290 (Dense)            (None, 10)                10510
=================================================================
Total params: 834,760
Trainable params: 834,760
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_291 (Dense)            (None, 960)               753600
_________________________________________________________________
activation_198 (Activation)  (None, 960)               0
_________________________________________________________________
dropout_107 (Dropout)        (None, 960)               0
_________________________________________________________________
batch_normalization_104 (Bat (None, 960)               3840
_________________________________________________________________
dense_292 (Dense)            (None, 10)                9610
=================================================================
Total params: 767,050
Trainable params: 765,130
Non-trainable params: 1,920
_________________________________________________________________
None
Model: "model_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_293 (Dense)            (None, 1160)              910600
_________________________________________________________________
activation_199 (Activation)  (None, 1160)              0
_________________________________________________________________
dense_294 (Dense)            (None, 10)                11610
=================================================================
Total params: 922,210
Trainable params: 922,210
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_295 (Dense)            (None, 1120)              879200
_________________________________________________________________
activation_200 (Activation)  (None, 1120)              0
_________________________________________________________________
dense_296 (Dense)            (None, 10)                11210
=================================================================
Total params: 890,410
Trainable params: 890,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_297 (Dense)            (None, 380)               298300
_________________________________________________________________
activation_201 (Activation)  (None, 380)               0
_________________________________________________________________
batch_normalization_105 (Bat (None, 380)               1520
_________________________________________________________________
dense_298 (Dense)            (None, 10)                3810
=================================================================
Total params: 303,630
Trainable params: 302,870
Non-trainable params: 760
_________________________________________________________________
None
Model: "model_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_299 (Dense)            (None, 190)               149150
_________________________________________________________________
activation_202 (Activation)  (None, 190)               0
_________________________________________________________________
dense_300 (Dense)            (None, 10)                1910
=================================================================
Total params: 151,060
Trainable params: 151,060
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_301 (Dense)            (None, 1860)              1460100
_________________________________________________________________
activation_203 (Activation)  (None, 1860)              0
_________________________________________________________________
batch_normalization_106 (Bat (None, 1860)              7440
_________________________________________________________________
dense_302 (Dense)            (None, 10)                18610
=================================================================
Total params: 1,486,150
Trainable params: 1,482,430
Non-trainable params: 3,720
_________________________________________________________________
None
Model: "model_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_303 (Dense)            (None, 180)               141300
_________________________________________________________________
activation_204 (Activation)  (None, 180)               0
_________________________________________________________________
dense_304 (Dense)            (None, 10)                1810
=================================================================
Total params: 143,110
Trainable params: 143,110
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_100"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_305 (Dense)            (None, 1380)              1083300
_________________________________________________________________
activation_205 (Activation)  (None, 1380)              0
_________________________________________________________________
dropout_108 (Dropout)        (None, 1380)              0
_________________________________________________________________
batch_normalization_107 (Bat (None, 1380)              5520
_________________________________________________________________
dense_306 (Dense)            (None, 10)                13810
=================================================================
Total params: 1,102,630
Trainable params: 1,099,870
Non-trainable params: 2,760
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesEpoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples


Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10Epoch 1/10Train on 48000 samples, validate on 12000 samplesTrain on 48000 samples, validate on 12000 samples
Epoch 1/10Train on 48000 samples, validate on 12000 samples


Train on 48000 samples, validate on 12000 samples


Epoch 1/10Epoch 1/10
Epoch 1/10
Epoch 1/10

 -> id = 18  Epoch: 0   accuracy: 0.88502085  val_acc: 0.92908335
48000/48000 - 26s - loss: 0.4041 - accuracy: 0.8850 - val_loss: 0.2483 - val_accuracy: 0.9291
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.84675  val_acc: 0.9135
48000/48000 - 26s - loss: 0.6379 - accuracy: 0.8468 - val_loss: 0.3236 - val_accuracy: 0.9135
Epoch 2/10
 -> id = 9  Epoch: 0   accuracy: 0.91814584  val_acc: 0.95891666
48000/48000 - 29s - loss: 0.2903 - accuracy: 0.9181 - val_loss: 0.1517 - val_accuracy: 0.9589
Epoch 2/10
 -> id = 13  Epoch: 0   accuracy: 0.9235833  val_acc: 0.9554167
48000/48000 - 30s - loss: 0.2642 - accuracy: 0.9236 - val_loss: 0.1504 - val_accuracy: 0.9554
Epoch 2/10
 -> id = 14  Epoch: 0   accuracy: 0.71285415  val_acc: 0.8581667
48000/48000 - 32s - loss: 1.9557 - accuracy: 0.7129 - val_loss: 1.5975 - val_accuracy: 0.8582
Epoch 2/10
 -> id = 11  Epoch: 0   accuracy: 0.8936875  val_acc: 0.9295833
48000/48000 - 33s - loss: 0.3596 - accuracy: 0.8937 - val_loss: 0.2535 - val_accuracy: 0.9296
Epoch 2/10
 -> id = 10  Epoch: 0   accuracy: 0.9024792  val_acc: 0.937
48000/48000 - 38s - loss: 0.3329 - accuracy: 0.9025 - val_loss: 0.2261 - val_accuracy: 0.9370
Epoch 2/10
 -> id = 7  Epoch: 0   accuracy: 0.8666458  val_acc: 0.9175
48000/48000 - 44s - loss: 0.4593 - accuracy: 0.8666 - val_loss: 0.3288 - val_accuracy: 0.9175
Epoch 2/10
 -> id = 5  Epoch: 0   accuracy: 0.8822708  val_acc: 0.93441665
48000/48000 - 45s - loss: 0.5082 - accuracy: 0.8823 - val_loss: 1.2526 - val_accuracy: 0.9344
Epoch 2/10
 -> id = 8  Epoch: 0   accuracy: 0.831375  val_acc: 0.9291667
48000/48000 - 46s - loss: 0.5376 - accuracy: 0.8314 - val_loss: 0.2633 - val_accuracy: 0.9292
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.896875  val_acc: 0.92466664
48000/48000 - 47s - loss: 0.3588 - accuracy: 0.8969 - val_loss: 0.2972 - val_accuracy: 0.9247
Epoch 2/10
 -> id = 15  Epoch: 0   accuracy: 0.93127084  val_acc: 0.95775
48000/48000 - 48s - loss: 0.2313 - accuracy: 0.9313 - val_loss: 0.1729 - val_accuracy: 0.9578
Epoch 2/10
 -> id = 2  Epoch: 0   accuracy: 0.9031042  val_acc: 0.9575
48000/48000 - 50s - loss: 0.3210 - accuracy: 0.9031 - val_loss: 0.1655 - val_accuracy: 0.9575
Epoch 2/10
 -> id = 12  Epoch: 0   accuracy: 0.8567917  val_acc: 0.91675
48000/48000 - 50s - loss: 0.4801 - accuracy: 0.8568 - val_loss: 0.3031 - val_accuracy: 0.9168
Epoch 2/10
 -> id = 18  Epoch: 1   accuracy: 0.9372708  val_acc: 0.94941664
48000/48000 - 25s - loss: 0.2220 - accuracy: 0.9373 - val_loss: 0.1844 - val_accuracy: 0.9494
Epoch 3/10
 -> id = 3  Epoch: 0   accuracy: 0.9192708  val_acc: 0.9644167
48000/48000 - 52s - loss: 0.2653 - accuracy: 0.9193 - val_loss: 0.1465 - val_accuracy: 0.9644
Epoch 2/10
 -> id = 16  Epoch: 1   accuracy: 0.91510415  val_acc: 0.93008333
48000/48000 - 26s - loss: 0.3011 - accuracy: 0.9151 - val_loss: 0.2541 - val_accuracy: 0.9301
Epoch 3/10
 -> id = 9  Epoch: 1   accuracy: 0.9660208  val_acc: 0.9673333
48000/48000 - 26s - loss: 0.1185 - accuracy: 0.9660 - val_loss: 0.1054 - val_accuracy: 0.9673
Epoch 3/10
 -> id = 1  Epoch: 0   accuracy: 0.9272917  val_acc: 0.96208334
48000/48000 - 55s - loss: 0.2424 - accuracy: 0.9273 - val_loss: 0.1420 - val_accuracy: 0.9621
Epoch 2/10
 -> id = 19  Epoch: 0   accuracy: 0.90033334  val_acc: 0.93675
48000/48000 - 56s - loss: 0.3677 - accuracy: 0.9003 - val_loss: 0.2166 - val_accuracy: 0.9367
Epoch 2/10
 -> id = 0  Epoch: 0   accuracy: 0.92116666  val_acc: 0.9633333
48000/48000 - 57s - loss: 0.2595 - accuracy: 0.9212 - val_loss: 0.1494 - val_accuracy: 0.9633
Epoch 2/10
 -> id = 13  Epoch: 1   accuracy: 0.97010416  val_acc: 0.9680833
48000/48000 - 27s - loss: 0.1030 - accuracy: 0.9701 - val_loss: 0.1037 - val_accuracy: 0.9681
Epoch 3/10
 -> id = 4  Epoch: 0   accuracy: 0.9286875  val_acc: 0.95925
48000/48000 - 60s - loss: 0.2369 - accuracy: 0.9287 - val_loss: 0.1506 - val_accuracy: 0.9592
Epoch 2/10
 -> id = 17  Epoch: 0   accuracy: 0.8691667  val_acc: 0.9185
48000/48000 - 61s - loss: 0.5261 - accuracy: 0.8692 - val_loss: 1.2745 - val_accuracy: 0.9185
Epoch 2/10
 -> id = 14  Epoch: 1   accuracy: 0.88441664  val_acc: 0.9145833
48000/48000 - 30s - loss: 1.3772 - accuracy: 0.8844 - val_loss: 1.1683 - val_accuracy: 0.9146
Epoch 3/10
 -> id = 11  Epoch: 1   accuracy: 0.93622917  val_acc: 0.94191664
48000/48000 - 30s - loss: 0.2219 - accuracy: 0.9362 - val_loss: 0.1998 - val_accuracy: 0.9419
Epoch 3/10
 -> id = 10  Epoch: 1   accuracy: 0.94241667  val_acc: 0.95125
48000/48000 - 29s - loss: 0.1980 - accuracy: 0.9424 - val_loss: 0.1731 - val_accuracy: 0.9513
Epoch 3/10
 -> id = 7  Epoch: 1   accuracy: 0.922875  val_acc: 0.934
48000/48000 - 24s - loss: 0.2722 - accuracy: 0.9229 - val_loss: 0.2350 - val_accuracy: 0.9340
Epoch 3/10
 -> id = 8  Epoch: 1   accuracy: 0.91227084  val_acc: 0.9458333
48000/48000 - 27s - loss: 0.2891 - accuracy: 0.9123 - val_loss: 0.1950 - val_accuracy: 0.9458
Epoch 3/10
 -> id = 6  Epoch: 1   accuracy: 0.9393125  val_acc: 0.95025
48000/48000 - 27s - loss: 0.2107 - accuracy: 0.9393 - val_loss: 0.1829 - val_accuracy: 0.9503
Epoch 3/10
 -> id = 5  Epoch: 1   accuracy: 0.960875  val_acc: 0.9651667
48000/48000 - 29s - loss: 0.1360 - accuracy: 0.9609 - val_loss: 0.1531 - val_accuracy: 0.9652
Epoch 3/10
 -> id = 18  Epoch: 2   accuracy: 0.9512708  val_acc: 0.95683336
48000/48000 - 25s - loss: 0.1671 - accuracy: 0.9513 - val_loss: 0.1565 - val_accuracy: 0.9568
Epoch 4/10
 -> id = 2  Epoch: 1   accuracy: 0.95535415  val_acc: 0.96825
48000/48000 - 27s - loss: 0.1511 - accuracy: 0.9554 - val_loss: 0.1099 - val_accuracy: 0.9682
Epoch 3/10
 -> id = 16  Epoch: 2   accuracy: 0.9295833  val_acc: 0.93925
48000/48000 - 25s - loss: 0.2452 - accuracy: 0.9296 - val_loss: 0.2168 - val_accuracy: 0.9392
Epoch 4/10
 -> id = 15  Epoch: 1   accuracy: 0.9754792  val_acc: 0.96816665
48000/48000 - 30s - loss: 0.0846 - accuracy: 0.9755 - val_loss: 0.1020 - val_accuracy: 0.9682
Epoch 3/10
 -> id = 12  Epoch: 1   accuracy: 0.9113333  val_acc: 0.93591666
48000/48000 - 31s - loss: 0.3044 - accuracy: 0.9113 - val_loss: 0.2244 - val_accuracy: 0.9359
Epoch 3/10
 -> id = 9  Epoch: 2   accuracy: 0.9780625  val_acc: 0.97208333
48000/48000 - 30s - loss: 0.0758 - accuracy: 0.9781 - val_loss: 0.0931 - val_accuracy: 0.9721
Epoch 4/10
 -> id = 3  Epoch: 1   accuracy: 0.9640833  val_acc: 0.9685
48000/48000 - 35s - loss: 0.1215 - accuracy: 0.9641 - val_loss: 0.0982 - val_accuracy: 0.9685
Epoch 3/10
 -> id = 13  Epoch: 2   accuracy: 0.9818958  val_acc: 0.97375
48000/48000 - 30s - loss: 0.0641 - accuracy: 0.9819 - val_loss: 0.0882 - val_accuracy: 0.9737
Epoch 4/10
 -> id = 19  Epoch: 1   accuracy: 0.942875  val_acc: 0.95491666
48000/48000 - 35s - loss: 0.1924 - accuracy: 0.9429 - val_loss: 0.1562 - val_accuracy: 0.9549
Epoch 3/10
 -> id = 1  Epoch: 1   accuracy: 0.96533334  val_acc: 0.9734167
48000/48000 - 37s - loss: 0.1120 - accuracy: 0.9653 - val_loss: 0.0899 - val_accuracy: 0.9734
Epoch 3/10
 -> id = 11  Epoch: 2   accuracy: 0.95475  val_acc: 0.96091664
48000/48000 - 30s - loss: 0.1540 - accuracy: 0.9548 - val_loss: 0.1416 - val_accuracy: 0.9609
Epoch 4/10
 -> id = 7  Epoch: 2   accuracy: 0.9399167  val_acc: 0.94725
48000/48000 - 25s - loss: 0.2123 - accuracy: 0.9399 - val_loss: 0.1891 - val_accuracy: 0.9473
Epoch 4/10
 -> id = 14  Epoch: 2   accuracy: 0.9161875  val_acc: 0.92441666
48000/48000 - 32s - loss: 1.0204 - accuracy: 0.9162 - val_loss: 0.8750 - val_accuracy: 0.9244
Epoch 4/10
 -> id = 0  Epoch: 1   accuracy: 0.9649583  val_acc: 0.97333336
48000/48000 - 38s - loss: 0.1163 - accuracy: 0.9650 - val_loss: 0.0926 - val_accuracy: 0.9733
Epoch 3/10
 -> id = 10  Epoch: 2   accuracy: 0.9571875  val_acc: 0.96
48000/48000 - 32s - loss: 0.1423 - accuracy: 0.9572 - val_loss: 0.1384 - val_accuracy: 0.9600
Epoch 4/10
 -> id = 4  Epoch: 1   accuracy: 0.9679792  val_acc: 0.97125
48000/48000 - 40s - loss: 0.1078 - accuracy: 0.9680 - val_loss: 0.0942 - val_accuracy: 0.9712
Epoch 3/10
 -> id = 8  Epoch: 2   accuracy: 0.93427086  val_acc: 0.95825
48000/48000 - 28s - loss: 0.2208 - accuracy: 0.9343 - val_loss: 0.1545 - val_accuracy: 0.9582
Epoch 4/10
 -> id = 18  Epoch: 3   accuracy: 0.96183336  val_acc: 0.9619167
48000/48000 - 25s - loss: 0.1313 - accuracy: 0.9618 - val_loss: 0.1346 - val_accuracy: 0.9619
Epoch 5/10
 -> id = 16  Epoch: 3   accuracy: 0.9394583  val_acc: 0.94516665
48000/48000 - 26s - loss: 0.2087 - accuracy: 0.9395 - val_loss: 0.1956 - val_accuracy: 0.9452
Epoch 5/10
 -> id = 6  Epoch: 2   accuracy: 0.95727086  val_acc: 0.9615
48000/48000 - 30s - loss: 0.1464 - accuracy: 0.9573 - val_loss: 0.1387 - val_accuracy: 0.9615
Epoch 4/10
 -> id = 5  Epoch: 2   accuracy: 0.97477084  val_acc: 0.9684167
48000/48000 - 32s - loss: 0.0918 - accuracy: 0.9748 - val_loss: 0.1029 - val_accuracy: 0.9684
Epoch 4/10
 -> id = 17  Epoch: 1   accuracy: 0.96370834  val_acc: 0.9655
48000/48000 - 45s - loss: 0.1261 - accuracy: 0.9637 - val_loss: 0.1483 - val_accuracy: 0.9655
Epoch 3/10
 -> id = 2  Epoch: 2   accuracy: 0.96522915  val_acc: 0.97291666
48000/48000 - 31s - loss: 0.1147 - accuracy: 0.9652 - val_loss: 0.0902 - val_accuracy: 0.9729
Epoch 4/10
 -> id = 15  Epoch: 2   accuracy: 0.98525  val_acc: 0.97225
48000/48000 - 31s - loss: 0.0511 - accuracy: 0.9852 - val_loss: 0.0949 - val_accuracy: 0.9722
Epoch 4/10
 -> id = 9  Epoch: 3   accuracy: 0.9847292  val_acc: 0.97425
48000/48000 - 27s - loss: 0.0539 - accuracy: 0.9847 - val_loss: 0.0814 - val_accuracy: 0.9743
Epoch 5/10
 -> id = 12  Epoch: 2   accuracy: 0.93616664  val_acc: 0.9558333
48000/48000 - 32s - loss: 0.2185 - accuracy: 0.9362 - val_loss: 0.1655 - val_accuracy: 0.9558
Epoch 4/10
 -> id = 13  Epoch: 3   accuracy: 0.98672915  val_acc: 0.97875
48000/48000 - 31s - loss: 0.0444 - accuracy: 0.9867 - val_loss: 0.0708 - val_accuracy: 0.9787
Epoch 5/10
 -> id = 7  Epoch: 3   accuracy: 0.95104164  val_acc: 0.95475
48000/48000 - 26s - loss: 0.1730 - accuracy: 0.9510 - val_loss: 0.1685 - val_accuracy: 0.9548
Epoch 5/10
 -> id = 3  Epoch: 2   accuracy: 0.973875  val_acc: 0.9734167
48000/48000 - 33s - loss: 0.0866 - accuracy: 0.9739 - val_loss: 0.0875 - val_accuracy: 0.9734
Epoch 4/10
 -> id = 11  Epoch: 3   accuracy: 0.9657083  val_acc: 0.96383333
48000/48000 - 30s - loss: 0.1159 - accuracy: 0.9657 - val_loss: 0.1267 - val_accuracy: 0.9638
Epoch 5/10
 -> id = 19  Epoch: 2   accuracy: 0.95697916  val_acc: 0.96075
48000/48000 - 34s - loss: 0.1411 - accuracy: 0.9570 - val_loss: 0.1364 - val_accuracy: 0.9607
Epoch 4/10
 -> id = 14  Epoch: 3   accuracy: 0.9255625  val_acc: 0.931
48000/48000 - 32s - loss: 0.7757 - accuracy: 0.9256 - val_loss: 0.6760 - val_accuracy: 0.9310
Epoch 5/10
 -> id = 1  Epoch: 2   accuracy: 0.97404164  val_acc: 0.97508335
48000/48000 - 36s - loss: 0.0842 - accuracy: 0.9740 - val_loss: 0.0817 - val_accuracy: 0.9751
Epoch 4/10
 -> id = 18  Epoch: 4   accuracy: 0.9701875  val_acc: 0.96425
48000/48000 - 27s - loss: 0.1064 - accuracy: 0.9702 - val_loss: 0.1205 - val_accuracy: 0.9643
Epoch 6/10
 -> id = 8  Epoch: 3   accuracy: 0.9456458  val_acc: 0.96258336
48000/48000 - 28s - loss: 0.1832 - accuracy: 0.9456 - val_loss: 0.1335 - val_accuracy: 0.9626
Epoch 5/10
 -> id = 10  Epoch: 3   accuracy: 0.96727085  val_acc: 0.96325
48000/48000 - 31s - loss: 0.1097 - accuracy: 0.9673 - val_loss: 0.1217 - val_accuracy: 0.9632
Epoch 5/10
 -> id = 16  Epoch: 4   accuracy: 0.94825  val_acc: 0.9519167
48000/48000 - 27s - loss: 0.1799 - accuracy: 0.9482 - val_loss: 0.1738 - val_accuracy: 0.9519
Epoch 6/10
 -> id = 0  Epoch: 2   accuracy: 0.97333336  val_acc: 0.9759167
48000/48000 - 37s - loss: 0.0869 - accuracy: 0.9733 - val_loss: 0.0801 - val_accuracy: 0.9759
Epoch 4/10
 -> id = 6  Epoch: 3   accuracy: 0.968  val_acc: 0.96566665
48000/48000 - 30s - loss: 0.1080 - accuracy: 0.9680 - val_loss: 0.1163 - val_accuracy: 0.9657
Epoch 5/10
 -> id = 4  Epoch: 2   accuracy: 0.974875  val_acc: 0.97375
48000/48000 - 39s - loss: 0.0815 - accuracy: 0.9749 - val_loss: 0.0896 - val_accuracy: 0.9737
Epoch 4/10
 -> id = 15  Epoch: 3   accuracy: 0.9900417  val_acc: 0.9723333
 -> id = 5  Epoch: 3   accuracy: 0.98070836  val_acc: 0.97183335
48000/48000 - 29s - loss: 0.0342 - accuracy: 0.9900 - val_loss: 0.0923 - val_accuracy: 0.9723
48000/48000 - 32s - loss: 0.0674 - accuracy: 0.9807 - val_loss: 0.0946 - val_accuracy: 0.9718
Epoch 5/10Epoch 5/10

 -> id = 2  Epoch: 3   accuracy: 0.9710625  val_acc: 0.97608334
48000/48000 - 30s - loss: 0.0933 - accuracy: 0.9711 - val_loss: 0.0828 - val_accuracy: 0.9761
Epoch 5/10
 -> id = 9  Epoch: 4   accuracy: 0.98897916  val_acc: 0.9766667
48000/48000 - 27s - loss: 0.0384 - accuracy: 0.9890 - val_loss: 0.0801 - val_accuracy: 0.9767
Epoch 6/10
 -> id = 7  Epoch: 4   accuracy: 0.9586875  val_acc: 0.958
48000/48000 - 26s - loss: 0.1447 - accuracy: 0.9587 - val_loss: 0.1492 - val_accuracy: 0.9580
Epoch 6/10
 -> id = 12  Epoch: 3   accuracy: 0.95033336  val_acc: 0.9636667
48000/48000 - 33s - loss: 0.1645 - accuracy: 0.9503 - val_loss: 0.1354 - val_accuracy: 0.9637
Epoch 5/10
 -> id = 13  Epoch: 4   accuracy: 0.99160415  val_acc: 0.97816664
48000/48000 - 29s - loss: 0.0301 - accuracy: 0.9916 - val_loss: 0.0764 - val_accuracy: 0.9782
Epoch 6/10
 -> id = 17  Epoch: 2   accuracy: 0.9771042  val_acc: 0.97183335
48000/48000 - 44s - loss: 0.0831 - accuracy: 0.9771 - val_loss: 0.0974 - val_accuracy: 0.9718
Epoch 4/10
 -> id = 11  Epoch: 4   accuracy: 0.9732917  val_acc: 0.96825
48000/48000 - 31s - loss: 0.0905 - accuracy: 0.9733 - val_loss: 0.1095 - val_accuracy: 0.9682
Epoch 6/10
 -> id = 3  Epoch: 3   accuracy: 0.97729164  val_acc: 0.9759167
48000/48000 - 34s - loss: 0.0740 - accuracy: 0.9773 - val_loss: 0.0817 - val_accuracy: 0.9759
Epoch 5/10
 -> id = 18  Epoch: 5   accuracy: 0.97572917  val_acc: 0.96858335
48000/48000 - 26s - loss: 0.0880 - accuracy: 0.9757 - val_loss: 0.1087 - val_accuracy: 0.9686
Epoch 7/10
 -> id = 16  Epoch: 5   accuracy: 0.9546875  val_acc: 0.955
48000/48000 - 27s - loss: 0.1580 - accuracy: 0.9547 - val_loss: 0.1591 - val_accuracy: 0.9550
Epoch 7/10
 -> id = 8  Epoch: 4   accuracy: 0.9527917  val_acc: 0.967
 -> id = 14  Epoch: 4   accuracy: 0.9301042  val_acc: 0.93383336
48000/48000 - 29s - loss: 0.1572 - accuracy: 0.9528 - val_loss: 0.1164 - val_accuracy: 0.9670
48000/48000 - 32s - loss: 0.6117 - accuracy: 0.9301 - val_loss: 0.5454 - val_accuracy: 0.9338
Epoch 6/10
Epoch 6/10
 -> id = 19  Epoch: 3   accuracy: 0.9661458  val_acc: 0.9651667
48000/48000 - 34s - loss: 0.1111 - accuracy: 0.9661 - val_loss: 0.1179 - val_accuracy: 0.9652
Epoch 5/10
 -> id = 10  Epoch: 4   accuracy: 0.973875  val_acc: 0.96775
48000/48000 - 31s - loss: 0.0873 - accuracy: 0.9739 - val_loss: 0.1096 - val_accuracy: 0.9678
Epoch 6/10
 -> id = 6  Epoch: 4   accuracy: 0.97564584  val_acc: 0.9684167
48000/48000 - 30s - loss: 0.0838 - accuracy: 0.9756 - val_loss: 0.1093 - val_accuracy: 0.9684
Epoch 6/10
 -> id = 1  Epoch: 3   accuracy: 0.97933334  val_acc: 0.97675
48000/48000 - 37s - loss: 0.0643 - accuracy: 0.9793 - val_loss: 0.0808 - val_accuracy: 0.9768
Epoch 5/10
 -> id = 9  Epoch: 5   accuracy: 0.9925417  val_acc: 0.9780833
48000/48000 - 27s - loss: 0.0282 - accuracy: 0.9925 - val_loss: 0.0771 - val_accuracy: 0.9781
Epoch 7/10
 -> id = 15  Epoch: 4   accuracy: 0.9941667  val_acc: 0.975
48000/48000 - 30s - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.0887 - val_accuracy: 0.9750
Epoch 6/10
 -> id = 5  Epoch: 4   accuracy: 0.9853125  val_acc: 0.9745
48000/48000 - 31s - loss: 0.0525 - accuracy: 0.9853 - val_loss: 0.0918 - val_accuracy: 0.9745
Epoch 6/10
 -> id = 2  Epoch: 4   accuracy: 0.9763125  val_acc: 0.97575
48000/48000 - 30s - loss: 0.0784 - accuracy: 0.9763 - val_loss: 0.0800 - val_accuracy: 0.9758
Epoch 6/10
 -> id = 7  Epoch: 5   accuracy: 0.9635625  val_acc: 0.9623333
48000/48000 - 25s - loss: 0.1255 - accuracy: 0.9636 - val_loss: 0.1354 - val_accuracy: 0.9623
Epoch 7/10
 -> id = 0  Epoch: 3   accuracy: 0.97902083  val_acc: 0.9770833
48000/48000 - 38s - loss: 0.0690 - accuracy: 0.9790 - val_loss: 0.0774 - val_accuracy: 0.9771
Epoch 5/10
 -> id = 13  Epoch: 5   accuracy: 0.9945833  val_acc: 0.97816664
48000/48000 - 30s - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.0762 - val_accuracy: 0.9782
Epoch 7/10
 -> id = 4  Epoch: 3   accuracy: 0.9792708  val_acc: 0.9735
48000/48000 - 40s - loss: 0.0671 - accuracy: 0.9793 - val_loss: 0.0876 - val_accuracy: 0.9735
Epoch 5/10
 -> id = 12  Epoch: 4   accuracy: 0.961  val_acc: 0.96708333
48000/48000 - 33s - loss: 0.1307 - accuracy: 0.9610 - val_loss: 0.1168 - val_accuracy: 0.9671
Epoch 6/10
 -> id = 18  Epoch: 6   accuracy: 0.9806042  val_acc: 0.96966666
48000/48000 - 27s - loss: 0.0729 - accuracy: 0.9806 - val_loss: 0.1027 - val_accuracy: 0.9697
Epoch 8/10
 -> id = 11  Epoch: 5   accuracy: 0.98027086  val_acc: 0.971
48000/48000 - 31s - loss: 0.0693 - accuracy: 0.9803 - val_loss: 0.0971 - val_accuracy: 0.9710
Epoch 7/10
 -> id = 16  Epoch: 6   accuracy: 0.960125  val_acc: 0.959
48000/48000 - 28s - loss: 0.1394 - accuracy: 0.9601 - val_loss: 0.1458 - val_accuracy: 0.9590
Epoch 8/10
 -> id = 8  Epoch: 5   accuracy: 0.95929164  val_acc: 0.97008336
48000/48000 - 29s - loss: 0.1347 - accuracy: 0.9593 - val_loss: 0.1069 - val_accuracy: 0.9701
Epoch 7/10
 -> id = 3  Epoch: 4   accuracy: 0.97966665  val_acc: 0.97466666
48000/48000 - 35s - loss: 0.0654 - accuracy: 0.9797 - val_loss: 0.0835 - val_accuracy: 0.9747
Epoch 6/10
 -> id = 14  Epoch: 5   accuracy: 0.9340208  val_acc: 0.93441665
48000/48000 - 33s - loss: 0.5022 - accuracy: 0.9340 - val_loss: 0.4589 - val_accuracy: 0.9344
Epoch 7/10
 -> id = 10  Epoch: 5   accuracy: 0.9784375  val_acc: 0.9694167
48000/48000 - 32s - loss: 0.0705 - accuracy: 0.9784 - val_loss: 0.1057 - val_accuracy: 0.9694
Epoch 7/10
 -> id = 17  Epoch: 3   accuracy: 0.982375  val_acc: 0.97241664
48000/48000 - 44s - loss: 0.0616 - accuracy: 0.9824 - val_loss: 0.0947 - val_accuracy: 0.9724
Epoch 5/10
 -> id = 6  Epoch: 5   accuracy: 0.97966665  val_acc: 0.9716667
48000/48000 - 30s - loss: 0.0672 - accuracy: 0.9797 - val_loss: 0.0987 - val_accuracy: 0.9717
Epoch 7/10
 -> id = 19  Epoch: 4   accuracy: 0.9710625  val_acc: 0.96675
48000/48000 - 36s - loss: 0.0934 - accuracy: 0.9711 - val_loss: 0.1114 - val_accuracy: 0.9668
Epoch 6/10
 -> id = 9  Epoch: 6   accuracy: 0.99472916  val_acc: 0.9769167
48000/48000 - 28s - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.0759 - val_accuracy: 0.9769
Epoch 8/10
 -> id = 7  Epoch: 6   accuracy: 0.96710414  val_acc: 0.96183336
48000/48000 - 27s - loss: 0.1112 - accuracy: 0.9671 - val_loss: 0.1306 - val_accuracy: 0.9618
Epoch 8/10
 -> id = 15  Epoch: 5   accuracy: 0.9946667  val_acc: 0.9770833
48000/48000 - 31s - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.0863 - val_accuracy: 0.9771
Epoch 7/10
 -> id = 5  Epoch: 5   accuracy: 0.9890417  val_acc: 0.97358334
48000/48000 - 33s - loss: 0.0399 - accuracy: 0.9890 - val_loss: 0.0948 - val_accuracy: 0.9736
Epoch 7/10
 -> id = 2  Epoch: 5   accuracy: 0.9775  val_acc: 0.9769167
48000/48000 - 33s - loss: 0.0716 - accuracy: 0.9775 - val_loss: 0.0775 - val_accuracy: 0.9769
Epoch 7/10
 -> id = 1  Epoch: 4   accuracy: 0.9814583  val_acc: 0.97641665
48000/48000 - 38s - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.0788 - val_accuracy: 0.9764
Epoch 6/10
 -> id = 13  Epoch: 6   accuracy: 0.99589586  val_acc: 0.97641665
48000/48000 - 30s - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.0854 - val_accuracy: 0.9764
Epoch 8/10
 -> id = 0  Epoch: 4   accuracy: 0.9806875  val_acc: 0.9776667
48000/48000 - 38s - loss: 0.0605 - accuracy: 0.9807 - val_loss: 0.0778 - val_accuracy: 0.9777
Epoch 6/10
 -> id = 18  Epoch: 7   accuracy: 0.9844583  val_acc: 0.9715
48000/48000 - 27s - loss: 0.0607 - accuracy: 0.9845 - val_loss: 0.0955 - val_accuracy: 0.9715
Epoch 9/10
 -> id = 12  Epoch: 5   accuracy: 0.96827084  val_acc: 0.9694167
48000/48000 - 32s - loss: 0.1059 - accuracy: 0.9683 - val_loss: 0.1064 - val_accuracy: 0.9694
Epoch 7/10
 -> id = 16  Epoch: 7   accuracy: 0.9649792  val_acc: 0.9604167
48000/48000 - 27s - loss: 0.1240 - accuracy: 0.9650 - val_loss: 0.1369 - val_accuracy: 0.9604
Epoch 9/10
 -> id = 11  Epoch: 6   accuracy: 0.9826875  val_acc: 0.97291666
48000/48000 - 30s - loss: 0.0562 - accuracy: 0.9827 - val_loss: 0.0883 - val_accuracy: 0.9729
Epoch 8/10
 -> id = 8  Epoch: 6   accuracy: 0.96229166  val_acc: 0.97225
48000/48000 - 28s - loss: 0.1213 - accuracy: 0.9623 - val_loss: 0.0978 - val_accuracy: 0.9722
Epoch 8/10
 -> id = 4  Epoch: 4   accuracy: 0.98204166  val_acc: 0.97675
48000/48000 - 41s - loss: 0.0575 - accuracy: 0.9820 - val_loss: 0.0795 - val_accuracy: 0.9768
Epoch 6/10
 -> id = 7  Epoch: 7   accuracy: 0.9715833  val_acc: 0.96491665
48000/48000 - 26s - loss: 0.0980 - accuracy: 0.9716 - val_loss: 0.1255 - val_accuracy: 0.9649
Epoch 9/10
 -> id = 14  Epoch: 6   accuracy: 0.9364167  val_acc: 0.93658334
48000/48000 - 32s - loss: 0.4278 - accuracy: 0.9364 - val_loss: 0.3998 - val_accuracy: 0.9366
Epoch 8/10
 -> id = 6  Epoch: 6   accuracy: 0.98408335  val_acc: 0.97291666
48000/48000 - 30s - loss: 0.0540 - accuracy: 0.9841 - val_loss: 0.0892 - val_accuracy: 0.9729
Epoch 8/10
 -> id = 10  Epoch: 6   accuracy: 0.982  val_acc: 0.9713333
48000/48000 - 32s - loss: 0.0583 - accuracy: 0.9820 - val_loss: 0.0944 - val_accuracy: 0.9713
Epoch 8/10
 -> id = 9  Epoch: 7   accuracy: 0.99645835  val_acc: 0.97866666
48000/48000 - 29s - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.0743 - val_accuracy: 0.9787
Epoch 9/10
 -> id = 3  Epoch: 5   accuracy: 0.981875  val_acc: 0.9788333
48000/48000 - 36s - loss: 0.0575 - accuracy: 0.9819 - val_loss: 0.0747 - val_accuracy: 0.9788
Epoch 7/10
 -> id = 15  Epoch: 6   accuracy: 0.99560416  val_acc: 0.97291666
48000/48000 - 30s - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.0968 - val_accuracy: 0.9729
Epoch 8/10
 -> id = 19  Epoch: 5   accuracy: 0.9739375  val_acc: 0.9701667
48000/48000 - 36s - loss: 0.0798 - accuracy: 0.9739 - val_loss: 0.1040 - val_accuracy: 0.9702
Epoch 7/10
 -> id = 2  Epoch: 6   accuracy: 0.98020834  val_acc: 0.9775
48000/48000 - 30s - loss: 0.0630 - accuracy: 0.9802 - val_loss: 0.0777 - val_accuracy: 0.9775
Epoch 8/10
 -> id = 5  Epoch: 6   accuracy: 0.99139583  val_acc: 0.97291666
48000/48000 - 32s - loss: 0.0322 - accuracy: 0.9914 - val_loss: 0.0945 - val_accuracy: 0.9729
Epoch 8/10
 -> id = 18  Epoch: 8   accuracy: 0.9869583  val_acc: 0.97225
48000/48000 - 26s - loss: 0.0515 - accuracy: 0.9870 - val_loss: 0.0955 - val_accuracy: 0.9722
Epoch 10/10
 -> id = 13  Epoch: 7   accuracy: 0.9977083  val_acc: 0.9795833
48000/48000 - 28s - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.0723 - val_accuracy: 0.9796
Epoch 9/10
 -> id = 17  Epoch: 4   accuracy: 0.98704165  val_acc: 0.97216666
48000/48000 - 44s - loss: 0.0457 - accuracy: 0.9870 - val_loss: 0.0931 - val_accuracy: 0.9722
Epoch 6/10
 -> id = 16  Epoch: 8   accuracy: 0.96845835  val_acc: 0.96391666
48000/48000 - 26s - loss: 0.1110 - accuracy: 0.9685 - val_loss: 0.1279 - val_accuracy: 0.9639
Epoch 10/10
 -> id = 1  Epoch: 5   accuracy: 0.98410416  val_acc: 0.9776667
48000/48000 - 36s - loss: 0.0501 - accuracy: 0.9841 - val_loss: 0.0756 - val_accuracy: 0.9777
Epoch 7/10
 -> id = 12  Epoch: 6   accuracy: 0.9726667  val_acc: 0.97258335
48000/48000 - 32s - loss: 0.0888 - accuracy: 0.9727 - val_loss: 0.0941 - val_accuracy: 0.9726
Epoch 8/10
 -> id = 11  Epoch: 7   accuracy: 0.98760414  val_acc: 0.97283334
48000/48000 - 30s - loss: 0.0434 - accuracy: 0.9876 - val_loss: 0.0879 - val_accuracy: 0.9728
Epoch 9/10
 -> id = 8  Epoch: 7   accuracy: 0.96752083  val_acc: 0.9748333
48000/48000 - 29s - loss: 0.1077 - accuracy: 0.9675 - val_loss: 0.0900 - val_accuracy: 0.9748
Epoch 9/10
 -> id = 0  Epoch: 5   accuracy: 0.9828333  val_acc: 0.97858334
48000/48000 - 37s - loss: 0.0538 - accuracy: 0.9828 - val_loss: 0.0738 - val_accuracy: 0.9786
Epoch 7/10
 -> id = 7  Epoch: 8   accuracy: 0.97389585  val_acc: 0.96433336
48000/48000 - 25s - loss: 0.0894 - accuracy: 0.9739 - val_loss: 0.1234 - val_accuracy: 0.9643
Epoch 10/10
 -> id = 9  Epoch: 8   accuracy: 0.9980417  val_acc: 0.9785
48000/48000 - 29s - loss: 0.0108 - accuracy: 0.9980 - val_loss: 0.0736 - val_accuracy: 0.9785
Epoch 10/10
 -> id = 6  Epoch: 7   accuracy: 0.9870625  val_acc: 0.9740833
48000/48000 - 30s - loss: 0.0438 - accuracy: 0.9871 - val_loss: 0.0871 - val_accuracy: 0.9741
Epoch 9/10
 -> id = 14  Epoch: 7   accuracy: 0.93885416  val_acc: 0.93825
48000/48000 - 31s - loss: 0.3756 - accuracy: 0.9389 - val_loss: 0.3594 - val_accuracy: 0.9383
Epoch 9/10
 -> id = 10  Epoch: 7   accuracy: 0.98466665  val_acc: 0.97183335
48000/48000 - 31s - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.0961 - val_accuracy: 0.9718
Epoch 9/10
 -> id = 4  Epoch: 5   accuracy: 0.984375  val_acc: 0.97725
48000/48000 - 39s - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0779 - val_accuracy: 0.9772
Epoch 7/10
 -> id = 3  Epoch: 6   accuracy: 0.98377085  val_acc: 0.97791666
48000/48000 - 34s - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0772 - val_accuracy: 0.9779
Epoch 8/10
 -> id = 15  Epoch: 7   accuracy: 0.9969375  val_acc: 0.9748333
48000/48000 - 31s - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0890 - val_accuracy: 0.9748
Epoch 9/10
 -> id = 18  Epoch: 9   accuracy: 0.9896875  val_acc: 0.9719167
48000/48000 - 26s - loss: 0.0433 - accuracy: 0.9897 - val_loss: 0.0917 - val_accuracy: 0.9719
 -> id = 2  Epoch: 7   accuracy: 0.9805833  val_acc: 0.97833335
48000/48000 - 30s - loss: 0.0609 - accuracy: 0.9806 - val_loss: 0.0765 - val_accuracy: 0.9783
Epoch 9/10
 -> id = 13  Epoch: 8   accuracy: 0.99864584  val_acc: 0.978
48000/48000 - 29s - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0792 - val_accuracy: 0.9780
Epoch 10/10
 -> id = 16  Epoch: 9   accuracy: 0.9728125  val_acc: 0.9655
48000/48000 - 26s - loss: 0.0991 - accuracy: 0.9728 - val_loss: 0.1191 - val_accuracy: 0.9655
 -> id = 5  Epoch: 7   accuracy: 0.9935833  val_acc: 0.97391665
48000/48000 - 31s - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0958 - val_accuracy: 0.9739
Epoch 9/10
 -> id = 19  Epoch: 6   accuracy: 0.9782917  val_acc: 0.97258335
48000/48000 - 34s - loss: 0.0672 - accuracy: 0.9783 - val_loss: 0.0969 - val_accuracy: 0.9726
Epoch 8/10
 -> id = 11  Epoch: 8   accuracy: 0.99010414  val_acc: 0.97333336
48000/48000 - 29s - loss: 0.0341 - accuracy: 0.9901 - val_loss: 0.0856 - val_accuracy: 0.9733
Epoch 10/10
 -> id = 7  Epoch: 9   accuracy: 0.9759167  val_acc: 0.96641666
48000/48000 - 26s - loss: 0.0821 - accuracy: 0.9759 - val_loss: 0.1202 - val_accuracy: 0.9664
 -> id = 8  Epoch: 8   accuracy: 0.96991664  val_acc: 0.9755833
48000/48000 - 29s - loss: 0.0966 - accuracy: 0.9699 - val_loss: 0.0851 - val_accuracy: 0.9756
Epoch 10/10
 -> id = 1  Epoch: 6   accuracy: 0.9838333  val_acc: 0.9775
48000/48000 - 36s - loss: 0.0486 - accuracy: 0.9838 - val_loss: 0.0782 - val_accuracy: 0.9775
Epoch 8/10
 -> id = 12  Epoch: 7   accuracy: 0.97672915  val_acc: 0.97275
48000/48000 - 33s - loss: 0.0753 - accuracy: 0.9767 - val_loss: 0.0954 - val_accuracy: 0.9728
Epoch 9/10
 -> id = 9  Epoch: 9   accuracy: 0.9985625  val_acc: 0.97975
48000/48000 - 27s - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.0742 - val_accuracy: 0.9797
 -> id = 17  Epoch: 5   accuracy: 0.99039584  val_acc: 0.97358334
48000/48000 - 44s - loss: 0.0352 - accuracy: 0.9904 - val_loss: 0.0944 - val_accuracy: 0.9736
Epoch 7/10
 -> id = 0  Epoch: 6   accuracy: 0.98529166  val_acc: 0.9775
48000/48000 - 37s - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.0780 - val_accuracy: 0.9775
Epoch 8/10
 -> id = 6  Epoch: 8   accuracy: 0.98995835  val_acc: 0.976
48000/48000 - 30s - loss: 0.0352 - accuracy: 0.9900 - val_loss: 0.0836 - val_accuracy: 0.9760
Epoch 10/10
 -> id = 10  Epoch: 8   accuracy: 0.9881875  val_acc: 0.97475
48000/48000 - 30s - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.0885 - val_accuracy: 0.9747
Epoch 10/10
 -> id = 14  Epoch: 8   accuracy: 0.9407708  val_acc: 0.93875
48000/48000 - 31s - loss: 0.3379 - accuracy: 0.9408 - val_loss: 0.3301 - val_accuracy: 0.9388
Epoch 10/10
 -> id = 15  Epoch: 8   accuracy: 0.9981875  val_acc: 0.9773333
48000/48000 - 28s - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0848 - val_accuracy: 0.9773
Epoch 10/10
 -> id = 2  Epoch: 8   accuracy: 0.98322916  val_acc: 0.97833335
48000/48000 - 29s - loss: 0.0535 - accuracy: 0.9832 - val_loss: 0.0739 - val_accuracy: 0.9783
Epoch 10/10
 -> id = 3  Epoch: 7   accuracy: 0.9859167  val_acc: 0.9788333
48000/48000 - 33s - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.0704 - val_accuracy: 0.9788
Epoch 9/10
 -> id = 13  Epoch: 9   accuracy: 0.99925  val_acc: 0.97925
48000/48000 - 28s - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0765 - val_accuracy: 0.9793
 -> id = 4  Epoch: 6   accuracy: 0.984625  val_acc: 0.97866666
48000/48000 - 38s - loss: 0.0472 - accuracy: 0.9846 - val_loss: 0.0751 - val_accuracy: 0.9787
Epoch 8/10
 -> id = 5  Epoch: 8   accuracy: 0.99472916  val_acc: 0.97541666
48000/48000 - 30s - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.0966 - val_accuracy: 0.9754
Epoch 10/10
 -> id = 19  Epoch: 7   accuracy: 0.9812083  val_acc: 0.97358334
48000/48000 - 31s - loss: 0.0577 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9736
Epoch 9/10
 -> id = 8  Epoch: 9   accuracy: 0.97216666  val_acc: 0.97716665
48000/48000 - 26s - loss: 0.0880 - accuracy: 0.9722 - val_loss: 0.0818 - val_accuracy: 0.9772
 -> id = 11  Epoch: 9   accuracy: 0.992625  val_acc: 0.97508335
48000/48000 - 27s - loss: 0.0266 - accuracy: 0.9926 - val_loss: 0.0826 - val_accuracy: 0.9751
 -> id = 12  Epoch: 8   accuracy: 0.9806875  val_acc: 0.9745
48000/48000 - 29s - loss: 0.0639 - accuracy: 0.9807 - val_loss: 0.0892 - val_accuracy: 0.9745
Epoch 10/10
 -> id = 1  Epoch: 7   accuracy: 0.98564583  val_acc: 0.9795833
48000/48000 - 33s - loss: 0.0448 - accuracy: 0.9856 - val_loss: 0.0708 - val_accuracy: 0.9796
Epoch 9/10
 -> id = 6  Epoch: 9   accuracy: 0.99160415  val_acc: 0.97641665
48000/48000 - 25s - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0847 - val_accuracy: 0.9764
 -> id = 15  Epoch: 9   accuracy: 0.9982708  val_acc: 0.9735
48000/48000 - 23s - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0979 - val_accuracy: 0.9735
 -> id = 10  Epoch: 9   accuracy: 0.9897083  val_acc: 0.9723333
48000/48000 - 25s - loss: 0.0327 - accuracy: 0.9897 - val_loss: 0.0964 - val_accuracy: 0.9723
 -> id = 14  Epoch: 9   accuracy: 0.9423958  val_acc: 0.93875
48000/48000 - 25s - loss: 0.3108 - accuracy: 0.9424 - val_loss: 0.3092 - val_accuracy: 0.9388
 -> id = 0  Epoch: 7   accuracy: 0.98616666  val_acc: 0.97875
48000/48000 - 30s - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.0767 - val_accuracy: 0.9787
Epoch 9/10
 -> id = 2  Epoch: 9   accuracy: 0.9828333  val_acc: 0.97825
48000/48000 - 22s - loss: 0.0534 - accuracy: 0.9828 - val_loss: 0.0747 - val_accuracy: 0.9783
 -> id = 3  Epoch: 8   accuracy: 0.98645836  val_acc: 0.97858334
48000/48000 - 24s - loss: 0.0428 - accuracy: 0.9865 - val_loss: 0.0761 - val_accuracy: 0.9786
Epoch 10/10
 -> id = 17  Epoch: 6   accuracy: 0.99291664  val_acc: 0.97433335
48000/48000 - 35s - loss: 0.0261 - accuracy: 0.9929 - val_loss: 0.0932 - val_accuracy: 0.9743
Epoch 8/10
 -> id = 5  Epoch: 9   accuracy: 0.9958125  val_acc: 0.97425
48000/48000 - 20s - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.1013 - val_accuracy: 0.9743
 -> id = 19  Epoch: 8   accuracy: 0.982875  val_acc: 0.9741667
48000/48000 - 24s - loss: 0.0525 - accuracy: 0.9829 - val_loss: 0.0937 - val_accuracy: 0.9742
Epoch 10/10
 -> id = 4  Epoch: 7   accuracy: 0.9866458  val_acc: 0.98025
48000/48000 - 27s - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.0712 - val_accuracy: 0.9803
Epoch 9/10
 -> id = 12  Epoch: 9   accuracy: 0.9830833  val_acc: 0.97566664
48000/48000 - 19s - loss: 0.0540 - accuracy: 0.9831 - val_loss: 0.0872 - val_accuracy: 0.9757
 -> id = 1  Epoch: 8   accuracy: 0.9878125  val_acc: 0.98008335
48000/48000 - 19s - loss: 0.0373 - accuracy: 0.9878 - val_loss: 0.0691 - val_accuracy: 0.9801
Epoch 10/10
 -> id = 0  Epoch: 8   accuracy: 0.98639584  val_acc: 0.9780833
48000/48000 - 17s - loss: 0.0411 - accuracy: 0.9864 - val_loss: 0.0776 - val_accuracy: 0.9781
Epoch 10/10
 -> id = 3  Epoch: 9   accuracy: 0.98670834  val_acc: 0.979
48000/48000 - 14s - loss: 0.0396 - accuracy: 0.9867 - val_loss: 0.0701 - val_accuracy: 0.9790
 -> id = 19  Epoch: 9   accuracy: 0.98495835  val_acc: 0.9748333
48000/48000 - 16s - loss: 0.0456 - accuracy: 0.9850 - val_loss: 0.0928 - val_accuracy: 0.9748
 -> id = 17  Epoch: 7   accuracy: 0.994625  val_acc: 0.9755
48000/48000 - 22s - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.0921 - val_accuracy: 0.9755
Epoch 9/10
 -> id = 4  Epoch: 8   accuracy: 0.98820835  val_acc: 0.97758335
48000/48000 - 17s - loss: 0.0355 - accuracy: 0.9882 - val_loss: 0.0811 - val_accuracy: 0.9776
Epoch 10/10
 -> id = 1  Epoch: 9   accuracy: 0.988  val_acc: 0.9798333
48000/48000 - 14s - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.0748 - val_accuracy: 0.9798
 -> id = 0  Epoch: 9   accuracy: 0.9868542  val_acc: 0.98083335
48000/48000 - 12s - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.0720 - val_accuracy: 0.9808
 -> id = 4  Epoch: 9   accuracy: 0.98864585  val_acc: 0.97975
48000/48000 - 9s - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.0772 - val_accuracy: 0.9797
 -> id = 17  Epoch: 8   accuracy: 0.9959583  val_acc: 0.9759167
48000/48000 - 10s - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.0978 - val_accuracy: 0.9759
Epoch 10/10
 -> id = 17  Epoch: 9   accuracy: 0.99714583  val_acc: 0.97566664
48000/48000 - 5s - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.0954 - val_accuracy: 0.9757
 id = 0  val_accuracy = 0.9808333516120911
 id = 1  val_accuracy = 0.9798333048820496
 id = 4  val_accuracy = 0.9797499775886536
