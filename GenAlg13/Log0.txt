2020-03-26 17:39:19.590943: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-03-26 17:39:19.598369: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  0   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2020-03-26 17:39:23.919013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-03-26 17:39:23.951007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s
2020-03-26 17:39:23.957156: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-03-26 17:39:23.963980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-03-26 17:39:23.970551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-03-26 17:39:23.974413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-03-26 17:39:23.982260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-03-26 17:39:23.987349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-03-26 17:39:23.991261: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found
2020-03-26 17:39:23.994172: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-03-26 17:39:24.001981: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-03-26 17:39:24.012742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 17:39:24.016092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense (Dense)                (None, 370)               290450
_________________________________________________________________
activation (Activation)      (None, 370)               0
_________________________________________________________________
dense_1 (Dense)              (None, 1460)              541660
_________________________________________________________________
activation_1 (Activation)    (None, 1460)              0
_________________________________________________________________
batch_normalization (BatchNo (None, 1460)              5840
_________________________________________________________________
dense_2 (Dense)              (None, 1680)              2454480
_________________________________________________________________
activation_2 (Activation)    (None, 1680)              0
_________________________________________________________________
dropout (Dropout)            (None, 1680)              0
_________________________________________________________________
batch_normalization_1 (Batch (None, 1680)              6720
_________________________________________________________________
dense_3 (Dense)              (None, 880)               1479280
_________________________________________________________________
activation_3 (Activation)    (None, 880)               0
_________________________________________________________________
dense_4 (Dense)              (None, 10)                8810
=================================================================
Total params: 4,787,240
Trainable params: 4,780,960
Non-trainable params: 6,280
_________________________________________________________________
None
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_5 (Dense)              (None, 10)                7850
_________________________________________________________________
activation_4 (Activation)    (None, 10)                0
_________________________________________________________________
dropout_1 (Dropout)          (None, 10)                0
_________________________________________________________________
dense_6 (Dense)              (None, 1300)              14300
_________________________________________________________________
activation_5 (Activation)    (None, 1300)              0
_________________________________________________________________
dense_7 (Dense)              (None, 1640)              2133640
_________________________________________________________________
activation_6 (Activation)    (None, 1640)              0
_________________________________________________________________
dropout_2 (Dropout)          (None, 1640)              0
_________________________________________________________________
batch_normalization_2 (Batch (None, 1640)              6560
_________________________________________________________________
dense_8 (Dense)              (None, 680)               1115880
_________________________________________________________________
activation_7 (Activation)    (None, 680)               0
_________________________________________________________________
dense_9 (Dense)              (None, 10)                6810
=================================================================
Total params: 3,285,040
Trainable params: 3,281,760
Non-trainable params: 3,280
_________________________________________________________________
None
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_10 (Dense)             (None, 780)               612300
_________________________________________________________________
activation_8 (Activation)    (None, 780)               0
_________________________________________________________________
dropout_3 (Dropout)          (None, 780)               0
_________________________________________________________________
dense_11 (Dense)             (None, 700)               546700
_________________________________________________________________
activation_9 (Activation)    (None, 700)               0
_________________________________________________________________
dropout_4 (Dropout)          (None, 700)               0
_________________________________________________________________
batch_normalization_3 (Batch (None, 700)               2800
_________________________________________________________________
dense_12 (Dense)             (None, 1780)              1247780
_________________________________________________________________
activation_10 (Activation)   (None, 1780)              0
_________________________________________________________________
dense_13 (Dense)             (None, 1290)              2297490
_________________________________________________________________
activation_11 (Activation)   (None, 1290)              0
_________________________________________________________________
dense_14 (Dense)             (None, 790)               1019890
_________________________________________________________________
activation_12 (Activation)   (None, 790)               0
_________________________________________________________________
dense_15 (Dense)             (None, 890)               703990
_________________________________________________________________
activation_13 (Activation)   (None, 890)               0
_________________________________________________________________
dense_16 (Dense)             (None, 10)                8910
=================================================================
Total params: 6,439,860
Trainable params: 6,438,460
Non-trainable params: 1,400
_________________________________________________________________
None
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_17 (Dense)             (None, 1410)              1106850
_________________________________________________________________
activation_14 (Activation)   (None, 1410)              0
_________________________________________________________________
dropout_5 (Dropout)          (None, 1410)              0
_________________________________________________________________
dense_18 (Dense)             (None, 1790)              2525690
_________________________________________________________________
activation_15 (Activation)   (None, 1790)              0
_________________________________________________________________
dropout_6 (Dropout)          (None, 1790)              0
_________________________________________________________________
batch_normalization_4 (Batch (None, 1790)              7160
_________________________________________________________________
dense_19 (Dense)             (None, 1390)              2489490
_________________________________________________________________
activation_16 (Activation)   (None, 1390)              0
_________________________________________________________________
dense_20 (Dense)             (None, 100)               139100
_________________________________________________________________
activation_17 (Activation)   (None, 100)               0
_________________________________________________________________
batch_normalization_5 (Batch (None, 100)               400
_________________________________________________________________
dense_21 (Dense)             (None, 1340)              135340
_________________________________________________________________
activation_18 (Activation)   (None, 1340)              0
_________________________________________________________________
dropout_7 (Dropout)          (None, 1340)              0
_________________________________________________________________
dense_22 (Dense)             (None, 1560)              2091960
_________________________________________________________________
activation_19 (Activation)   (None, 1560)              0
_________________________________________________________________
dropout_8 (Dropout)          (None, 1560)              0
_________________________________________________________________
dense_23 (Dense)             (None, 1290)              2013690
_________________________________________________________________
activation_20 (Activation)   (None, 1290)              0
_________________________________________________________________
batch_normalization_6 (Batch (None, 1290)              5160
_________________________________________________________________
dense_24 (Dense)             (None, 110)               142010
_________________________________________________________________
activation_21 (Activation)   (None, 110)               0
_________________________________________________________________
dropout_9 (Dropout)          (None, 110)               0
_________________________________________________________________
dense_25 (Dense)             (None, 170)               18870
_________________________________________________________________
activation_22 (Activation)   (None, 170)               0
_________________________________________________________________
dense_26 (Dense)             (None, 10)                1710
=================================================================
Total params: 10,677,430
Trainable params: 10,671,070
Non-trainable params: 6,360
_________________________________________________________________
None
Model: "model_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_27 (Dense)             (None, 1150)              902750
_________________________________________________________________
activation_23 (Activation)   (None, 1150)              0
_________________________________________________________________
dense_28 (Dense)             (None, 10)                11510
=================================================================
Total params: 914,260
Trainable params: 914,260
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_29 (Dense)             (None, 150)               117750
_________________________________________________________________
activation_24 (Activation)   (None, 150)               0
_________________________________________________________________
batch_normalization_7 (Batch (None, 150)               600
_________________________________________________________________
dense_30 (Dense)             (None, 1970)              297470
_________________________________________________________________
activation_25 (Activation)   (None, 1970)              0
_________________________________________________________________
dropout_10 (Dropout)         (None, 1970)              0
_________________________________________________________________
dense_31 (Dense)             (None, 1920)              3784320
_________________________________________________________________
activation_26 (Activation)   (None, 1920)              0
_________________________________________________________________
dropout_11 (Dropout)         (None, 1920)              0
_________________________________________________________________
batch_normalization_8 (Batch (None, 1920)              7680
_________________________________________________________________
dense_32 (Dense)             (None, 1360)              2612560
_________________________________________________________________
activation_27 (Activation)   (None, 1360)              0
_________________________________________________________________
batch_normalization_9 (Batch (None, 1360)              5440
_________________________________________________________________
dense_33 (Dense)             (None, 770)               1047970
_________________________________________________________________
activation_28 (Activation)   (None, 770)               0
_________________________________________________________________
dense_34 (Dense)             (None, 10)                7710
=================================================================
Total params: 7,881,500
Trainable params: 7,874,640
Non-trainable params: 6,860
_________________________________________________________________
None
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_35 (Dense)             (None, 1050)              824250
_________________________________________________________________
activation_29 (Activation)   (None, 1050)              0
_________________________________________________________________
batch_normalization_10 (Batc (None, 1050)              4200
_________________________________________________________________
dense_36 (Dense)             (None, 1200)              1261200
_________________________________________________________________
activation_30 (Activation)   (None, 1200)              0
_________________________________________________________________
dropout_12 (Dropout)         (None, 1200)              0
_________________________________________________________________
dense_37 (Dense)             (None, 1180)              1417180
_________________________________________________________________
activation_31 (Activation)   (None, 1180)              0
_________________________________________________________________
dropout_13 (Dropout)         (None, 1180)              0
_________________________________________________________________
batch_normalization_11 (Batc (None, 1180)              4720
_________________________________________________________________
dense_38 (Dense)             (None, 460)               543260
_________________________________________________________________
activation_32 (Activation)   (None, 460)               0
_________________________________________________________________
dropout_14 (Dropout)         (None, 460)               0
_________________________________________________________________
batch_normalization_12 (Batc (None, 460)               1840
_________________________________________________________________
dense_39 (Dense)             (None, 710)               327310
_________________________________________________________________
activation_33 (Activation)   (None, 710)               0
_________________________________________________________________
batch_normalization_13 (Batc (None, 710)               2840
_________________________________________________________________
dense_40 (Dense)             (None, 420)               298620
_________________________________________________________________
activation_34 (Activation)   (None, 420)               0
_________________________________________________________________
dropout_15 (Dropout)         (None, 420)               0
_________________________________________________________________
dense_41 (Dense)             (None, 10)                4210
=================================================================
Total params: 4,689,630
Trainable params: 4,682,830
Non-trainable params: 6,800
_________________________________________________________________
None
Model: "model_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_42 (Dense)             (None, 1060)              832100
_________________________________________________________________
activation_35 (Activation)   (None, 1060)              0
_________________________________________________________________
dropout_16 (Dropout)         (None, 1060)              0
_________________________________________________________________
batch_normalization_14 (Batc (None, 1060)              4240
_________________________________________________________________
dense_43 (Dense)             (None, 1890)              2005290
_________________________________________________________________
activation_36 (Activation)   (None, 1890)              0
_________________________________________________________________
dropout_17 (Dropout)         (None, 1890)              0
_________________________________________________________________
dense_44 (Dense)             (None, 940)               1777540
_________________________________________________________________
activation_37 (Activation)   (None, 940)               0
_________________________________________________________________
batch_normalization_15 (Batc (None, 940)               3760
_________________________________________________________________
dense_45 (Dense)             (None, 580)               545780
_________________________________________________________________
activation_38 (Activation)   (None, 580)               0
_________________________________________________________________
dense_46 (Dense)             (None, 350)               203350
_________________________________________________________________
activation_39 (Activation)   (None, 350)               0
_________________________________________________________________
dropout_18 (Dropout)         (None, 350)               0
_________________________________________________________________
dense_47 (Dense)             (None, 670)               235170
_________________________________________________________________
activation_40 (Activation)   (None, 670)               0
_________________________________________________________________
batch_normalization_16 (Batc (None, 670)               2680
_________________________________________________________________
dense_48 (Dense)             (None, 880)               590480
_________________________________________________________________
activation_41 (Activation)   (None, 880)               0
_________________________________________________________________
dropout_19 (Dropout)         (None, 880)               0
_________________________________________________________________
batch_normalization_17 (Batc (None, 880)               3520
_________________________________________________________________
dense_49 (Dense)             (None, 370)               325970
_________________________________________________________________
activation_42 (Activation)   (None, 370)               0
_________________________________________________________________
batch_normalization_18 (Batc (None, 370)               1480
_________________________________________________________________
dense_50 (Dense)             (None, 90)                33390
_________________________________________________________________
activation_43 (Activation)   (None, 90)                0
_________________________________________________________________
dense_51 (Dense)             (None, 10)                910
=================================================================
Total params: 6,565,660
Trainable params: 6,557,820
Non-trainable params: 7,840
_________________________________________________________________
None
Model: "model_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_52 (Dense)             (None, 650)               510250
_________________________________________________________________
activation_44 (Activation)   (None, 650)               0
_________________________________________________________________
dropout_20 (Dropout)         (None, 650)               0
_________________________________________________________________
dense_53 (Dense)             (None, 1750)              1139250
_________________________________________________________________
activation_45 (Activation)   (None, 1750)              0
_________________________________________________________________
dropout_21 (Dropout)         (None, 1750)              0
_________________________________________________________________
batch_normalization_19 (Batc (None, 1750)              7000
_________________________________________________________________
dense_54 (Dense)             (None, 820)               1435820
_________________________________________________________________
activation_46 (Activation)   (None, 820)               0
_________________________________________________________________
dense_55 (Dense)             (None, 10)                8210
=================================================================
Total params: 3,100,530
Trainable params: 3,097,030
Non-trainable params: 3,500
_________________________________________________________________
None
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_56 (Dense)             (None, 1990)              1562150
_________________________________________________________________
activation_47 (Activation)   (None, 1990)              0
_________________________________________________________________
dense_57 (Dense)             (None, 1540)              3066140
_________________________________________________________________
activation_48 (Activation)   (None, 1540)              0
_________________________________________________________________
batch_normalization_20 (Batc (None, 1540)              6160
_________________________________________________________________
dense_58 (Dense)             (None, 1470)              2265270
_________________________________________________________________
activation_49 (Activation)   (None, 1470)              0
_________________________________________________________________
batch_normalization_21 (Batc (None, 1470)              5880
_________________________________________________________________
dense_59 (Dense)             (None, 10)                14710
=================================================================
Total params: 6,920,310
Trainable params: 6,914,290
Non-trainable params: 6,020
_________________________________________________________________
None
Model: "model_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_60 (Dense)             (None, 1130)              887050
_________________________________________________________________
activation_50 (Activation)   (None, 1130)              0
_________________________________________________________________
dropout_22 (Dropout)         (None, 1130)              0
_________________________________________________________________
batch_normalization_22 (Batc (None, 1130)              4520
_________________________________________________________________
dense_61 (Dense)             (None, 210)               237510
_________________________________________________________________
activation_51 (Activation)   (None, 210)               0
_________________________________________________________________
dense_62 (Dense)             (None, 590)               124490
_________________________________________________________________
activation_52 (Activation)   (None, 590)               0
_________________________________________________________________
batch_normalization_23 (Batc (None, 590)               2360
_________________________________________________________________
dense_63 (Dense)             (None, 440)               260040
_________________________________________________________________
activation_53 (Activation)   (None, 440)               0
_________________________________________________________________
dropout_23 (Dropout)         (None, 440)               0
_________________________________________________________________
batch_normalization_24 (Batc (None, 440)               1760
_________________________________________________________________
dense_64 (Dense)             (None, 1540)              679140
_________________________________________________________________
activation_54 (Activation)   (None, 1540)              0
_________________________________________________________________
dropout_24 (Dropout)         (None, 1540)              0
_________________________________________________________________
batch_normalization_25 (Batc (None, 1540)              6160
_________________________________________________________________
dense_65 (Dense)             (None, 10)                15410
=================================================================
Total params: 2,218,440
Trainable params: 2,211,040
Non-trainable params: 7,400
_________________________________________________________________
None
Model: "model_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_66 (Dense)             (None, 330)               259050
_________________________________________________________________
activation_55 (Activation)   (None, 330)               0
_________________________________________________________________
dense_67 (Dense)             (None, 1930)              638830
_________________________________________________________________
activation_56 (Activation)   (None, 1930)              0
_________________________________________________________________
dropout_25 (Dropout)         (None, 1930)              0
_________________________________________________________________
batch_normalization_26 (Batc (None, 1930)              7720
_________________________________________________________________
dense_68 (Dense)             (None, 1930)              3726830
_________________________________________________________________
activation_57 (Activation)   (None, 1930)              0
_________________________________________________________________
dropout_26 (Dropout)         (None, 1930)              0
_________________________________________________________________
dense_69 (Dense)             (None, 1350)              2606850
_________________________________________________________________
activation_58 (Activation)   (None, 1350)              0
_________________________________________________________________
batch_normalization_27 (Batc (None, 1350)              5400
_________________________________________________________________
dense_70 (Dense)             (None, 10)                13510
=================================================================
Total params: 7,258,190
Trainable params: 7,251,630
Non-trainable params: 6,560
_________________________________________________________________
None
Model: "model_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_71 (Dense)             (None, 1310)              1028350
_________________________________________________________________
activation_59 (Activation)   (None, 1310)              0
_________________________________________________________________
batch_normalization_28 (Batc (None, 1310)              5240
_________________________________________________________________
dense_72 (Dense)             (None, 1980)              2595780
_________________________________________________________________
activation_60 (Activation)   (None, 1980)              0
_________________________________________________________________
dropout_27 (Dropout)         (None, 1980)              0
_________________________________________________________________
dense_73 (Dense)             (None, 60)                118860
_________________________________________________________________
activation_61 (Activation)   (None, 60)                0
_________________________________________________________________
dropout_28 (Dropout)         (None, 60)                0
_________________________________________________________________
dense_74 (Dense)             (None, 1340)              81740
_________________________________________________________________
activation_62 (Activation)   (None, 1340)              0
_________________________________________________________________
dropout_29 (Dropout)         (None, 1340)              0
_________________________________________________________________
dense_75 (Dense)             (None, 540)               724140
_________________________________________________________________
activation_63 (Activation)   (None, 540)               0
_________________________________________________________________
batch_normalization_29 (Batc (None, 540)               2160
_________________________________________________________________
dense_76 (Dense)             (None, 1380)              746580
_________________________________________________________________
activation_64 (Activation)   (None, 1380)              0
_________________________________________________________________
dense_77 (Dense)             (None, 10)                13810
=================================================================
Total params: 5,316,660
Trainable params: 5,312,960
Non-trainable params: 3,700
_________________________________________________________________
None
Model: "model_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_78 (Dense)             (None, 1730)              1358050
_________________________________________________________________
activation_65 (Activation)   (None, 1730)              0
_________________________________________________________________
dense_79 (Dense)             (None, 1650)              2856150
_________________________________________________________________
activation_66 (Activation)   (None, 1650)              0
_________________________________________________________________
batch_normalization_30 (Batc (None, 1650)              6600
_________________________________________________________________
dense_80 (Dense)             (None, 10)                16510
=================================================================
Total params: 4,237,310
Trainable params: 4,234,010
Non-trainable params: 3,300
_________________________________________________________________
None
Model: "model_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_81 (Dense)             (None, 1920)              1507200
_________________________________________________________________
activation_67 (Activation)   (None, 1920)              0
_________________________________________________________________
dropout_30 (Dropout)         (None, 1920)              0
_________________________________________________________________
dense_82 (Dense)             (None, 10)                19210
=================================================================
Total params: 1,526,410
Trainable params: 1,526,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_83 (Dense)             (None, 180)               141300
_________________________________________________________________
activation_68 (Activation)   (None, 180)               0
_________________________________________________________________
dropout_31 (Dropout)         (None, 180)               0
_________________________________________________________________
batch_normalization_31 (Batc (None, 180)               720
_________________________________________________________________
dense_84 (Dense)             (None, 10)                1810
=================================================================
Total params: 143,830
Trainable params: 143,470
Non-trainable params: 360
_________________________________________________________________
None
Model: "model_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_85 (Dense)             (None, 1490)              1169650
_________________________________________________________________
activation_69 (Activation)   (None, 1490)              0
_________________________________________________________________
dropout_32 (Dropout)         (None, 1490)              0
_________________________________________________________________
batch_normalization_32 (Batc (None, 1490)              5960
_________________________________________________________________
dense_86 (Dense)             (None, 870)               1297170
_________________________________________________________________
activation_70 (Activation)   (None, 870)               0
_________________________________________________________________
dropout_33 (Dropout)         (None, 870)               0
_________________________________________________________________
dense_87 (Dense)             (None, 610)               531310
_________________________________________________________________
activation_71 (Activation)   (None, 610)               0
_________________________________________________________________
dense_88 (Dense)             (None, 10)                6110
=================================================================
Total params: 3,010,200
Trainable params: 3,007,220
Non-trainable params: 2,980
_________________________________________________________________
None
Model: "model_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_89 (Dense)             (None, 110)               86350
_________________________________________________________________
activation_72 (Activation)   (None, 110)               0
_________________________________________________________________
dropout_34 (Dropout)         (None, 110)               0
_________________________________________________________________
batch_normalization_33 (Batc (None, 110)               440
_________________________________________________________________
dense_90 (Dense)             (None, 1520)              168720
_________________________________________________________________
activation_73 (Activation)   (None, 1520)              0
_________________________________________________________________
batch_normalization_34 (Batc (None, 1520)              6080
_________________________________________________________________
dense_91 (Dense)             (None, 10)                15210
=================================================================
Total params: 276,800
Trainable params: 273,540
Non-trainable params: 3,260
_________________________________________________________________
None
Model: "model_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_92 (Dense)             (None, 1420)              1114700
_________________________________________________________________
activation_74 (Activation)   (None, 1420)              0
_________________________________________________________________
dropout_35 (Dropout)         (None, 1420)              0
_________________________________________________________________
batch_normalization_35 (Batc (None, 1420)              5680
_________________________________________________________________
dense_93 (Dense)             (None, 1000)              1421000
_________________________________________________________________
activation_75 (Activation)   (None, 1000)              0
_________________________________________________________________
dropout_36 (Dropout)         (None, 1000)              0
_________________________________________________________________
batch_normalization_36 (Batc (None, 1000)              4000
_________________________________________________________________
dense_94 (Dense)             (None, 1190)              1191190
_________________________________________________________________
activation_76 (Activation)   (None, 1190)              0
_________________________________________________________________
dropout_37 (Dropout)         (None, 1190)              0
_________________________________________________________________
batch_normalization_37 (Batc (None, 1190)              4760
_________________________________________________________________
dense_95 (Dense)             (None, 10)                11910
=================================================================
Total params: 3,753,240
Trainable params: 3,746,020
Non-trainable params: 7,220
_________________________________________________________________
None
Model: "model_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_96 (Dense)             (None, 1730)              1358050
_________________________________________________________________
activation_77 (Activation)   (None, 1730)              0
_________________________________________________________________
dense_97 (Dense)             (None, 1940)              3358140
_________________________________________________________________
activation_78 (Activation)   (None, 1940)              0
_________________________________________________________________
dropout_38 (Dropout)         (None, 1940)              0
_________________________________________________________________
dense_98 (Dense)             (None, 1600)              3105600
_________________________________________________________________
activation_79 (Activation)   (None, 1600)              0
_________________________________________________________________
dense_99 (Dense)             (None, 1960)              3137960
_________________________________________________________________
activation_80 (Activation)   (None, 1960)              0
_________________________________________________________________
dropout_39 (Dropout)         (None, 1960)              0
_________________________________________________________________
batch_normalization_38 (Batc (None, 1960)              7840
_________________________________________________________________
dense_100 (Dense)            (None, 1010)              1980610
_________________________________________________________________
activation_81 (Activation)   (None, 1010)              0
_________________________________________________________________
batch_normalization_39 (Batc (None, 1010)              4040
_________________________________________________________________
dense_101 (Dense)            (None, 940)               950340
_________________________________________________________________
activation_82 (Activation)   (None, 940)               0
_________________________________________________________________
dropout_40 (Dropout)         (None, 940)               0
_________________________________________________________________
batch_normalization_40 (Batc (None, 940)               3760
_________________________________________________________________
dense_102 (Dense)            (None, 770)               724570
_________________________________________________________________
activation_83 (Activation)   (None, 770)               0
_________________________________________________________________
dropout_41 (Dropout)         (None, 770)               0
_________________________________________________________________
batch_normalization_41 (Batc (None, 770)               3080
_________________________________________________________________
dense_103 (Dense)            (None, 10)                7710
=================================================================
Total params: 14,641,700
Trainable params: 14,632,340
Non-trainable params: 9,360
_________________________________________________________________
None
Model: "model_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_104 (Dense)            (None, 170)               133450
_________________________________________________________________
activation_84 (Activation)   (None, 170)               0
_________________________________________________________________
dropout_42 (Dropout)         (None, 170)               0
_________________________________________________________________
batch_normalization_42 (Batc (None, 170)               680
_________________________________________________________________
dense_105 (Dense)            (None, 250)               42750
_________________________________________________________________
activation_85 (Activation)   (None, 250)               0
_________________________________________________________________
dense_106 (Dense)            (None, 1840)              461840
_________________________________________________________________
activation_86 (Activation)   (None, 1840)              0
_________________________________________________________________
dense_107 (Dense)            (None, 1080)              1988280
_________________________________________________________________
activation_87 (Activation)   (None, 1080)              0
_________________________________________________________________
batch_normalization_43 (Batc (None, 1080)              4320
_________________________________________________________________
dense_108 (Dense)            (None, 1450)              1567450
_________________________________________________________________
activation_88 (Activation)   (None, 1450)              0
_________________________________________________________________
dense_109 (Dense)            (None, 330)               478830
_________________________________________________________________
activation_89 (Activation)   (None, 330)               0
_________________________________________________________________
dropout_43 (Dropout)         (None, 330)               0
_________________________________________________________________
dense_110 (Dense)            (None, 1740)              575940
_________________________________________________________________
activation_90 (Activation)   (None, 1740)              0
_________________________________________________________________
dropout_44 (Dropout)         (None, 1740)              0
_________________________________________________________________
batch_normalization_44 (Batc (None, 1740)              6960
_________________________________________________________________
dense_111 (Dense)            (None, 1280)              2228480
_________________________________________________________________
activation_91 (Activation)   (None, 1280)              0
_________________________________________________________________
batch_normalization_45 (Batc (None, 1280)              5120
_________________________________________________________________
dense_112 (Dense)            (None, 680)               871080
_________________________________________________________________
activation_92 (Activation)   (None, 680)               0
_________________________________________________________________
batch_normalization_46 (Batc (None, 680)               2720
_________________________________________________________________
dense_113 (Dense)            (None, 10)                6810
=================================================================
Total params: 8,374,710
Trainable params: 8,364,810
Non-trainable params: 9,900
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesEpoch 1/10
Epoch 1/10

Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples

Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samplesEpoch 1/10Train on 48000 samples, validate on 12000 samples
Epoch 1/10Epoch 1/10


Epoch 1/10

Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Epoch 1/10
 -> id = 4  Epoch: 0   accuracy: 0.8635  val_acc: 0.91508335
48000/48000 - 40s - loss: 0.4935 - accuracy: 0.8635 - val_loss: 0.2952 - val_accuracy: 0.9151
Epoch 2/10
 -> id = 14  Epoch: 0   accuracy: 0.89427084  val_acc: 0.93341666
48000/48000 - 42s - loss: 0.3537 - accuracy: 0.8943 - val_loss: 0.2374 - val_accuracy: 0.9334
Epoch 2/10
 -> id = 15  Epoch: 0   accuracy: 0.8716458  val_acc: 0.95016664
48000/48000 - 69s - loss: 0.4301 - accuracy: 0.8716 - val_loss: 0.1997 - val_accuracy: 0.9502
Epoch 2/10
 -> id = 13  Epoch: 0   accuracy: 0.903875  val_acc: 0.8865833
48000/48000 - 194s - loss: 0.3348 - accuracy: 0.9039 - val_loss: 0.3997 - val_accuracy: 0.8866
Epoch 2/10
 -> id = 17  Epoch: 0   accuracy: 0.8787708  val_acc: 0.85716665
48000/48000 - 205s - loss: 0.4876 - accuracy: 0.8788 - val_loss: 1.4740 - val_accuracy: 0.8572
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.5634375  val_acc: 0.58283335
48000/48000 - 228s - loss: 2.0571 - accuracy: 0.5634 - val_loss: 1.8759 - val_accuracy: 0.5828
Epoch 2/10
 -> id = 8  Epoch: 0   accuracy: 0.2411875  val_acc: 0.17241667
48000/48000 - 256s - loss: 1.9821 - accuracy: 0.2412 - val_loss: 2.0783 - val_accuracy: 0.1724
Epoch 2/10
 -> id = 4  Epoch: 1   accuracy: 0.915875  val_acc: 0.9266667
48000/48000 - 221s - loss: 0.2934 - accuracy: 0.9159 - val_loss: 0.2607 - val_accuracy: 0.9267
Epoch 3/10
 -> id = 1  Epoch: 0   accuracy: 0.6466042  val_acc: 0.72491664
48000/48000 - 263s - loss: 2.0177 - accuracy: 0.6466 - val_loss: 1.7717 - val_accuracy: 0.7249
Epoch 2/10
 -> id = 14  Epoch: 1   accuracy: 0.93052083  val_acc: 0.94491667
48000/48000 - 224s - loss: 0.2385 - accuracy: 0.9305 - val_loss: 0.1925 - val_accuracy: 0.9449
Epoch 3/10
 -> id = 9  Epoch: 0   accuracy: 0.93041664  val_acc: 0.33758333
48000/48000 - 281s - loss: 0.2456 - accuracy: 0.9304 - val_loss: 1.9373 - val_accuracy: 0.3376
Epoch 2/10
 -> id = 0  Epoch: 0   accuracy: 0.8250625  val_acc: 0.87775
48000/48000 - 289s - loss: 0.6906 - accuracy: 0.8251 - val_loss: 0.5719 - val_accuracy: 0.8777
Epoch 2/10
 -> id = 15  Epoch: 1   accuracy: 0.93691665  val_acc: 0.9633333
48000/48000 - 221s - loss: 0.2190 - accuracy: 0.9369 - val_loss: 0.1296 - val_accuracy: 0.9633
Epoch 3/10
 -> id = 10  Epoch: 0   accuracy: 0.760375  val_acc: 0.47383332
48000/48000 - 301s - loss: 0.7601 - accuracy: 0.7604 - val_loss: 1.7769 - val_accuracy: 0.4738
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.89720833  val_acc: 0.93866664
48000/48000 - 302s - loss: 0.3555 - accuracy: 0.8972 - val_loss: 0.2010 - val_accuracy: 0.9387
Epoch 2/10
 -> id = 5  Epoch: 0   accuracy: 0.8999583  val_acc: 0.41333333
48000/48000 - 320s - loss: 0.3771 - accuracy: 0.9000 - val_loss: 1.5189 - val_accuracy: 0.4133
Epoch 2/10
 -> id = 18  Epoch: 0   accuracy: 0.8230208  val_acc: 0.92583334
48000/48000 - 322s - loss: 0.5807 - accuracy: 0.8230 - val_loss: 0.3899 - val_accuracy: 0.9258
Epoch 2/10
 -> id = 2  Epoch: 0   accuracy: 0.09841666  val_acc: 0.0995
48000/48000 - 327s - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0995
Epoch 2/10
 -> id = 12  Epoch: 0   accuracy: 0.10822917  val_acc: 0.0995
48000/48000 - 338s - loss: nan - accuracy: 0.1082 - val_loss: nan - val_accuracy: 0.0995
Epoch 2/10
 -> id = 11  Epoch: 0   accuracy: 0.89816666  val_acc: 0.19075
48000/48000 - 351s - loss: 0.3438 - accuracy: 0.8982 - val_loss: 2.1511 - val_accuracy: 0.1908
Epoch 2/10
 -> id = 7  Epoch: 0   accuracy: 0.6555625  val_acc: 0.0995
48000/48000 - 364s - loss: nan - accuracy: 0.6556 - val_loss: nan - val_accuracy: 0.0995
Epoch 2/10
 -> id = 17  Epoch: 1   accuracy: 0.9532083  val_acc: 0.96241665
48000/48000 - 188s - loss: 0.1556 - accuracy: 0.9532 - val_loss: 0.1683 - val_accuracy: 0.9624
Epoch 3/10
 -> id = 3  Epoch: 0   accuracy: 0.7966875  val_acc: 0.63266665
48000/48000 - 401s - loss: 0.7704 - accuracy: 0.7967 - val_loss: 1.6571 - val_accuracy: 0.6327
Epoch 2/10
 -> id = 20  Epoch: 0   accuracy: 0.7730208  val_acc: 0.91066664
48000/48000 - 403s - loss: 0.8090 - accuracy: 0.7730 - val_loss: 0.3108 - val_accuracy: 0.9107
Epoch 2/10
 -> id = 13  Epoch: 1   accuracy: 0.9533542  val_acc: 0.94491667
48000/48000 - 231s - loss: 0.1596 - accuracy: 0.9534 - val_loss: 0.1949 - val_accuracy: 0.9449
Epoch 3/10
 -> id = 16  Epoch: 1   accuracy: 0.48410416  val_acc: 0.5075833
48000/48000 - 247s - loss: 1.8692 - accuracy: 0.4841 - val_loss: 1.7760 - val_accuracy: 0.5076
Epoch 3/10
 -> id = 19  Epoch: 0   accuracy: 0.34147915  val_acc: 0.20875
48000/48000 - 482s - loss: 1.7055 - accuracy: 0.3415 - val_loss: 2.0691 - val_accuracy: 0.2087
Epoch 2/10
 -> id = 4  Epoch: 2   accuracy: 0.927625  val_acc: 0.9353333
48000/48000 - 221s - loss: 0.2501 - accuracy: 0.9276 - val_loss: 0.2267 - val_accuracy: 0.9353
Epoch 4/10
 -> id = 14  Epoch: 2   accuracy: 0.9434583  val_acc: 0.95308334
48000/48000 - 220s - loss: 0.1891 - accuracy: 0.9435 - val_loss: 0.1632 - val_accuracy: 0.9531
Epoch 4/10
 -> id = 15  Epoch: 2   accuracy: 0.9499375  val_acc: 0.9669167
48000/48000 - 200s - loss: 0.1712 - accuracy: 0.9499 - val_loss: 0.1141 - val_accuracy: 0.9669
Epoch 4/10
 -> id = 1  Epoch: 1   accuracy: 0.71552086  val_acc: 0.74633336
48000/48000 - 247s - loss: 1.6048 - accuracy: 0.7155 - val_loss: 1.4020 - val_accuracy: 0.7463
Epoch 3/10
 -> id = 8  Epoch: 1   accuracy: 0.395625  val_acc: 0.51266664
48000/48000 - 254s - loss: 1.4204 - accuracy: 0.3956 - val_loss: 1.1976 - val_accuracy: 0.5127
Epoch 3/10
 -> id = 10  Epoch: 1   accuracy: 0.8940833  val_acc: 0.83033335
48000/48000 - 210s - loss: 0.3593 - accuracy: 0.8941 - val_loss: 1.3927 - val_accuracy: 0.8303
Epoch 3/10
 -> id = 6  Epoch: 1   accuracy: 0.9451042  val_acc: 0.95825
48000/48000 - 236s - loss: 0.1898 - accuracy: 0.9451 - val_loss: 0.1549 - val_accuracy: 0.9582
Epoch 3/10
 -> id = 9  Epoch: 1   accuracy: 0.9587708  val_acc: 0.54891664
48000/48000 - 260s - loss: 0.1387 - accuracy: 0.9588 - val_loss: 313.6371 - val_accuracy: 0.5489
Epoch 3/10
 -> id = 0  Epoch: 1   accuracy: 0.8336667  val_acc: 0.91116667
48000/48000 - 261s - loss: 0.6442 - accuracy: 0.8337 - val_loss: 0.3578 - val_accuracy: 0.9112
Epoch 3/10
 -> id = 5  Epoch: 1   accuracy: 0.94245833  val_acc: 0.94233334
48000/48000 - 241s - loss: 0.2185 - accuracy: 0.9425 - val_loss: 0.2198 - val_accuracy: 0.9423
Epoch 3/10
 -> id = 17  Epoch: 2   accuracy: 0.9670208  val_acc: 0.9659167
48000/48000 - 179s - loss: 0.1072 - accuracy: 0.9670 - val_loss: 0.1123 - val_accuracy: 0.9659
Epoch 4/10
 -> id = 18  Epoch: 1   accuracy: 0.9222292  val_acc: 0.95608336
48000/48000 - 258s - loss: 0.2543 - accuracy: 0.9222 - val_loss: 0.1999 - val_accuracy: 0.9561
Epoch 3/10
 -> id = 12  Epoch: 1   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 275s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 3/10
 -> id = 2  Epoch: 1   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 289s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 3/10
 -> id = 11  Epoch: 1   accuracy: 0.9471458  val_acc: 0.9241667
48000/48000 - 281s - loss: 0.1755 - accuracy: 0.9471 - val_loss: 0.2560 - val_accuracy: 0.9242
Epoch 3/10
 -> id = 7  Epoch: 1   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 290s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 3/10
 -> id = 13  Epoch: 2   accuracy: 0.9675417  val_acc: 0.9655
48000/48000 - 248s - loss: 0.1062 - accuracy: 0.9675 - val_loss: 0.1168 - val_accuracy: 0.9655
Epoch 4/10
 -> id = 4  Epoch: 3   accuracy: 0.9387917  val_acc: 0.9464167
48000/48000 - 203s - loss: 0.2089 - accuracy: 0.9388 - val_loss: 0.1947 - val_accuracy: 0.9464
Epoch 5/10
 -> id = 15  Epoch: 3   accuracy: 0.95597917  val_acc: 0.9701667
48000/48000 - 203s - loss: 0.1467 - accuracy: 0.9560 - val_loss: 0.1028 - val_accuracy: 0.9702
Epoch 5/10
 -> id = 14  Epoch: 3   accuracy: 0.9505  val_acc: 0.9601667
48000/48000 - 226s - loss: 0.1616 - accuracy: 0.9505 - val_loss: 0.1406 - val_accuracy: 0.9602
Epoch 5/10
 -> id = 16  Epoch: 2   accuracy: 0.426  val_acc: 0.41383332
48000/48000 - 240s - loss: 1.8386 - accuracy: 0.4260 - val_loss: 1.8479 - val_accuracy: 0.4138
Epoch 4/10
 -> id = 10  Epoch: 2   accuracy: 0.92658335  val_acc: 0.8171667
48000/48000 - 216s - loss: 0.2524 - accuracy: 0.9266 - val_loss: 1.2323 - val_accuracy: 0.8172
Epoch 4/10
 -> id = 3  Epoch: 1   accuracy: 0.9198125  val_acc: 0.94075
48000/48000 - 336s - loss: 0.3458 - accuracy: 0.9198 - val_loss: 0.2505 - val_accuracy: 0.9408
Epoch 3/10
 -> id = 20  Epoch: 1   accuracy: 0.89035416  val_acc: 0.93125
48000/48000 - 334s - loss: 0.3861 - accuracy: 0.8904 - val_loss: 0.2519 - val_accuracy: 0.9312
Epoch 3/10
 -> id = 17  Epoch: 3   accuracy: 0.9756042  val_acc: 0.96575
48000/48000 - 180s - loss: 0.0801 - accuracy: 0.9756 - val_loss: 0.1190 - val_accuracy: 0.9657
Epoch 5/10
 -> id = 1  Epoch: 2   accuracy: 0.72683334  val_acc: 0.75408334
48000/48000 - 250s - loss: 1.3038 - accuracy: 0.7268 - val_loss: 1.1347 - val_accuracy: 0.7541
Epoch 4/10
 -> id = 8  Epoch: 2   accuracy: 0.5379375  val_acc: 0.80583334
48000/48000 - 251s - loss: 1.1872 - accuracy: 0.5379 - val_loss: 0.7270 - val_accuracy: 0.8058
Epoch 4/10
 -> id = 6  Epoch: 2   accuracy: 0.95827085  val_acc: 0.9655833
48000/48000 - 224s - loss: 0.1403 - accuracy: 0.9583 - val_loss: 0.1203 - val_accuracy: 0.9656
Epoch 4/10
 -> id = 0  Epoch: 2   accuracy: 0.88  val_acc: 0.9163333
48000/48000 - 258s - loss: 0.4687 - accuracy: 0.8800 - val_loss: 0.3206 - val_accuracy: 0.9163
Epoch 4/10
 -> id = 5  Epoch: 2   accuracy: 0.95210415  val_acc: 0.94491667
48000/48000 - 254s - loss: 0.1765 - accuracy: 0.9521 - val_loss: 0.2109 - val_accuracy: 0.9449
Epoch 4/10
 -> id = 9  Epoch: 2   accuracy: 0.96254164  val_acc: 0.36558333
48000/48000 - 275s - loss: 0.1217 - accuracy: 0.9625 - val_loss: 1917.1444 - val_accuracy: 0.3656
Epoch 4/10
 -> id = 18  Epoch: 2   accuracy: 0.9419583  val_acc: 0.96033335
48000/48000 - 267s - loss: 0.1901 - accuracy: 0.9420 - val_loss: 0.1647 - val_accuracy: 0.9603
Epoch 4/10
 -> id = 19  Epoch: 1   accuracy: 0.34585416  val_acc: 0.24308333
48000/48000 - 396s - loss: 1.6650 - accuracy: 0.3459 - val_loss: 1.8934 - val_accuracy: 0.2431
Epoch 3/10
 -> id = 2  Epoch: 2   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 271s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 4/10
 -> id = 12  Epoch: 2   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 275s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 4/10
 -> id = 15  Epoch: 4   accuracy: 0.9600833  val_acc: 0.97283334
48000/48000 - 195s - loss: 0.1328 - accuracy: 0.9601 - val_loss: 0.0947 - val_accuracy: 0.9728
Epoch 6/10
 -> id = 4  Epoch: 4   accuracy: 0.9509583  val_acc: 0.95233333
48000/48000 - 204s - loss: 0.1708 - accuracy: 0.9510 - val_loss: 0.1679 - val_accuracy: 0.9523
Epoch 6/10
 -> id = 13  Epoch: 3   accuracy: 0.97577083  val_acc: 0.9713333
48000/48000 - 225s - loss: 0.0796 - accuracy: 0.9758 - val_loss: 0.1027 - val_accuracy: 0.9713
Epoch 5/10
 -> id = 14  Epoch: 4   accuracy: 0.9582292  val_acc: 0.9633333
48000/48000 - 213s - loss: 0.1366 - accuracy: 0.9582 - val_loss: 0.1272 - val_accuracy: 0.9633
Epoch 6/10
 -> id = 11  Epoch: 2   accuracy: 0.95966667  val_acc: 0.96375
48000/48000 - 293s - loss: 0.1348 - accuracy: 0.9597 - val_loss: 0.1374 - val_accuracy: 0.9638
Epoch 4/10
 -> id = 10  Epoch: 3   accuracy: 0.94366664  val_acc: 0.8354167
48000/48000 - 202s - loss: 0.1951 - accuracy: 0.9437 - val_loss: 1.2469 - val_accuracy: 0.8354
Epoch 5/10
 -> id = 7  Epoch: 2   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 279s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 4/10
 -> id = 17  Epoch: 4   accuracy: 0.98085415  val_acc: 0.97083336
48000/48000 - 180s - loss: 0.0615 - accuracy: 0.9809 - val_loss: 0.0952 - val_accuracy: 0.9708
Epoch 6/10
 -> id = 16  Epoch: 3   accuracy: 0.3790625  val_acc: 0.41925
48000/48000 - 234s - loss: 1.8342 - accuracy: 0.3791 - val_loss: 1.7000 - val_accuracy: 0.4193
Epoch 5/10
 -> id = 1  Epoch: 3   accuracy: 0.73358333  val_acc: 0.7518333
48000/48000 - 239s - loss: 1.0921 - accuracy: 0.7336 - val_loss: 0.9629 - val_accuracy: 0.7518
Epoch 5/10
 -> id = 8  Epoch: 3   accuracy: 0.63633335  val_acc: 0.8944167
48000/48000 - 239s - loss: 1.0081 - accuracy: 0.6363 - val_loss: 0.4902 - val_accuracy: 0.8944
Epoch 5/10
 -> id = 6  Epoch: 3   accuracy: 0.96314585  val_acc: 0.9661667
48000/48000 - 239s - loss: 0.1235 - accuracy: 0.9631 - val_loss: 0.1249 - val_accuracy: 0.9662
Epoch 5/10
 -> id = 20  Epoch: 2   accuracy: 0.914375  val_acc: 0.94775
48000/48000 - 311s - loss: 0.3033 - accuracy: 0.9144 - val_loss: 0.1828 - val_accuracy: 0.9477
Epoch 4/10
 -> id = 0  Epoch: 3   accuracy: 0.91847914  val_acc: 0.92266667
48000/48000 - 255s - loss: 0.3111 - accuracy: 0.9185 - val_loss: 0.3121 - val_accuracy: 0.9227
Epoch 5/10
 -> id = 5  Epoch: 3   accuracy: 0.957  val_acc: 0.9573333
48000/48000 - 252s - loss: 0.1586 - accuracy: 0.9570 - val_loss: 0.2042 - val_accuracy: 0.9573
Epoch 5/10
 -> id = 9  Epoch: 3   accuracy: 0.96760416  val_acc: 0.38533333
48000/48000 - 256s - loss: 0.1078 - accuracy: 0.9676 - val_loss: 2604.4828 - val_accuracy: 0.3853
Epoch 5/10
 -> id = 3  Epoch: 2   accuracy: 0.93627083  val_acc: 0.95175
48000/48000 - 346s - loss: 0.2850 - accuracy: 0.9363 - val_loss: 0.2326 - val_accuracy: 0.9517
Epoch 4/10
 -> id = 15  Epoch: 5   accuracy: 0.96283334  val_acc: 0.97241664
48000/48000 - 205s - loss: 0.1195 - accuracy: 0.9628 - val_loss: 0.0922 - val_accuracy: 0.9724
Epoch 7/10
 -> id = 4  Epoch: 5   accuracy: 0.959875  val_acc: 0.95858335
48000/48000 - 205s - loss: 0.1397 - accuracy: 0.9599 - val_loss: 0.1465 - val_accuracy: 0.9586
Epoch 7/10
 -> id = 18  Epoch: 3   accuracy: 0.9503125  val_acc: 0.96925
48000/48000 - 254s - loss: 0.1581 - accuracy: 0.9503 - val_loss: 0.1542 - val_accuracy: 0.9693
Epoch 5/10
 -> id = 17  Epoch: 5   accuracy: 0.983625  val_acc: 0.9730833
48000/48000 - 176s - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.0941 - val_accuracy: 0.9731
Epoch 7/10
 -> id = 14  Epoch: 5   accuracy: 0.9631875  val_acc: 0.9663333
48000/48000 - 212s - loss: 0.1189 - accuracy: 0.9632 - val_loss: 0.1190 - val_accuracy: 0.9663
Epoch 7/10
 -> id = 10  Epoch: 4   accuracy: 0.951  val_acc: 0.835
48000/48000 - 216s - loss: 0.1697 - accuracy: 0.9510 - val_loss: nan - val_accuracy: 0.8350
Epoch 6/10
 -> id = 13  Epoch: 4   accuracy: 0.9806042  val_acc: 0.96991664
48000/48000 - 249s - loss: 0.0634 - accuracy: 0.9806 - val_loss: 0.1132 - val_accuracy: 0.9699
Epoch 6/10
 -> id = 12  Epoch: 3   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 264s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 5/10
 -> id = 2  Epoch: 3   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 291s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 5/10
 -> id = 16  Epoch: 4   accuracy: 0.38741666  val_acc: 0.38083333
48000/48000 - 234s - loss: 1.7552 - accuracy: 0.3874 - val_loss: 1.6743 - val_accuracy: 0.3808
Epoch 6/10
 -> id = 11  Epoch: 3   accuracy: 0.9668958  val_acc: 0.96325
48000/48000 - 288s - loss: 0.1103 - accuracy: 0.9669 - val_loss: 0.1431 - val_accuracy: 0.9632
Epoch 5/10
 -> id = 7  Epoch: 3   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 283s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 5/10
 -> id = 6  Epoch: 4   accuracy: 0.9663125  val_acc: 0.96566665
48000/48000 - 222s - loss: 0.1126 - accuracy: 0.9663 - val_loss: 0.1258 - val_accuracy: 0.9657
Epoch 6/10
 -> id = 8  Epoch: 4   accuracy: 0.67597914  val_acc: 0.8803333
48000/48000 - 235s - loss: 0.8991 - accuracy: 0.6760 - val_loss: 0.4832 - val_accuracy: 0.8803
Epoch 6/10
 -> id = 1  Epoch: 4   accuracy: 0.73616666  val_acc: 0.75775
48000/48000 - 246s - loss: 0.9542 - accuracy: 0.7362 - val_loss: 0.8311 - val_accuracy: 0.7577
Epoch 6/10
 -> id = 17  Epoch: 6   accuracy: 0.987  val_acc: 0.97333336
48000/48000 - 173s - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0966 - val_accuracy: 0.9733
Epoch 8/10
 -> id = 19  Epoch: 2   accuracy: 0.26935416  val_acc: 0.25425
48000/48000 - 412s - loss: 1.8588 - accuracy: 0.2694 - val_loss: 1.7863 - val_accuracy: 0.2542
Epoch 4/10
 -> id = 15  Epoch: 6   accuracy: 0.96554166  val_acc: 0.97375
48000/48000 - 203s - loss: 0.1099 - accuracy: 0.9655 - val_loss: 0.0908 - val_accuracy: 0.9737
Epoch 8/10
 -> id = 0  Epoch: 4   accuracy: 0.9391875  val_acc: 0.9126667
48000/48000 - 251s - loss: 0.2317 - accuracy: 0.9392 - val_loss: 0.3907 - val_accuracy: 0.9127
Epoch 6/10
 -> id = 4  Epoch: 6   accuracy: 0.96639585  val_acc: 0.96375
48000/48000 - 223s - loss: 0.1167 - accuracy: 0.9664 - val_loss: 0.1285 - val_accuracy: 0.9638
Epoch 8/10
 -> id = 5  Epoch: 4   accuracy: 0.96620834  val_acc: 0.96166664
48000/48000 - 264s - loss: 0.1232 - accuracy: 0.9662 - val_loss: 0.1698 - val_accuracy: 0.9617
Epoch 6/10
 -> id = 9  Epoch: 4   accuracy: 0.9719375  val_acc: 0.6731667
48000/48000 - 276s - loss: 0.0887 - accuracy: 0.9719 - val_loss: 56.9043 - val_accuracy: 0.6732
Epoch 6/10
 -> id = 14  Epoch: 6   accuracy: 0.96752083  val_acc: 0.96541667
48000/48000 - 211s - loss: 0.1053 - accuracy: 0.9675 - val_loss: 0.1201 - val_accuracy: 0.9654
Epoch 8/10
 -> id = 20  Epoch: 3   accuracy: 0.9279375  val_acc: 0.95558333
48000/48000 - 306s - loss: 0.2583 - accuracy: 0.9279 - val_loss: 0.1708 - val_accuracy: 0.9556
Epoch 5/10
 -> id = 10  Epoch: 5   accuracy: 0.9557083  val_acc: 0.779
48000/48000 - 218s - loss: 0.1522 - accuracy: 0.9557 - val_loss: nan - val_accuracy: 0.7790
Epoch 7/10
 -> id = 13  Epoch: 5   accuracy: 0.98435414  val_acc: 0.96975
48000/48000 - 227s - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.1184 - val_accuracy: 0.9697
Epoch 7/10
 -> id = 18  Epoch: 4   accuracy: 0.95825  val_acc: 0.9698333
48000/48000 - 276s - loss: 0.1344 - accuracy: 0.9582 - val_loss: 0.1521 - val_accuracy: 0.9698
Epoch 6/10
 -> id = 3  Epoch: 3   accuracy: 0.94245833  val_acc: 0.953
48000/48000 - 339s - loss: 0.2612 - accuracy: 0.9425 - val_loss: 0.2008 - val_accuracy: 0.9530
Epoch 5/10
 -> id = 16  Epoch: 5   accuracy: 0.3934375  val_acc: 0.4135
48000/48000 - 243s - loss: 1.6989 - accuracy: 0.3934 - val_loss: 1.6048 - val_accuracy: 0.4135
Epoch 7/10
 -> id = 12  Epoch: 4   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 275s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 6/10
 -> id = 17  Epoch: 7   accuracy: 0.98889583  val_acc: 0.9738333
48000/48000 - 167s - loss: 0.0341 - accuracy: 0.9889 - val_loss: 0.0990 - val_accuracy: 0.9738
Epoch 9/10
 -> id = 6  Epoch: 5   accuracy: 0.9705  val_acc: 0.97275
48000/48000 - 231s - loss: 0.0955 - accuracy: 0.9705 - val_loss: 0.0970 - val_accuracy: 0.9728
Epoch 7/10
 -> id = 2  Epoch: 4   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 280s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 6/10
 -> id = 8  Epoch: 5   accuracy: 0.70252085  val_acc: 0.8265
48000/48000 - 236s - loss: 0.8420 - accuracy: 0.7025 - val_loss: 0.4760 - val_accuracy: 0.8265
Epoch 7/10
 -> id = 1  Epoch: 5   accuracy: 0.7390625  val_acc: 0.76066667
48000/48000 - 240s - loss: 0.8610 - accuracy: 0.7391 - val_loss: 0.7532 - val_accuracy: 0.7607
Epoch 7/10
 -> id = 15  Epoch: 7   accuracy: 0.9690625  val_acc: 0.9740833
48000/48000 - 196s - loss: 0.0992 - accuracy: 0.9691 - val_loss: 0.0874 - val_accuracy: 0.9741
Epoch 9/10
 -> id = 7  Epoch: 4   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 287s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 6/10
 -> id = 11  Epoch: 4   accuracy: 0.9745625  val_acc: 0.9663333
48000/48000 - 295s - loss: 0.0835 - accuracy: 0.9746 - val_loss: 0.1381 - val_accuracy: 0.9663
Epoch 6/10
 -> id = 4  Epoch: 7   accuracy: 0.97239584  val_acc: 0.9659167
48000/48000 - 208s - loss: 0.0969 - accuracy: 0.9724 - val_loss: 0.1169 - val_accuracy: 0.9659
Epoch 9/10
 -> id = 14  Epoch: 7   accuracy: 0.96860415  val_acc: 0.9705833
48000/48000 - 222s - loss: 0.1000 - accuracy: 0.9686 - val_loss: 0.1054 - val_accuracy: 0.9706
Epoch 9/10
 -> id = 10  Epoch: 6   accuracy: 0.9615625  val_acc: 0.8105
48000/48000 - 217s - loss: 0.1359 - accuracy: 0.9616 - val_loss: 182132.3957 - val_accuracy: 0.8105
Epoch 8/10
 -> id = 5  Epoch: 5   accuracy: 0.96958333  val_acc: 0.9590833
48000/48000 - 252s - loss: 0.1115 - accuracy: 0.9696 - val_loss: 0.1826 - val_accuracy: 0.9591
Epoch 7/10
 -> id = 0  Epoch: 5   accuracy: 0.94941664  val_acc: 0.838
48000/48000 - 271s - loss: 0.1957 - accuracy: 0.9494 - val_loss: 0.8631 - val_accuracy: 0.8380
Epoch 7/10
 -> id = 13  Epoch: 6   accuracy: 0.9874375  val_acc: 0.96683335
48000/48000 - 233s - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.1564 - val_accuracy: 0.9668
Epoch 8/10
 -> id = 9  Epoch: 5   accuracy: 0.97758335  val_acc: 0.71541667
48000/48000 - 284s - loss: 0.0727 - accuracy: 0.9776 - val_loss: 22.5254 - val_accuracy: 0.7154
Epoch 7/10
 -> id = 17  Epoch: 8   accuracy: 0.99104166  val_acc: 0.97358334
48000/48000 - 188s - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0995 - val_accuracy: 0.9736
Epoch 10/10
 -> id = 18  Epoch: 5   accuracy: 0.96239585  val_acc: 0.9705833
48000/48000 - 272s - loss: 0.1211 - accuracy: 0.9624 - val_loss: 0.1602 - val_accuracy: 0.9706
Epoch 7/10
 -> id = 16  Epoch: 6   accuracy: 0.40214583  val_acc: 0.42883334
48000/48000 - 238s - loss: 1.6463 - accuracy: 0.4021 - val_loss: 1.5323 - val_accuracy: 0.4288
Epoch 8/10
 -> id = 19  Epoch: 3   accuracy: 0.2078125  val_acc: 0.22316666
48000/48000 - 384s - loss: 2.0600 - accuracy: 0.2078 - val_loss: 2.0767 - val_accuracy: 0.2232
Epoch 5/10
 -> id = 20  Epoch: 4   accuracy: 0.9374375  val_acc: 0.95708334
48000/48000 - 323s - loss: 0.2248 - accuracy: 0.9374 - val_loss: 0.1565 - val_accuracy: 0.9571
Epoch 6/10
 -> id = 15  Epoch: 8   accuracy: 0.9689792  val_acc: 0.97433335
48000/48000 - 197s - loss: 0.0968 - accuracy: 0.9690 - val_loss: 0.0827 - val_accuracy: 0.9743
Epoch 10/10
 -> id = 6  Epoch: 6   accuracy: 0.9735208  val_acc: 0.96758336
48000/48000 - 236s - loss: 0.0899 - accuracy: 0.9735 - val_loss: 0.1150 - val_accuracy: 0.9676
Epoch 8/10
 -> id = 12  Epoch: 5   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 272s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 7/10
 -> id = 8  Epoch: 6   accuracy: 0.7233125  val_acc: 0.89816666
48000/48000 - 245s - loss: 0.7915 - accuracy: 0.7233 - val_loss: 0.4231 - val_accuracy: 0.8982
Epoch 8/10
 -> id = 1  Epoch: 6   accuracy: 0.7416667  val_acc: 0.7614167
48000/48000 - 238s - loss: 0.7952 - accuracy: 0.7417 - val_loss: 0.6971 - val_accuracy: 0.7614
Epoch 8/10
 -> id = 4  Epoch: 8   accuracy: 0.9770833  val_acc: 0.97025
48000/48000 - 207s - loss: 0.0813 - accuracy: 0.9771 - val_loss: 0.1065 - val_accuracy: 0.9703
Epoch 10/10
 -> id = 2  Epoch: 5   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 285s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 7/10
 -> id = 3  Epoch: 4   accuracy: 0.9454167  val_acc: 0.95958334
48000/48000 - 347s - loss: 0.2473 - accuracy: 0.9454 - val_loss: 0.1867 - val_accuracy: 0.9596
Epoch 6/10
 -> id = 7  Epoch: 5   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 280s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 7/10
 -> id = 14  Epoch: 8   accuracy: 0.97195834  val_acc: 0.9695
48000/48000 - 220s - loss: 0.0895 - accuracy: 0.9720 - val_loss: 0.1059 - val_accuracy: 0.9695
Epoch 10/10
 -> id = 10  Epoch: 7   accuracy: 0.96433336  val_acc: 0.8235
48000/48000 - 217s - loss: 0.1223 - accuracy: 0.9643 - val_loss: nan - val_accuracy: 0.8235
Epoch 9/10
 -> id = 11  Epoch: 5   accuracy: 0.9769792  val_acc: 0.96925
48000/48000 - 291s - loss: 0.0788 - accuracy: 0.9770 - val_loss: 0.1295 - val_accuracy: 0.9693
Epoch 7/10
 -> id = 17  Epoch: 9   accuracy: 0.99172914  val_acc: 0.97358334
48000/48000 - 174s - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.1046 - val_accuracy: 0.9736
 -> id = 5  Epoch: 6   accuracy: 0.969  val_acc: 0.966
48000/48000 - 254s - loss: 0.1116 - accuracy: 0.9690 - val_loss: 0.1595 - val_accuracy: 0.9660
Epoch 8/10
 -> id = 13  Epoch: 7   accuracy: 0.98808336  val_acc: 0.97225
48000/48000 - 235s - loss: 0.0364 - accuracy: 0.9881 - val_loss: 0.1156 - val_accuracy: 0.9722
Epoch 9/10
 -> id = 0  Epoch: 6   accuracy: 0.95725  val_acc: 0.9299167
48000/48000 - 257s - loss: 0.1603 - accuracy: 0.9572 - val_loss: 0.2952 - val_accuracy: 0.9299
Epoch 8/10
 -> id = 15  Epoch: 9   accuracy: 0.9711667  val_acc: 0.9765
48000/48000 - 197s - loss: 0.0917 - accuracy: 0.9712 - val_loss: 0.0831 - val_accuracy: 0.9765
 -> id = 18  Epoch: 6   accuracy: 0.96741664  val_acc: 0.9709167
48000/48000 - 250s - loss: 0.1063 - accuracy: 0.9674 - val_loss: 0.1680 - val_accuracy: 0.9709
Epoch 8/10
 -> id = 16  Epoch: 7   accuracy: 0.40345833  val_acc: 0.43308333
48000/48000 - 237s - loss: 1.6230 - accuracy: 0.4035 - val_loss: 1.5095 - val_accuracy: 0.4331
Epoch 9/10
 -> id = 9  Epoch: 6   accuracy: 0.97975  val_acc: 0.811
48000/48000 - 272s - loss: 0.0648 - accuracy: 0.9797 - val_loss: 3.3192 - val_accuracy: 0.8110
Epoch 8/10
 -> id = 6  Epoch: 7   accuracy: 0.97420835  val_acc: 0.972
48000/48000 - 233s - loss: 0.0845 - accuracy: 0.9742 - val_loss: 0.1013 - val_accuracy: 0.9720
Epoch 9/10
 -> id = 4  Epoch: 9   accuracy: 0.98125  val_acc: 0.96966666
48000/48000 - 202s - loss: 0.0693 - accuracy: 0.9812 - val_loss: 0.1048 - val_accuracy: 0.9697
 -> id = 1  Epoch: 7   accuracy: 0.74310416  val_acc: 0.7583333
48000/48000 - 239s - loss: 0.7596 - accuracy: 0.7431 - val_loss: 0.6687 - val_accuracy: 0.7583
Epoch 9/10
 -> id = 8  Epoch: 7   accuracy: 0.7331667  val_acc: 0.8419167
48000/48000 - 251s - loss: 0.7644 - accuracy: 0.7332 - val_loss: 0.4721 - val_accuracy: 0.8419
Epoch 9/10
 -> id = 12  Epoch: 6   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 274s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 8/10
 -> id = 20  Epoch: 5   accuracy: 0.94439584  val_acc: 0.95916665
48000/48000 - 326s - loss: 0.2027 - accuracy: 0.9444 - val_loss: 0.1528 - val_accuracy: 0.9592
Epoch 7/10
 -> id = 14  Epoch: 9   accuracy: 0.97402084  val_acc: 0.9690833
48000/48000 - 218s - loss: 0.0820 - accuracy: 0.9740 - val_loss: 0.1061 - val_accuracy: 0.9691
 -> id = 10  Epoch: 8   accuracy: 0.9651875  val_acc: 0.84041667
48000/48000 - 212s - loss: 0.1209 - accuracy: 0.9652 - val_loss: nan - val_accuracy: 0.8404
Epoch 10/10
 -> id = 2  Epoch: 6   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 270s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 8/10
 -> id = 13  Epoch: 8   accuracy: 0.99085414  val_acc: 0.972
48000/48000 - 218s - loss: 0.0276 - accuracy: 0.9909 - val_loss: 0.1155 - val_accuracy: 0.9720
Epoch 10/10
 -> id = 7  Epoch: 6   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 283s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 8/10
 -> id = 19  Epoch: 4   accuracy: 0.19689584  val_acc: 0.20783333
48000/48000 - 399s - loss: 2.0804 - accuracy: 0.1969 - val_loss: 2.0849 - val_accuracy: 0.2078
Epoch 6/10
 -> id = 5  Epoch: 7   accuracy: 0.97258335  val_acc: 0.96725
48000/48000 - 246s - loss: 0.1002 - accuracy: 0.9726 - val_loss: 0.1433 - val_accuracy: 0.9672
Epoch 9/10
 -> id = 11  Epoch: 6   accuracy: 0.97964585  val_acc: 0.9640833
48000/48000 - 285s - loss: 0.0673 - accuracy: 0.9796 - val_loss: 0.1426 - val_accuracy: 0.9641
Epoch 8/10
 -> id = 0  Epoch: 7   accuracy: 0.96508336  val_acc: 0.93116665
48000/48000 - 254s - loss: 0.1310 - accuracy: 0.9651 - val_loss: 0.3169 - val_accuracy: 0.9312
Epoch 9/10
 -> id = 3  Epoch: 5   accuracy: 0.949875  val_acc: 0.9579167
48000/48000 - 339s - loss: 0.2170 - accuracy: 0.9499 - val_loss: 0.1983 - val_accuracy: 0.9579
Epoch 7/10
 -> id = 16  Epoch: 8   accuracy: 0.38708332  val_acc: 0.38441667
48000/48000 - 221s - loss: 1.6323 - accuracy: 0.3871 - val_loss: 1.5599 - val_accuracy: 0.3844
Epoch 10/10
 -> id = 18  Epoch: 7   accuracy: 0.969  val_acc: 0.9738333
48000/48000 - 250s - loss: 0.0986 - accuracy: 0.9690 - val_loss: 0.1982 - val_accuracy: 0.9738
Epoch 9/10
 -> id = 6  Epoch: 8   accuracy: 0.97575  val_acc: 0.96966666
48000/48000 - 228s - loss: 0.0802 - accuracy: 0.9758 - val_loss: 0.1110 - val_accuracy: 0.9697
Epoch 10/10
 -> id = 9  Epoch: 7   accuracy: 0.98183334  val_acc: 0.87441665
48000/48000 - 253s - loss: 0.0559 - accuracy: 0.9818 - val_loss: 2.2154 - val_accuracy: 0.8744
Epoch 9/10
 -> id = 1  Epoch: 8   accuracy: 0.741375  val_acc: 0.7698333
48000/48000 - 225s - loss: 0.7350 - accuracy: 0.7414 - val_loss: 0.6383 - val_accuracy: 0.7698
Epoch 10/10
 -> id = 8  Epoch: 8   accuracy: 0.7424375  val_acc: 0.86675
48000/48000 - 231s - loss: 0.7356 - accuracy: 0.7424 - val_loss: 0.4416 - val_accuracy: 0.8668
Epoch 10/10
 -> id = 10  Epoch: 9   accuracy: 0.96875  val_acc: 0.73191667
48000/48000 - 204s - loss: 0.1086 - accuracy: 0.9688 - val_loss: 266641613573952.4375 - val_accuracy: 0.7319
 -> id = 12  Epoch: 7   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 267s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 9/10
 -> id = 2  Epoch: 7   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 255s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 9/10
 -> id = 13  Epoch: 9   accuracy: 0.9915417  val_acc: 0.9735
48000/48000 - 238s - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.1271 - val_accuracy: 0.9735
 -> id = 20  Epoch: 6   accuracy: 0.94860417  val_acc: 0.96666664
48000/48000 - 313s - loss: 0.1839 - accuracy: 0.9486 - val_loss: 0.1270 - val_accuracy: 0.9667
Epoch 8/10
 -> id = 5  Epoch: 8   accuracy: 0.97139585  val_acc: 0.9688333
48000/48000 - 237s - loss: 0.1066 - accuracy: 0.9714 - val_loss: 0.1457 - val_accuracy: 0.9688
Epoch 10/10
 -> id = 0  Epoch: 8   accuracy: 0.97085416  val_acc: 0.93908334
48000/48000 - 244s - loss: 0.1064 - accuracy: 0.9709 - val_loss: 0.2848 - val_accuracy: 0.9391
Epoch 10/10
 -> id = 7  Epoch: 7   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 274s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 9/10
 -> id = 16  Epoch: 9   accuracy: 0.3850625  val_acc: 0.40358335
48000/48000 - 219s - loss: 1.6492 - accuracy: 0.3851 - val_loss: 1.6510 - val_accuracy: 0.4036
 -> id = 11  Epoch: 7   accuracy: 0.9807708  val_acc: 0.96383333
48000/48000 - 275s - loss: 0.0646 - accuracy: 0.9808 - val_loss: 0.1453 - val_accuracy: 0.9638
Epoch 9/10
 -> id = 6  Epoch: 9   accuracy: 0.9775625  val_acc: 0.97575
48000/48000 - 216s - loss: 0.0742 - accuracy: 0.9776 - val_loss: 0.0950 - val_accuracy: 0.9758
 -> id = 18  Epoch: 8   accuracy: 0.9704375  val_acc: 0.9684167
48000/48000 - 229s - loss: 0.0951 - accuracy: 0.9704 - val_loss: 0.2421 - val_accuracy: 0.9684
Epoch 10/10
 -> id = 9  Epoch: 8   accuracy: 0.9816667  val_acc: 0.9094167
48000/48000 - 229s - loss: 0.0590 - accuracy: 0.9817 - val_loss: 1.9813 - val_accuracy: 0.9094
Epoch 10/10
 -> id = 1  Epoch: 9   accuracy: 0.745875  val_acc: 0.7635
48000/48000 - 202s - loss: 0.7067 - accuracy: 0.7459 - val_loss: 0.6243 - val_accuracy: 0.7635
 -> id = 8  Epoch: 9   accuracy: 0.7671667  val_acc: 0.8950833
48000/48000 - 193s - loss: 0.6932 - accuracy: 0.7672 - val_loss: 0.3848 - val_accuracy: 0.8951
 -> id = 3  Epoch: 6   accuracy: 0.9532083  val_acc: 0.9648333
48000/48000 - 302s - loss: 0.2108 - accuracy: 0.9532 - val_loss: 0.1719 - val_accuracy: 0.9648
Epoch 8/10
 -> id = 19  Epoch: 5   accuracy: 0.19639583  val_acc: 0.20666666
48000/48000 - 368s - loss: 2.0747 - accuracy: 0.1964 - val_loss: 2.0773 - val_accuracy: 0.2067
Epoch 7/10
 -> id = 12  Epoch: 8   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 210s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 10/10
 -> id = 2  Epoch: 8   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 208s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 10/10
 -> id = 0  Epoch: 9   accuracy: 0.97654164  val_acc: 0.9565
48000/48000 - 175s - loss: 0.0887 - accuracy: 0.9765 - val_loss: 0.1719 - val_accuracy: 0.9565
 -> id = 5  Epoch: 9   accuracy: 0.975625  val_acc: 0.96625
48000/48000 - 197s - loss: 0.0847 - accuracy: 0.9756 - val_loss: 0.1814 - val_accuracy: 0.9663
 -> id = 18  Epoch: 9   accuracy: 0.9732917  val_acc: 0.9701667
48000/48000 - 163s - loss: 0.0855 - accuracy: 0.9733 - val_loss: 0.2506 - val_accuracy: 0.9702
 -> id = 9  Epoch: 9   accuracy: 0.98354167  val_acc: 0.9090833
48000/48000 - 161s - loss: 0.0521 - accuracy: 0.9835 - val_loss: 0.3495 - val_accuracy: 0.9091
 -> id = 11  Epoch: 8   accuracy: 0.9826875  val_acc: 0.96566665
48000/48000 - 188s - loss: 0.0580 - accuracy: 0.9827 - val_loss: 0.1527 - val_accuracy: 0.9657
Epoch 10/10
 -> id = 7  Epoch: 8   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 217s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 10/10
 -> id = 20  Epoch: 7   accuracy: 0.9523542  val_acc: 0.9625
48000/48000 - 242s - loss: 0.1712 - accuracy: 0.9524 - val_loss: 0.1386 - val_accuracy: 0.9625
Epoch 9/10
 -> id = 12  Epoch: 9   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 143s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
 -> id = 2  Epoch: 9   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 132s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
 -> id = 3  Epoch: 7   accuracy: 0.95591664  val_acc: 0.961
48000/48000 - 209s - loss: 0.2006 - accuracy: 0.9559 - val_loss: 0.1793 - val_accuracy: 0.9610
Epoch 9/10
 -> id = 11  Epoch: 9   accuracy: 0.9830833  val_acc: 0.96816665
48000/48000 - 109s - loss: 0.0555 - accuracy: 0.9831 - val_loss: 0.1419 - val_accuracy: 0.9682
 -> id = 19  Epoch: 6   accuracy: 0.193375  val_acc: 0.18158333
48000/48000 - 232s - loss: 2.0806 - accuracy: 0.1934 - val_loss: 2.1824 - val_accuracy: 0.1816
Epoch 8/10
 -> id = 7  Epoch: 9   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 126s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
 -> id = 20  Epoch: 8   accuracy: 0.9559583  val_acc: 0.97033334
48000/48000 - 128s - loss: 0.1592 - accuracy: 0.9560 - val_loss: 0.1135 - val_accuracy: 0.9703
Epoch 10/10
 -> id = 3  Epoch: 8   accuracy: 0.95697916  val_acc: 0.96566665
48000/48000 - 104s - loss: 0.1960 - accuracy: 0.9570 - val_loss: 0.1673 - val_accuracy: 0.9657
Epoch 10/10
 -> id = 20  Epoch: 9   accuracy: 0.957625  val_acc: 0.9685
48000/48000 - 82s - loss: 0.1508 - accuracy: 0.9576 - val_loss: 0.1192 - val_accuracy: 0.9685
 -> id = 19  Epoch: 7   accuracy: 0.18741667  val_acc: 0.19241667
48000/48000 - 104s - loss: 2.1230 - accuracy: 0.1874 - val_loss: 2.1358 - val_accuracy: 0.1924
Epoch 9/10
 -> id = 3  Epoch: 9   accuracy: 0.9605833  val_acc: 0.9688333
48000/48000 - 71s - loss: 0.1809 - accuracy: 0.9606 - val_loss: 0.1505 - val_accuracy: 0.9688
 -> id = 19  Epoch: 8   accuracy: 0.1855625  val_acc: 0.17408334
48000/48000 - 47s - loss: 2.1243 - accuracy: 0.1856 - val_loss: 2.1249 - val_accuracy: 0.1741
Epoch 10/10
 -> id = 19  Epoch: 9   accuracy: 0.1894375  val_acc: 0.19233334
48000/48000 - 40s - loss: 2.1216 - accuracy: 0.1894 - val_loss: 2.1344 - val_accuracy: 0.1923
 id = 15  val_accuracy = 0.9764999747276306
 id = 6  val_accuracy = 0.9757500290870667
 id = 17  val_accuracy = 0.9735833406448364
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  1   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Model: "model_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_114 (Dense)            (None, 180)               141300
_________________________________________________________________
activation_93 (Activation)   (None, 180)               0
_________________________________________________________________
dropout_45 (Dropout)         (None, 180)               0
_________________________________________________________________
batch_normalization_47 (Batc (None, 180)               720
_________________________________________________________________
dense_115 (Dense)            (None, 10)                1810
=================================================================
Total params: 143,830
Trainable params: 143,470
Non-trainable params: 360
_________________________________________________________________
None
Model: "model_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_116 (Dense)            (None, 1050)              824250
_________________________________________________________________
activation_94 (Activation)   (None, 1050)              0
_________________________________________________________________
batch_normalization_48 (Batc (None, 1050)              4200
_________________________________________________________________
dense_117 (Dense)            (None, 1200)              1261200
_________________________________________________________________
activation_95 (Activation)   (None, 1200)              0
_________________________________________________________________
dropout_46 (Dropout)         (None, 1200)              0
_________________________________________________________________
dense_118 (Dense)            (None, 1180)              1417180
_________________________________________________________________
activation_96 (Activation)   (None, 1180)              0
_________________________________________________________________
dropout_47 (Dropout)         (None, 1180)              0
_________________________________________________________________
batch_normalization_49 (Batc (None, 1180)              4720
_________________________________________________________________
dense_119 (Dense)            (None, 460)               543260
_________________________________________________________________
activation_97 (Activation)   (None, 460)               0
_________________________________________________________________
dropout_48 (Dropout)         (None, 460)               0
_________________________________________________________________
batch_normalization_50 (Batc (None, 460)               1840
_________________________________________________________________
dense_120 (Dense)            (None, 710)               327310
_________________________________________________________________
activation_98 (Activation)   (None, 710)               0
_________________________________________________________________
batch_normalization_51 (Batc (None, 710)               2840
_________________________________________________________________
dense_121 (Dense)            (None, 420)               298620
_________________________________________________________________
activation_99 (Activation)   (None, 420)               0
_________________________________________________________________
dropout_49 (Dropout)         (None, 420)               0
_________________________________________________________________
dense_122 (Dense)            (None, 10)                4210
=================================================================
Total params: 4,689,630
Trainable params: 4,682,830
Non-trainable params: 6,800
_________________________________________________________________
None
Model: "model_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_123 (Dense)            (None, 110)               86350
_________________________________________________________________
activation_100 (Activation)  (None, 110)               0
_________________________________________________________________
dropout_50 (Dropout)         (None, 110)               0
_________________________________________________________________
batch_normalization_52 (Batc (None, 110)               440
_________________________________________________________________
dense_124 (Dense)            (None, 1520)              168720
_________________________________________________________________
activation_101 (Activation)  (None, 1520)              0
_________________________________________________________________
batch_normalization_53 (Batc (None, 1520)              6080
_________________________________________________________________
dense_125 (Dense)            (None, 10)                15210
=================================================================
Total params: 276,800
Trainable params: 273,540
Non-trainable params: 3,260
_________________________________________________________________
None
Model: "model_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_126 (Dense)            (None, 112)               87920
_________________________________________________________________
activation_102 (Activation)  (None, 112)               0
_________________________________________________________________
dropout_51 (Dropout)         (None, 112)               0
_________________________________________________________________
batch_normalization_54 (Batc (None, 112)               448
_________________________________________________________________
dense_127 (Dense)            (None, 10)                1130
=================================================================
Total params: 89,498
Trainable params: 89,274
Non-trainable params: 224
_________________________________________________________________
None
Model: "model_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_128 (Dense)            (None, 1234)              968690
_________________________________________________________________
activation_103 (Activation)  (None, 1234)              0
_________________________________________________________________
batch_normalization_55 (Batc (None, 1234)              4936
_________________________________________________________________
dense_129 (Dense)            (None, 1411)              1742585
_________________________________________________________________
activation_104 (Activation)  (None, 1411)              0
_________________________________________________________________
dropout_52 (Dropout)         (None, 1411)              0
_________________________________________________________________
dense_130 (Dense)            (None, 972)               1372464
_________________________________________________________________
activation_105 (Activation)  (None, 972)               0
_________________________________________________________________
dropout_53 (Dropout)         (None, 972)               0
_________________________________________________________________
batch_normalization_56 (Batc (None, 972)               3888
_________________________________________________________________
dense_131 (Dense)            (None, 379)               368767
_________________________________________________________________
activation_106 (Activation)  (None, 379)               0
_________________________________________________________________
dropout_54 (Dropout)         (None, 379)               0
_________________________________________________________________
batch_normalization_57 (Batc (None, 379)               1516
_________________________________________________________________
dense_132 (Dense)            (None, 834)               316920
_________________________________________________________________
activation_107 (Activation)  (None, 834)               0
_________________________________________________________________
batch_normalization_58 (Batc (None, 834)               3336
_________________________________________________________________
dense_133 (Dense)            (None, 346)               288910
_________________________________________________________________
activation_108 (Activation)  (None, 346)               0
_________________________________________________________________
dropout_55 (Dropout)         (None, 346)               0
_________________________________________________________________
dense_134 (Dense)            (None, 10)                3470
=================================================================
Total params: 5,075,482
Trainable params: 5,068,644
Non-trainable params: 6,838
_________________________________________________________________
None
Model: "model_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_135 (Dense)            (None, 710)               557350
_________________________________________________________________
activation_109 (Activation)  (None, 710)               0
_________________________________________________________________
dropout_56 (Dropout)         (None, 710)               0
_________________________________________________________________
batch_normalization_59 (Batc (None, 710)               2840
_________________________________________________________________
dense_136 (Dense)            (None, 490)               348390
_________________________________________________________________
activation_110 (Activation)  (None, 490)               0
_________________________________________________________________
batch_normalization_60 (Batc (None, 490)               1960
_________________________________________________________________
dense_137 (Dense)            (None, 1630)              800330
_________________________________________________________________
activation_111 (Activation)  (None, 1630)              0
_________________________________________________________________
dropout_57 (Dropout)         (None, 1630)              0
_________________________________________________________________
dense_138 (Dense)            (None, 780)               1272180
_________________________________________________________________
activation_112 (Activation)  (None, 780)               0
_________________________________________________________________
dense_139 (Dense)            (None, 730)               570130
_________________________________________________________________
activation_113 (Activation)  (None, 730)               0
_________________________________________________________________
dropout_58 (Dropout)         (None, 730)               0
_________________________________________________________________
dense_140 (Dense)            (None, 1670)              1220770
_________________________________________________________________
activation_114 (Activation)  (None, 1670)              0
_________________________________________________________________
dropout_59 (Dropout)         (None, 1670)              0
_________________________________________________________________
dense_141 (Dense)            (None, 10)                16710
=================================================================
Total params: 4,790,660
Trainable params: 4,788,260
Non-trainable params: 2,400
_________________________________________________________________
None
Model: "model_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_142 (Dense)            (None, 1100)              863500
_________________________________________________________________
activation_115 (Activation)  (None, 1100)              0
_________________________________________________________________
batch_normalization_61 (Batc (None, 1100)              4400
_________________________________________________________________
dense_143 (Dense)            (None, 10)                11010
=================================================================
Total params: 878,910
Trainable params: 876,710
Non-trainable params: 2,200
_________________________________________________________________
None
Model: "model_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_144 (Dense)            (None, 1690)              1326650
_________________________________________________________________
activation_116 (Activation)  (None, 1690)              0
_________________________________________________________________
dropout_60 (Dropout)         (None, 1690)              0
_________________________________________________________________
batch_normalization_62 (Batc (None, 1690)              6760
_________________________________________________________________
dense_145 (Dense)            (None, 350)               591850
_________________________________________________________________
activation_117 (Activation)  (None, 350)               0
_________________________________________________________________
dense_146 (Dense)            (None, 890)               312390
_________________________________________________________________
activation_118 (Activation)  (None, 890)               0
_________________________________________________________________
dropout_61 (Dropout)         (None, 890)               0
_________________________________________________________________
dense_147 (Dense)            (None, 1690)              1505790
_________________________________________________________________
activation_119 (Activation)  (None, 1690)              0
_________________________________________________________________
dropout_62 (Dropout)         (None, 1690)              0
_________________________________________________________________
batch_normalization_63 (Batc (None, 1690)              6760
_________________________________________________________________
dense_148 (Dense)            (None, 1320)              2232120
_________________________________________________________________
activation_120 (Activation)  (None, 1320)              0
_________________________________________________________________
dense_149 (Dense)            (None, 10)                13210
=================================================================
Total params: 5,995,530
Trainable params: 5,988,770
Non-trainable params: 6,760
_________________________________________________________________
None
Model: "model_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_150 (Dense)            (None, 610)               478850
_________________________________________________________________
activation_121 (Activation)  (None, 610)               0
_________________________________________________________________
dense_151 (Dense)            (None, 1800)              1099800
_________________________________________________________________
activation_122 (Activation)  (None, 1800)              0
_________________________________________________________________
dense_152 (Dense)            (None, 620)               1116620
_________________________________________________________________
activation_123 (Activation)  (None, 620)               0
_________________________________________________________________
dense_153 (Dense)            (None, 10)                6210
=================================================================
Total params: 2,701,480
Trainable params: 2,701,480
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_154 (Dense)            (None, 460)               361100
_________________________________________________________________
activation_124 (Activation)  (None, 460)               0
_________________________________________________________________
dropout_63 (Dropout)         (None, 460)               0
_________________________________________________________________
batch_normalization_64 (Batc (None, 460)               1840
_________________________________________________________________
dense_155 (Dense)            (None, 10)                4610
=================================================================
Total params: 367,550
Trainable params: 366,630
Non-trainable params: 920
_________________________________________________________________
None
Model: "model_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_156 (Dense)            (None, 100)               78500
_________________________________________________________________
activation_125 (Activation)  (None, 100)               0
_________________________________________________________________
batch_normalization_65 (Batc (None, 100)               400
_________________________________________________________________
dense_157 (Dense)            (None, 390)               39390
_________________________________________________________________
activation_126 (Activation)  (None, 390)               0
_________________________________________________________________
dropout_64 (Dropout)         (None, 390)               0
_________________________________________________________________
batch_normalization_66 (Batc (None, 390)               1560
_________________________________________________________________
dense_158 (Dense)            (None, 10)                3910
=================================================================
Total params: 123,760
Trainable params: 122,780
Non-trainable params: 980
_________________________________________________________________
None
Model: "model_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_159 (Dense)            (None, 1260)              989100
_________________________________________________________________
activation_127 (Activation)  (None, 1260)              0
_________________________________________________________________
batch_normalization_67 (Batc (None, 1260)              5040
_________________________________________________________________
dense_160 (Dense)            (None, 930)               1172730
_________________________________________________________________
activation_128 (Activation)  (None, 930)               0
_________________________________________________________________
batch_normalization_68 (Batc (None, 930)               3720
_________________________________________________________________
dense_161 (Dense)            (None, 1140)              1061340
_________________________________________________________________
activation_129 (Activation)  (None, 1140)              0
_________________________________________________________________
dense_162 (Dense)            (None, 430)               490630
_________________________________________________________________
activation_130 (Activation)  (None, 430)               0
_________________________________________________________________
dropout_65 (Dropout)         (None, 430)               0
_________________________________________________________________
dense_163 (Dense)            (None, 10)                4310
=================================================================
Total params: 3,726,870
Trainable params: 3,722,490
Non-trainable params: 4,380
_________________________________________________________________
None
Model: "model_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_164 (Dense)            (None, 50)                39250
_________________________________________________________________
activation_131 (Activation)  (None, 50)                0
_________________________________________________________________
dropout_66 (Dropout)         (None, 50)                0
_________________________________________________________________
dense_165 (Dense)            (None, 240)               12240
_________________________________________________________________
activation_132 (Activation)  (None, 240)               0
_________________________________________________________________
dense_166 (Dense)            (None, 1100)              265100
_________________________________________________________________
activation_133 (Activation)  (None, 1100)              0
_________________________________________________________________
dropout_67 (Dropout)         (None, 1100)              0
_________________________________________________________________
dense_167 (Dense)            (None, 1800)              1981800
_________________________________________________________________
activation_134 (Activation)  (None, 1800)              0
_________________________________________________________________
dense_168 (Dense)            (None, 10)                18010
=================================================================
Total params: 2,316,400
Trainable params: 2,316,400
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_169 (Dense)            (None, 620)               486700
_________________________________________________________________
activation_135 (Activation)  (None, 620)               0
_________________________________________________________________
dense_170 (Dense)            (None, 10)                6210
=================================================================
Total params: 492,910
Trainable params: 492,910
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_171 (Dense)            (None, 1030)              808550
_________________________________________________________________
activation_136 (Activation)  (None, 1030)              0
_________________________________________________________________
dropout_68 (Dropout)         (None, 1030)              0
_________________________________________________________________
batch_normalization_69 (Batc (None, 1030)              4120
_________________________________________________________________
dense_172 (Dense)            (None, 10)                10310
=================================================================
Total params: 822,980
Trainable params: 820,920
Non-trainable params: 2,060
_________________________________________________________________
None
Model: "model_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_173 (Dense)            (None, 1790)              1405150
_________________________________________________________________
activation_137 (Activation)  (None, 1790)              0
_________________________________________________________________
batch_normalization_70 (Batc (None, 1790)              7160
_________________________________________________________________
dense_174 (Dense)            (None, 1450)              2596950
_________________________________________________________________
activation_138 (Activation)  (None, 1450)              0
_________________________________________________________________
batch_normalization_71 (Batc (None, 1450)              5800
_________________________________________________________________
dense_175 (Dense)            (None, 1300)              1886300
_________________________________________________________________
activation_139 (Activation)  (None, 1300)              0
_________________________________________________________________
dense_176 (Dense)            (None, 1750)              2276750
_________________________________________________________________
activation_140 (Activation)  (None, 1750)              0
_________________________________________________________________
dropout_69 (Dropout)         (None, 1750)              0
_________________________________________________________________
batch_normalization_72 (Batc (None, 1750)              7000
_________________________________________________________________
dense_177 (Dense)            (None, 630)               1103130
_________________________________________________________________
activation_141 (Activation)  (None, 630)               0
_________________________________________________________________
dropout_70 (Dropout)         (None, 630)               0
_________________________________________________________________
batch_normalization_73 (Batc (None, 630)               2520
_________________________________________________________________
dense_178 (Dense)            (None, 780)               492180
_________________________________________________________________
activation_142 (Activation)  (None, 780)               0
_________________________________________________________________
batch_normalization_74 (Batc (None, 780)               3120
_________________________________________________________________
dense_179 (Dense)            (None, 10)                7810
=================================================================
Total params: 9,793,870
Trainable params: 9,781,070
Non-trainable params: 12,800
_________________________________________________________________
None
Model: "model_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_180 (Dense)            (None, 720)               565200
_________________________________________________________________
activation_143 (Activation)  (None, 720)               0
_________________________________________________________________
batch_normalization_75 (Batc (None, 720)               2880
_________________________________________________________________
dense_181 (Dense)            (None, 980)               706580
_________________________________________________________________
activation_144 (Activation)  (None, 980)               0
_________________________________________________________________
dropout_71 (Dropout)         (None, 980)               0
_________________________________________________________________
batch_normalization_76 (Batc (None, 980)               3920
_________________________________________________________________
dense_182 (Dense)            (None, 10)                9810
=================================================================
Total params: 1,288,390
Trainable params: 1,284,990
Non-trainable params: 3,400
_________________________________________________________________
None
Model: "model_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_183 (Dense)            (None, 660)               518100
_________________________________________________________________
activation_145 (Activation)  (None, 660)               0
_________________________________________________________________
dropout_72 (Dropout)         (None, 660)               0
_________________________________________________________________
dense_184 (Dense)            (None, 1870)              1236070
_________________________________________________________________
activation_146 (Activation)  (None, 1870)              0
_________________________________________________________________
dropout_73 (Dropout)         (None, 1870)              0
_________________________________________________________________
dense_185 (Dense)            (None, 210)               392910
_________________________________________________________________
activation_147 (Activation)  (None, 210)               0
_________________________________________________________________
dense_186 (Dense)            (None, 270)               56970
_________________________________________________________________
activation_148 (Activation)  (None, 270)               0
_________________________________________________________________
dropout_74 (Dropout)         (None, 270)               0
_________________________________________________________________
batch_normalization_77 (Batc (None, 270)               1080
_________________________________________________________________
dense_187 (Dense)            (None, 1010)              273710
_________________________________________________________________
activation_149 (Activation)  (None, 1010)              0
_________________________________________________________________
batch_normalization_78 (Batc (None, 1010)              4040
_________________________________________________________________
dense_188 (Dense)            (None, 270)               272970
_________________________________________________________________
activation_150 (Activation)  (None, 270)               0
_________________________________________________________________
dense_189 (Dense)            (None, 10)                2710
=================================================================
Total params: 2,758,560
Trainable params: 2,756,000
Non-trainable params: 2,560
_________________________________________________________________
None
Model: "model_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_190 (Dense)            (None, 1960)              1538600
_________________________________________________________________
activation_151 (Activation)  (None, 1960)              0
_________________________________________________________________
dropout_75 (Dropout)         (None, 1960)              0
_________________________________________________________________
batch_normalization_79 (Batc (None, 1960)              7840
_________________________________________________________________
dense_191 (Dense)            (None, 1070)              2098270
_________________________________________________________________
activation_152 (Activation)  (None, 1070)              0
_________________________________________________________________
dropout_76 (Dropout)         (None, 1070)              0
_________________________________________________________________
dense_192 (Dense)            (None, 220)               235620
_________________________________________________________________
activation_153 (Activation)  (None, 220)               0
_________________________________________________________________
dropout_77 (Dropout)         (None, 220)               0
_________________________________________________________________
dense_193 (Dense)            (None, 1860)              411060
_________________________________________________________________
activation_154 (Activation)  (None, 1860)              0
_________________________________________________________________
dropout_78 (Dropout)         (None, 1860)              0
_________________________________________________________________
dense_194 (Dense)            (None, 10)                18610
=================================================================
Total params: 4,310,000
Trainable params: 4,306,080
Non-trainable params: 3,920
_________________________________________________________________
None
Model: "model_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_195 (Dense)            (None, 1430)              1122550
_________________________________________________________________
activation_155 (Activation)  (None, 1430)              0
_________________________________________________________________
dropout_79 (Dropout)         (None, 1430)              0
_________________________________________________________________
batch_normalization_80 (Batc (None, 1430)              5720
_________________________________________________________________
dense_196 (Dense)            (None, 1080)              1545480
_________________________________________________________________
activation_156 (Activation)  (None, 1080)              0
_________________________________________________________________
dense_197 (Dense)            (None, 690)               745890
_________________________________________________________________
activation_157 (Activation)  (None, 690)               0
_________________________________________________________________
dropout_80 (Dropout)         (None, 690)               0
_________________________________________________________________
batch_normalization_81 (Batc (None, 690)               2760
_________________________________________________________________
dense_198 (Dense)            (None, 200)               138200
_________________________________________________________________
activation_158 (Activation)  (None, 200)               0
_________________________________________________________________
batch_normalization_82 (Batc (None, 200)               800
_________________________________________________________________
dense_199 (Dense)            (None, 10)                2010
=================================================================
Total params: 3,563,410
Trainable params: 3,558,770
Non-trainable params: 4,640
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Epoch 1/10

Epoch 1/10Train on 48000 samples, validate on 12000 samples

Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Epoch 1/10Train on 48000 samples, validate on 12000 samplesEpoch 1/10



Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
 -> id = 13  Epoch: 0   accuracy: 0.8891875  val_acc: 0.92041665
48000/48000 - 30s - loss: 0.3829 - accuracy: 0.8892 - val_loss: 0.2808 - val_accuracy: 0.9204
Epoch 2/10
 -> id = 0  Epoch: 0   accuracy: 0.86927086  val_acc: 0.951
48000/48000 - 56s - loss: 0.4381 - accuracy: 0.8693 - val_loss: 0.2011 - val_accuracy: 0.9510
Epoch 2/10
 -> id = 3  Epoch: 0   accuracy: 0.84077084  val_acc: 0.94458336
48000/48000 - 56s - loss: 0.5353 - accuracy: 0.8408 - val_loss: 0.2212 - val_accuracy: 0.9446
Epoch 2/10
 -> id = 14  Epoch: 0   accuracy: 0.8810833  val_acc: 0.90533334
48000/48000 - 65s - loss: 0.4344 - accuracy: 0.8811 - val_loss: 0.3486 - val_accuracy: 0.9053
Epoch 2/10
 -> id = 9  Epoch: 0   accuracy: 0.8788125  val_acc: 0.93191665
48000/48000 - 67s - loss: 0.4072 - accuracy: 0.8788 - val_loss: 0.2439 - val_accuracy: 0.9319
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.8847917  val_acc: 0.84
48000/48000 - 69s - loss: 0.4317 - accuracy: 0.8848 - val_loss: 0.6075 - val_accuracy: 0.8400
Epoch 2/10
 -> id = 8  Epoch: 0   accuracy: 0.5079167  val_acc: 0.84391665
48000/48000 - 89s - loss: 1.4992 - accuracy: 0.5079 - val_loss: 0.4878 - val_accuracy: 0.8439
Epoch 2/10
 -> id = 12  Epoch: 0   accuracy: 0.8846875  val_acc: 0.94775
48000/48000 - 101s - loss: 0.3654 - accuracy: 0.8847 - val_loss: 0.1708 - val_accuracy: 0.9477
Epoch 2/10
 -> id = 2  Epoch: 0   accuracy: 0.8774792  val_acc: 0.85858333
48000/48000 - 107s - loss: 0.4872 - accuracy: 0.8775 - val_loss: 1.4512 - val_accuracy: 0.8586
Epoch 2/10
 -> id = 13  Epoch: 1   accuracy: 0.9130833  val_acc: 0.92141664
 -> id = 10  Epoch: 0   accuracy: 0.8980833  val_acc: 0.9564166748000/48000 - 82s - loss: 0.3066 - accuracy: 0.9131 - val_loss: 0.2896 - val_accuracy: 0.9214

Epoch 3/10
48000/48000 - 112s - loss: 0.3307 - accuracy: 0.8981 - val_loss: 0.1643 - val_accuracy: 0.9564
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.9390417  val_acc: 0.95566666
48000/48000 - 128s - loss: 0.2092 - accuracy: 0.9390 - val_loss: 0.1562 - val_accuracy: 0.9557
Epoch 2/10
 -> id = 0  Epoch: 1   accuracy: 0.9386875  val_acc: 0.9626667
48000/48000 - 87s - loss: 0.2137 - accuracy: 0.9387 - val_loss: 0.1311 - val_accuracy: 0.9627
Epoch 3/10
 -> id = 3  Epoch: 1   accuracy: 0.922  val_acc: 0.95641667
48000/48000 - 88s - loss: 0.2723 - accuracy: 0.9220 - val_loss: 0.1553 - val_accuracy: 0.9564
Epoch 3/10
 -> id = 14  Epoch: 1   accuracy: 0.904125  val_acc: 0.9123333
48000/48000 - 95s - loss: 0.3380 - accuracy: 0.9041 - val_loss: 0.3284 - val_accuracy: 0.9123
Epoch 3/10
 -> id = 18  Epoch: 0   accuracy: 0.14404167  val_acc: 0.19816667
48000/48000 - 161s - loss: 2.2510 - accuracy: 0.1440 - val_loss: 2.0833 - val_accuracy: 0.1982
Epoch 2/10
 -> id = 19  Epoch: 0   accuracy: 0.8245208  val_acc: 0.90925
48000/48000 - 168s - loss: 0.6933 - accuracy: 0.8245 - val_loss: 0.6840 - val_accuracy: 0.9093
Epoch 2/10
 -> id = 11  Epoch: 0   accuracy: 0.9194375  val_acc: 0.95066667
48000/48000 - 173s - loss: 0.2741 - accuracy: 0.9194 - val_loss: 0.1679 - val_accuracy: 0.9507
Epoch 2/10
 -> id = 6  Epoch: 1   accuracy: 0.9066875  val_acc: 0.9065833
48000/48000 - 109s - loss: 0.3317 - accuracy: 0.9067 - val_loss: 0.3177 - val_accuracy: 0.9066
Epoch 3/10
 -> id = 9  Epoch: 1   accuracy: 0.9191667  val_acc: 0.9403333
48000/48000 - 111s - loss: 0.2724 - accuracy: 0.9192 - val_loss: 0.2106 - val_accuracy: 0.9403
Epoch 3/10
 -> id = 17  Epoch: 0   accuracy: 0.8657708  val_acc: 0.5423333
48000/48000 - 184s - loss: 0.4207 - accuracy: 0.8658 - val_loss: 1.2811 - val_accuracy: 0.5423
Epoch 2/10
 -> id = 2  Epoch: 1   accuracy: 0.95091665  val_acc: 0.96458334
48000/48000 - 83s - loss: 0.1621 - accuracy: 0.9509 - val_loss: 0.1736 - val_accuracy: 0.9646
Epoch 3/10
 -> id = 7  Epoch: 0   accuracy: 0.09835417  val_acc: 0.0995
48000/48000 - 191s - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0995
Epoch 2/10
 -> id = 1  Epoch: 0   accuracy: 0.8953125  val_acc: 0.92975
48000/48000 - 195s - loss: 0.3605 - accuracy: 0.8953 - val_loss: 0.2348 - val_accuracy: 0.9298
Epoch 2/10
 -> id = 5  Epoch: 0   accuracy: 0.7996042  val_acc: 0.92516667
48000/48000 - 205s - loss: 0.8152 - accuracy: 0.7996 - val_loss: 0.2730 - val_accuracy: 0.9252
Epoch 2/10
 -> id = 13  Epoch: 2   accuracy: 0.91770834  val_acc: 0.91641665
48000/48000 - 93s - loss: 0.2941 - accuracy: 0.9177 - val_loss: 0.3042 - val_accuracy: 0.9164
Epoch 4/10
 -> id = 10  Epoch: 1   accuracy: 0.95402086  val_acc: 0.9665833
48000/48000 - 94s - loss: 0.1535 - accuracy: 0.9540 - val_loss: 0.1125 - val_accuracy: 0.9666
Epoch 3/10
 -> id = 0  Epoch: 2   accuracy: 0.9493333  val_acc: 0.96758336
48000/48000 - 69s - loss: 0.1744 - accuracy: 0.9493 - val_loss: 0.1132 - val_accuracy: 0.9676
Epoch 4/10
 -> id = 3  Epoch: 2   accuracy: 0.93539584  val_acc: 0.9615
48000/48000 - 70s - loss: 0.2246 - accuracy: 0.9354 - val_loss: 0.1330 - val_accuracy: 0.9615
Epoch 4/10
 -> id = 16  Epoch: 1   accuracy: 0.9718958  val_acc: 0.96891665
48000/48000 - 88s - loss: 0.0920 - accuracy: 0.9719 - val_loss: 0.0990 - val_accuracy: 0.9689
Epoch 3/10
 -> id = 8  Epoch: 1   accuracy: 0.8674375  val_acc: 0.9044167
48000/48000 - 131s - loss: 0.4359 - accuracy: 0.8674 - val_loss: 0.3407 - val_accuracy: 0.9044
Epoch 3/10
 -> id = 12  Epoch: 1   accuracy: 0.93560416  val_acc: 0.95108336
48000/48000 - 121s - loss: 0.2106 - accuracy: 0.9356 - val_loss: 0.1575 - val_accuracy: 0.9511
Epoch 3/10
 -> id = 4  Epoch: 0   accuracy: 0.89566666  val_acc: 0.92966664
48000/48000 - 224s - loss: 0.3619 - accuracy: 0.8957 - val_loss: 0.2427 - val_accuracy: 0.9297
Epoch 2/10
 -> id = 14  Epoch: 2   accuracy: 0.9094167  val_acc: 0.91425
48000/48000 - 88s - loss: 0.3156 - accuracy: 0.9094 - val_loss: 0.2992 - val_accuracy: 0.9143
Epoch 4/10
 -> id = 15  Epoch: 0   accuracy: 0.89341664  val_acc: 0.9435
48000/48000 - 269s - loss: 0.3886 - accuracy: 0.8934 - val_loss: 0.1950 - val_accuracy: 0.9435
Epoch 2/10
 -> id = 2  Epoch: 2   accuracy: 0.96697915  val_acc: 0.9690833
48000/48000 - 91s - loss: 0.1102 - accuracy: 0.9670 - val_loss: 0.1072 - val_accuracy: 0.9691
Epoch 4/10
 -> id = 9  Epoch: 2   accuracy: 0.932125  val_acc: 0.9456667
48000/48000 - 107s - loss: 0.2280 - accuracy: 0.9321 - val_loss: 0.1902 - val_accuracy: 0.9457
Epoch 4/10
 -> id = 19  Epoch: 1   accuracy: 0.7926667  val_acc: 0.91716665
48000/48000 - 120s - loss: 0.8389 - accuracy: 0.7927 - val_loss: 0.3444 - val_accuracy: 0.9172
Epoch 3/10
 -> id = 6  Epoch: 2   accuracy: 0.91216666  val_acc: 0.9165
48000/48000 - 112s - loss: 0.3094 - accuracy: 0.9122 - val_loss: 0.3034 - val_accuracy: 0.9165
Epoch 4/10
 -> id = 0  Epoch: 3   accuracy: 0.9570417  val_acc: 0.96925
48000/48000 - 81s - loss: 0.1446 - accuracy: 0.9570 - val_loss: 0.1044 - val_accuracy: 0.9693
Epoch 5/10
 -> id = 18  Epoch: 1   accuracy: 0.21347916  val_acc: 0.29525
48000/48000 - 139s - loss: 2.0596 - accuracy: 0.2135 - val_loss: 1.8094 - val_accuracy: 0.2952
Epoch 3/10
 -> id = 3  Epoch: 3   accuracy: 0.94233334  val_acc: 0.967
48000/48000 - 86s - loss: 0.1973 - accuracy: 0.9423 - val_loss: 0.1159 - val_accuracy: 0.9670
Epoch 5/10
 -> id = 10  Epoch: 2   accuracy: 0.9659167  val_acc: 0.97033334
48000/48000 - 98s - loss: 0.1138 - accuracy: 0.9659 - val_loss: 0.0976 - val_accuracy: 0.9703
Epoch 4/10
 -> id = 11  Epoch: 1   accuracy: 0.9565  val_acc: 0.96416664
48000/48000 - 136s - loss: 0.1437 - accuracy: 0.9565 - val_loss: 0.1251 - val_accuracy: 0.9642
Epoch 3/10
 -> id = 13  Epoch: 3   accuracy: 0.9200208  val_acc: 0.9185
48000/48000 - 105s - loss: 0.2864 - accuracy: 0.9200 - val_loss: 0.2873 - val_accuracy: 0.9185
Epoch 5/10
 -> id = 16  Epoch: 2   accuracy: 0.97952086  val_acc: 0.9738333
48000/48000 - 96s - loss: 0.0663 - accuracy: 0.9795 - val_loss: 0.0903 - val_accuracy: 0.9738
Epoch 4/10
 -> id = 17  Epoch: 1   accuracy: 0.93204165  val_acc: 0.77725
48000/48000 - 136s - loss: 0.2181 - accuracy: 0.9320 - val_loss: 0.9145 - val_accuracy: 0.7772
Epoch 3/10
 -> id = 14  Epoch: 3   accuracy: 0.91260415  val_acc: 0.91833335
48000/48000 - 86s - loss: 0.3070 - accuracy: 0.9126 - val_loss: 0.2907 - val_accuracy: 0.9183
Epoch 5/10
 -> id = 12  Epoch: 2   accuracy: 0.94654167  val_acc: 0.9640833
48000/48000 - 112s - loss: 0.1696 - accuracy: 0.9465 - val_loss: 0.1181 - val_accuracy: 0.9641
Epoch 4/10
 -> id = 7  Epoch: 1   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 145s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 3/10
 -> id = 1  Epoch: 1   accuracy: 0.942125  val_acc: 0.96066666
48000/48000 - 148s - loss: 0.1952 - accuracy: 0.9421 - val_loss: 0.1458 - val_accuracy: 0.9607
Epoch 3/10
 -> id = 8  Epoch: 2   accuracy: 0.9089583  val_acc: 0.9230833
48000/48000 - 125s - loss: 0.3300 - accuracy: 0.9090 - val_loss: 0.2837 - val_accuracy: 0.9231
Epoch 4/10
 -> id = 5  Epoch: 1   accuracy: 0.8949792  val_acc: 0.9350833
48000/48000 - 164s - loss: 0.4959 - accuracy: 0.8950 - val_loss: 0.2324 - val_accuracy: 0.9351
Epoch 3/10
 -> id = 0  Epoch: 4   accuracy: 0.96164584  val_acc: 0.97375
48000/48000 - 76s - loss: 0.1282 - accuracy: 0.9616 - val_loss: 0.0923 - val_accuracy: 0.9737
Epoch 6/10
 -> id = 2  Epoch: 3   accuracy: 0.97510415  val_acc: 0.97175
48000/48000 - 93s - loss: 0.0828 - accuracy: 0.9751 - val_loss: 0.0966 - val_accuracy: 0.9718
Epoch 5/10
 -> id = 3  Epoch: 4   accuracy: 0.9462708  val_acc: 0.96758336
48000/48000 - 73s - loss: 0.1781 - accuracy: 0.9463 - val_loss: 0.1083 - val_accuracy: 0.9676
Epoch 6/10
 -> id = 9  Epoch: 3   accuracy: 0.93983334  val_acc: 0.9548333
48000/48000 - 98s - loss: 0.1995 - accuracy: 0.9398 - val_loss: 0.1618 - val_accuracy: 0.9548
Epoch 5/10
 -> id = 6  Epoch: 3   accuracy: 0.9166667  val_acc: 0.9228333
48000/48000 - 104s - loss: 0.2950 - accuracy: 0.9167 - val_loss: 0.2806 - val_accuracy: 0.9228
Epoch 5/10
 -> id = 4  Epoch: 1   accuracy: 0.9421875  val_acc: 0.9669167
48000/48000 - 172s - loss: 0.2008 - accuracy: 0.9422 - val_loss: 0.1262 - val_accuracy: 0.9669
Epoch 3/10
 -> id = 19  Epoch: 2   accuracy: 0.7514375  val_acc: 0.9134167
48000/48000 - 116s - loss: 0.9468 - accuracy: 0.7514 - val_loss: 0.3283 - val_accuracy: 0.9134
Epoch 4/10
 -> id = 13  Epoch: 4   accuracy: 0.9214583  val_acc: 0.9238333
48000/48000 - 94s - loss: 0.2763 - accuracy: 0.9215 - val_loss: 0.2862 - val_accuracy: 0.9238
Epoch 6/10
 -> id = 10  Epoch: 3   accuracy: 0.9723125  val_acc: 0.97008336
48000/48000 - 100s - loss: 0.0890 - accuracy: 0.9723 - val_loss: 0.0941 - val_accuracy: 0.9701
Epoch 5/10
 -> id = 16  Epoch: 3   accuracy: 0.9836042  val_acc: 0.976
48000/48000 - 98s - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0854 - val_accuracy: 0.9760
Epoch 5/10
 -> id = 14  Epoch: 4   accuracy: 0.91495836  val_acc: 0.92116666
48000/48000 - 81s - loss: 0.3000 - accuracy: 0.9150 - val_loss: 0.2801 - val_accuracy: 0.9212
Epoch 6/10
 -> id = 18  Epoch: 2   accuracy: 0.24047917  val_acc: 0.30416667
48000/48000 - 138s - loss: 1.9181 - accuracy: 0.2405 - val_loss: 1.6830 - val_accuracy: 0.3042
Epoch 4/10
 -> id = 11  Epoch: 2   accuracy: 0.9646875  val_acc: 0.96108335
48000/48000 - 140s - loss: 0.1155 - accuracy: 0.9647 - val_loss: 0.1328 - val_accuracy: 0.9611
Epoch 4/10
 -> id = 3  Epoch: 5   accuracy: 0.95133334  val_acc: 0.96825
48000/48000 - 76s - loss: 0.1592 - accuracy: 0.9513 - val_loss: 0.1120 - val_accuracy: 0.9682
Epoch 7/10
 -> id = 17  Epoch: 2   accuracy: 0.47445834  val_acc: 0.0995
48000/48000 - 132s - loss: nan - accuracy: 0.4745 - val_loss: nan - val_accuracy: 0.0995
Epoch 4/10
 -> id = 0  Epoch: 5   accuracy: 0.96435416  val_acc: 0.9725
48000/48000 - 84s - loss: 0.1197 - accuracy: 0.9644 - val_loss: 0.0932 - val_accuracy: 0.9725
Epoch 7/10
 -> id = 12  Epoch: 3   accuracy: 0.95404166  val_acc: 0.96425
48000/48000 - 122s - loss: 0.1480 - accuracy: 0.9540 - val_loss: 0.1140 - val_accuracy: 0.9643
Epoch 5/10
 -> id = 2  Epoch: 4   accuracy: 0.98052084  val_acc: 0.97108334
48000/48000 - 90s - loss: 0.0630 - accuracy: 0.9805 - val_loss: 0.0992 - val_accuracy: 0.9711
Epoch 6/10
 -> id = 8  Epoch: 3   accuracy: 0.924875  val_acc: 0.92725
48000/48000 - 129s - loss: 0.2765 - accuracy: 0.9249 - val_loss: 0.2736 - val_accuracy: 0.9273
Epoch 5/10
 -> id = 9  Epoch: 4   accuracy: 0.9457292  val_acc: 0.95825
48000/48000 - 96s - loss: 0.1805 - accuracy: 0.9457 - val_loss: 0.1458 - val_accuracy: 0.9582
Epoch 6/10
 -> id = 15  Epoch: 1   accuracy: 0.9396458  val_acc: 0.956
48000/48000 - 213s - loss: 0.2035 - accuracy: 0.9396 - val_loss: 0.1560 - val_accuracy: 0.9560
Epoch 3/10
 -> id = 7  Epoch: 2   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 149s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 4/10
 -> id = 6  Epoch: 4   accuracy: 0.9222292  val_acc: 0.9321667
48000/48000 - 101s - loss: 0.2726 - accuracy: 0.9222 - val_loss: 0.2544 - val_accuracy: 0.9322
Epoch 6/10
 -> id = 1  Epoch: 2   accuracy: 0.9545  val_acc: 0.96491665
48000/48000 - 153s - loss: 0.1510 - accuracy: 0.9545 - val_loss: 0.1257 - val_accuracy: 0.9649
Epoch 4/10
 -> id = 16  Epoch: 4   accuracy: 0.9866667  val_acc: 0.97658336
48000/48000 - 86s - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.0882 - val_accuracy: 0.9766
Epoch 6/10
 -> id = 14  Epoch: 5   accuracy: 0.9163125  val_acc: 0.92575
48000/48000 - 84s - loss: 0.2937 - accuracy: 0.9163 - val_loss: 0.2732 - val_accuracy: 0.9258
Epoch 7/10
 -> id = 13  Epoch: 5   accuracy: 0.92310417  val_acc: 0.9275
48000/48000 - 96s - loss: 0.2734 - accuracy: 0.9231 - val_loss: 0.2716 - val_accuracy: 0.9275
Epoch 7/10
 -> id = 10  Epoch: 4   accuracy: 0.97716665  val_acc: 0.9738333
48000/48000 - 98s - loss: 0.0726 - accuracy: 0.9772 - val_loss: 0.0884 - val_accuracy: 0.9738
Epoch 6/10
 -> id = 19  Epoch: 3   accuracy: 0.71945834  val_acc: 0.9225
48000/48000 - 115s - loss: 1.0244 - accuracy: 0.7195 - val_loss: 0.3427 - val_accuracy: 0.9225
Epoch 5/10
 -> id = 3  Epoch: 6   accuracy: 0.9527708  val_acc: 0.96975
48000/48000 - 72s - loss: 0.1534 - accuracy: 0.9528 - val_loss: 0.1052 - val_accuracy: 0.9697
Epoch 8/10
 -> id = 0  Epoch: 6   accuracy: 0.966125  val_acc: 0.97541666
48000/48000 - 69s - loss: 0.1091 - accuracy: 0.9661 - val_loss: 0.0870 - val_accuracy: 0.9754
Epoch 8/10
 -> id = 5  Epoch: 2   accuracy: 0.9115625  val_acc: 0.9489167
48000/48000 - 161s - loss: 0.4182 - accuracy: 0.9116 - val_loss: 0.1851 - val_accuracy: 0.9489
Epoch 4/10
 -> id = 2  Epoch: 5   accuracy: 0.9845833  val_acc: 0.97433335
48000/48000 - 93s - loss: 0.0497 - accuracy: 0.9846 - val_loss: 0.0913 - val_accuracy: 0.9743
Epoch 7/10
 -> id = 4  Epoch: 2   accuracy: 0.956125  val_acc: 0.9633333
48000/48000 - 174s - loss: 0.1494 - accuracy: 0.9561 - val_loss: 0.1268 - val_accuracy: 0.9633
Epoch 4/10
 -> id = 18  Epoch: 3   accuracy: 0.242125  val_acc: 0.31383333
48000/48000 - 133s - loss: 1.8461 - accuracy: 0.2421 - val_loss: 1.6050 - val_accuracy: 0.3138
Epoch 5/10
 -> id = 12  Epoch: 4   accuracy: 0.95752084  val_acc: 0.97008336
48000/48000 - 118s - loss: 0.1345 - accuracy: 0.9575 - val_loss: 0.1058 - val_accuracy: 0.9701
Epoch 6/10
 -> id = 17  Epoch: 3   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 130s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 5/10
 -> id = 11  Epoch: 3   accuracy: 0.9698542  val_acc: 0.97241664
48000/48000 - 136s - loss: 0.0976 - accuracy: 0.9699 - val_loss: 0.0994 - val_accuracy: 0.9724
Epoch 5/10
 -> id = 14  Epoch: 6   accuracy: 0.91627085  val_acc: 0.91983336
48000/48000 - 88s - loss: 0.2915 - accuracy: 0.9163 - val_loss: 0.2890 - val_accuracy: 0.9198
Epoch 8/10
 -> id = 9  Epoch: 5   accuracy: 0.95014584  val_acc: 0.9625
48000/48000 - 108s - loss: 0.1643 - accuracy: 0.9501 - val_loss: 0.1334 - val_accuracy: 0.9625
Epoch 7/10
 -> id = 16  Epoch: 5   accuracy: 0.987875  val_acc: 0.9738333
48000/48000 - 92s - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.0897 - val_accuracy: 0.9738
Epoch 7/10
 -> id = 13  Epoch: 6   accuracy: 0.92245835  val_acc: 0.9241667
48000/48000 - 95s - loss: 0.2738 - accuracy: 0.9225 - val_loss: 0.2795 - val_accuracy: 0.9242
Epoch 8/10
 -> id = 0  Epoch: 7   accuracy: 0.967375  val_acc: 0.9748333
48000/48000 - 76s - loss: 0.1022 - accuracy: 0.9674 - val_loss: 0.0856 - val_accuracy: 0.9748
Epoch 9/10
 -> id = 8  Epoch: 4   accuracy: 0.93225  val_acc: 0.9343333
48000/48000 - 130s - loss: 0.2504 - accuracy: 0.9323 - val_loss: 0.2489 - val_accuracy: 0.9343
Epoch 6/10
 -> id = 6  Epoch: 5   accuracy: 0.93325  val_acc: 0.9355
48000/48000 - 109s - loss: 0.2344 - accuracy: 0.9333 - val_loss: 0.2267 - val_accuracy: 0.9355
Epoch 7/10
 -> id = 3  Epoch: 7   accuracy: 0.95720834  val_acc: 0.97208333
48000/48000 - 83s - loss: 0.1441 - accuracy: 0.9572 - val_loss: 0.0996 - val_accuracy: 0.9721
Epoch 9/10
 -> id = 10  Epoch: 5   accuracy: 0.98066664  val_acc: 0.97333336
48000/48000 - 105s - loss: 0.0618 - accuracy: 0.9807 - val_loss: 0.0865 - val_accuracy: 0.9733
Epoch 7/10
 -> id = 7  Epoch: 3   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 153s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 5/10
 -> id = 2  Epoch: 6   accuracy: 0.9875  val_acc: 0.97225
48000/48000 - 85s - loss: 0.0390 - accuracy: 0.9875 - val_loss: 0.0957 - val_accuracy: 0.9722
Epoch 8/10
 -> id = 19  Epoch: 4   accuracy: 0.6874375  val_acc: 0.9178333
48000/48000 - 122s - loss: 1.0944 - accuracy: 0.6874 - val_loss: 0.3538 - val_accuracy: 0.9178
Epoch 6/10
 -> id = 1  Epoch: 3   accuracy: 0.96283334  val_acc: 0.9640833
48000/48000 - 151s - loss: 0.1219 - accuracy: 0.9628 - val_loss: 0.1313 - val_accuracy: 0.9641
Epoch 5/10
 -> id = 3  Epoch: 8   accuracy: 0.9584375  val_acc: 0.97083336
48000/48000 - 77s - loss: 0.1375 - accuracy: 0.9584 - val_loss: 0.0955 - val_accuracy: 0.9708
Epoch 10/10
 -> id = 14  Epoch: 7   accuracy: 0.9178542  val_acc: 0.92441666
48000/48000 - 96s - loss: 0.2899 - accuracy: 0.9179 - val_loss: 0.2794 - val_accuracy: 0.9244
Epoch 9/10
 -> id = 0  Epoch: 8   accuracy: 0.96989584  val_acc: 0.97566664
48000/48000 - 87s - loss: 0.0952 - accuracy: 0.9699 - val_loss: 0.0847 - val_accuracy: 0.9757
Epoch 10/10
 -> id = 16  Epoch: 6   accuracy: 0.990375  val_acc: 0.9740833
48000/48000 - 97s - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0967 - val_accuracy: 0.9741
Epoch 8/10
 -> id = 9  Epoch: 6   accuracy: 0.9534375  val_acc: 0.96325
48000/48000 - 106s - loss: 0.1498 - accuracy: 0.9534 - val_loss: 0.1316 - val_accuracy: 0.9632
Epoch 8/10
 -> id = 12  Epoch: 5   accuracy: 0.9584375  val_acc: 0.9705
48000/48000 - 121s - loss: 0.1315 - accuracy: 0.9584 - val_loss: 0.1013 - val_accuracy: 0.9705
Epoch 7/10
 -> id = 13  Epoch: 7   accuracy: 0.9246875  val_acc: 0.92325
48000/48000 - 100s - loss: 0.2678 - accuracy: 0.9247 - val_loss: 0.2841 - val_accuracy: 0.9233
Epoch 9/10
 -> id = 5  Epoch: 3   accuracy: 0.91908336  val_acc: 0.9533333
48000/48000 - 167s - loss: 0.3817 - accuracy: 0.9191 - val_loss: 0.1783 - val_accuracy: 0.9533
Epoch 5/10
 -> id = 10  Epoch: 6   accuracy: 0.98335415  val_acc: 0.97825
48000/48000 - 99s - loss: 0.0532 - accuracy: 0.9834 - val_loss: 0.0769 - val_accuracy: 0.9783
Epoch 8/10
 -> id = 6  Epoch: 6   accuracy: 0.9459792  val_acc: 0.9511667
48000/48000 - 104s - loss: 0.1849 - accuracy: 0.9460 - val_loss: 0.1769 - val_accuracy: 0.9512
Epoch 8/10
 -> id = 15  Epoch: 2   accuracy: 0.9509792  val_acc: 0.96258336
48000/48000 - 226s - loss: 0.1617 - accuracy: 0.9510 - val_loss: 0.1297 - val_accuracy: 0.9626
Epoch 4/10
 -> id = 18  Epoch: 4   accuracy: 0.2476875  val_acc: 0.32575
48000/48000 - 138s - loss: 1.8002 - accuracy: 0.2477 - val_loss: 1.5463 - val_accuracy: 0.3257
Epoch 6/10
 -> id = 17  Epoch: 4   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 139s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 6/10
 -> id = 11  Epoch: 4   accuracy: 0.971375  val_acc: 0.9634167
48000/48000 - 142s - loss: 0.0920 - accuracy: 0.9714 - val_loss: 0.1226 - val_accuracy: 0.9634
Epoch 6/10
 -> id = 8  Epoch: 5   accuracy: 0.9360833  val_acc: 0.9379167
48000/48000 - 132s - loss: 0.2364 - accuracy: 0.9361 - val_loss: 0.2278 - val_accuracy: 0.9379
Epoch 7/10
 -> id = 2  Epoch: 7   accuracy: 0.98897916  val_acc: 0.97566664
48000/48000 - 94s - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.0889 - val_accuracy: 0.9757
Epoch 9/10
 -> id = 4  Epoch: 3   accuracy: 0.961875  val_acc: 0.96683335
48000/48000 - 184s - loss: 0.1261 - accuracy: 0.9619 - val_loss: 0.1157 - val_accuracy: 0.9668
Epoch 5/10
 -> id = 3  Epoch: 9   accuracy: 0.95991665  val_acc: 0.97225
48000/48000 - 81s - loss: 0.1309 - accuracy: 0.9599 - val_loss: 0.0946 - val_accuracy: 0.9722
 -> id = 19  Epoch: 5   accuracy: 0.6584167  val_acc: 0.9255
48000/48000 - 124s - loss: 1.1459 - accuracy: 0.6584 - val_loss: 0.3664 - val_accuracy: 0.9255
Epoch 7/10
 -> id = 14  Epoch: 8   accuracy: 0.91772914  val_acc: 0.92475
48000/48000 - 88s - loss: 0.2879 - accuracy: 0.9177 - val_loss: 0.2814 - val_accuracy: 0.9247
Epoch 10/10
 -> id = 0  Epoch: 9   accuracy: 0.97229165  val_acc: 0.97541666
48000/48000 - 87s - loss: 0.0888 - accuracy: 0.9723 - val_loss: 0.0844 - val_accuracy: 0.9754
 -> id = 16  Epoch: 7   accuracy: 0.9916458  val_acc: 0.97683334
48000/48000 - 94s - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0854 - val_accuracy: 0.9768
Epoch 9/10
 -> id = 7  Epoch: 4   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 153s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 6/10
 -> id = 1  Epoch: 4   accuracy: 0.96564585  val_acc: 0.9691667
48000/48000 - 148s - loss: 0.1125 - accuracy: 0.9656 - val_loss: 0.1171 - val_accuracy: 0.9692
Epoch 6/10
 -> id = 9  Epoch: 7   accuracy: 0.9575833  val_acc: 0.96525
48000/48000 - 102s - loss: 0.1387 - accuracy: 0.9576 - val_loss: 0.1202 - val_accuracy: 0.9653
Epoch 9/10
 -> id = 13  Epoch: 8   accuracy: 0.92475  val_acc: 0.92516667
48000/48000 - 108s - loss: 0.2669 - accuracy: 0.9247 - val_loss: 0.2800 - val_accuracy: 0.9252
Epoch 10/10
 -> id = 10  Epoch: 7   accuracy: 0.9862292  val_acc: 0.97716665
48000/48000 - 102s - loss: 0.0441 - accuracy: 0.9862 - val_loss: 0.0778 - val_accuracy: 0.9772
Epoch 9/10
 -> id = 6  Epoch: 7   accuracy: 0.95808333  val_acc: 0.9558333
48000/48000 - 106s - loss: 0.1433 - accuracy: 0.9581 - val_loss: 0.1568 - val_accuracy: 0.9558
Epoch 9/10
 -> id = 12  Epoch: 6   accuracy: 0.9636667  val_acc: 0.97125
48000/48000 - 120s - loss: 0.1191 - accuracy: 0.9637 - val_loss: 0.1017 - val_accuracy: 0.9712
Epoch 8/10
 -> id = 2  Epoch: 8   accuracy: 0.99070835  val_acc: 0.9738333
48000/48000 - 94s - loss: 0.0286 - accuracy: 0.9907 - val_loss: 0.0983 - val_accuracy: 0.9738
Epoch 10/10
 -> id = 18  Epoch: 5   accuracy: 0.2498125  val_acc: 0.37533334
48000/48000 - 134s - loss: 1.7733 - accuracy: 0.2498 - val_loss: 1.5309 - val_accuracy: 0.3753
Epoch 7/10
 -> id = 17  Epoch: 5   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 131s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 7/10
 -> id = 14  Epoch: 9   accuracy: 0.91922915  val_acc: 0.9234167
48000/48000 - 83s - loss: 0.2843 - accuracy: 0.9192 - val_loss: 0.2937 - val_accuracy: 0.9234
 -> id = 5  Epoch: 4   accuracy: 0.9253125  val_acc: 0.95033336
48000/48000 - 157s - loss: 0.3582 - accuracy: 0.9253 - val_loss: 0.2042 - val_accuracy: 0.9503
Epoch 6/10
 -> id = 8  Epoch: 6   accuracy: 0.9392083  val_acc: 0.93775
48000/48000 - 122s - loss: 0.2250 - accuracy: 0.9392 - val_loss: 0.2345 - val_accuracy: 0.9377
Epoch 8/10
 -> id = 11  Epoch: 5   accuracy: 0.975375  val_acc: 0.968
48000/48000 - 137s - loss: 0.0777 - accuracy: 0.9754 - val_loss: 0.1093 - val_accuracy: 0.9680
Epoch 7/10
 -> id = 16  Epoch: 8   accuracy: 0.9918542  val_acc: 0.97716665
48000/48000 - 97s - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0906 - val_accuracy: 0.9772
Epoch 10/10
 -> id = 19  Epoch: 6   accuracy: 0.63408333  val_acc: 0.9180833
48000/48000 - 119s - loss: 1.1909 - accuracy: 0.6341 - val_loss: 0.3704 - val_accuracy: 0.9181
Epoch 8/10
 -> id = 9  Epoch: 8   accuracy: 0.9598333  val_acc: 0.96675
48000/48000 - 101s - loss: 0.1310 - accuracy: 0.9598 - val_loss: 0.1145 - val_accuracy: 0.9668
Epoch 10/10
 -> id = 13  Epoch: 9   accuracy: 0.92675  val_acc: 0.91933334
48000/48000 - 98s - loss: 0.2641 - accuracy: 0.9268 - val_loss: 0.2872 - val_accuracy: 0.9193
 -> id = 10  Epoch: 8   accuracy: 0.9865  val_acc: 0.97725
48000/48000 - 104s - loss: 0.0406 - accuracy: 0.9865 - val_loss: 0.0819 - val_accuracy: 0.9772
Epoch 10/10
 -> id = 2  Epoch: 9   accuracy: 0.9915  val_acc: 0.97533333
48000/48000 - 88s - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0988 - val_accuracy: 0.9753
 -> id = 6  Epoch: 8   accuracy: 0.9649792  val_acc: 0.96325
48000/48000 - 104s - loss: 0.1183 - accuracy: 0.9650 - val_loss: 0.1357 - val_accuracy: 0.9632
Epoch 10/10
 -> id = 4  Epoch: 4   accuracy: 0.96641666  val_acc: 0.9694167
48000/48000 - 170s - loss: 0.1112 - accuracy: 0.9664 - val_loss: 0.1102 - val_accuracy: 0.9694
Epoch 6/10
 -> id = 15  Epoch: 3   accuracy: 0.95697916  val_acc: 0.9575833
48000/48000 - 218s - loss: 0.1434 - accuracy: 0.9570 - val_loss: 0.1360 - val_accuracy: 0.9576
Epoch 5/10
 -> id = 12  Epoch: 7   accuracy: 0.964625  val_acc: 0.96758336
48000/48000 - 115s - loss: 0.1128 - accuracy: 0.9646 - val_loss: 0.1121 - val_accuracy: 0.9676
Epoch 9/10
 -> id = 1  Epoch: 5   accuracy: 0.97022915  val_acc: 0.97258335
48000/48000 - 140s - loss: 0.0976 - accuracy: 0.9702 - val_loss: 0.0993 - val_accuracy: 0.9726
Epoch 7/10
 -> id = 7  Epoch: 5   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 144s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 7/10
 -> id = 18  Epoch: 6   accuracy: 0.2786875  val_acc: 0.38625
48000/48000 - 123s - loss: 1.7534 - accuracy: 0.2787 - val_loss: 1.4851 - val_accuracy: 0.3862
Epoch 8/10
 -> id = 16  Epoch: 9   accuracy: 0.9925  val_acc: 0.97725
48000/48000 - 92s - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.0917 - val_accuracy: 0.9772
 -> id = 8  Epoch: 7   accuracy: 0.9427083  val_acc: 0.93666667
48000/48000 - 113s - loss: 0.2114 - accuracy: 0.9427 - val_loss: 0.2333 - val_accuracy: 0.9367
Epoch 9/10
 -> id = 17  Epoch: 6   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 122s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 8/10
 -> id = 9  Epoch: 9   accuracy: 0.9617083  val_acc: 0.96925
48000/48000 - 88s - loss: 0.1221 - accuracy: 0.9617 - val_loss: 0.1088 - val_accuracy: 0.9693
 -> id = 19  Epoch: 7   accuracy: 0.60729164  val_acc: 0.9293333
48000/48000 - 107s - loss: 1.2303 - accuracy: 0.6073 - val_loss: 0.3803 - val_accuracy: 0.9293
Epoch 9/10
 -> id = 11  Epoch: 6   accuracy: 0.97804165  val_acc: 0.96966666
48000/48000 - 130s - loss: 0.0708 - accuracy: 0.9780 - val_loss: 0.1138 - val_accuracy: 0.9697
Epoch 8/10
 -> id = 10  Epoch: 9   accuracy: 0.9883958  val_acc: 0.9740833
48000/48000 - 90s - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.0901 - val_accuracy: 0.9741
 -> id = 6  Epoch: 9   accuracy: 0.9706875  val_acc: 0.9629167
48000/48000 - 86s - loss: 0.0994 - accuracy: 0.9707 - val_loss: 0.1297 - val_accuracy: 0.9629
 -> id = 5  Epoch: 5   accuracy: 0.92877084  val_acc: 0.95491666
48000/48000 - 151s - loss: 0.3420 - accuracy: 0.9288 - val_loss: 0.1836 - val_accuracy: 0.9549
Epoch 7/10
 -> id = 12  Epoch: 8   accuracy: 0.96622914  val_acc: 0.9694167
48000/48000 - 106s - loss: 0.1081 - accuracy: 0.9662 - val_loss: 0.0966 - val_accuracy: 0.9694
Epoch 10/10
 -> id = 8  Epoch: 8   accuracy: 0.9443542  val_acc: 0.9414167
48000/48000 - 100s - loss: 0.2023 - accuracy: 0.9444 - val_loss: 0.2181 - val_accuracy: 0.9414
Epoch 10/10
 -> id = 1  Epoch: 6   accuracy: 0.9729583  val_acc: 0.97083336
48000/48000 - 139s - loss: 0.0886 - accuracy: 0.9730 - val_loss: 0.1050 - val_accuracy: 0.9708
Epoch 8/10
 -> id = 7  Epoch: 6   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 138s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 8/10
 -> id = 4  Epoch: 5   accuracy: 0.9702917  val_acc: 0.9713333
48000/48000 - 155s - loss: 0.0965 - accuracy: 0.9703 - val_loss: 0.0997 - val_accuracy: 0.9713
Epoch 7/10
 -> id = 17  Epoch: 7   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 112s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 9/10
 -> id = 18  Epoch: 7   accuracy: 0.302625  val_acc: 0.39033332
48000/48000 - 121s - loss: 1.7225 - accuracy: 0.3026 - val_loss: 1.4352 - val_accuracy: 0.3903
Epoch 9/10
 -> id = 19  Epoch: 8   accuracy: 0.58783334  val_acc: 0.9091667
48000/48000 - 104s - loss: 1.2503 - accuracy: 0.5878 - val_loss: 0.4461 - val_accuracy: 0.9092
Epoch 10/10
 -> id = 11  Epoch: 7   accuracy: 0.97952086  val_acc: 0.971
48000/48000 - 119s - loss: 0.0644 - accuracy: 0.9795 - val_loss: 0.1088 - val_accuracy: 0.9710
Epoch 9/10
 -> id = 15  Epoch: 4   accuracy: 0.9590833  val_acc: 0.96466666
48000/48000 - 204s - loss: 0.1328 - accuracy: 0.9591 - val_loss: 0.1248 - val_accuracy: 0.9647
Epoch 6/10
 -> id = 12  Epoch: 9   accuracy: 0.96829164  val_acc: 0.97083336
48000/48000 - 94s - loss: 0.1001 - accuracy: 0.9683 - val_loss: 0.1015 - val_accuracy: 0.9708
 -> id = 5  Epoch: 6   accuracy: 0.92966664  val_acc: 0.95633334
48000/48000 - 137s - loss: 0.3268 - accuracy: 0.9297 - val_loss: 0.1654 - val_accuracy: 0.9563
Epoch 8/10
 -> id = 8  Epoch: 9   accuracy: 0.947  val_acc: 0.9410833
48000/48000 - 93s - loss: 0.1937 - accuracy: 0.9470 - val_loss: 0.2122 - val_accuracy: 0.9411
 -> id = 19  Epoch: 9   accuracy: 0.5708333  val_acc: 0.9264167
48000/48000 - 94s - loss: 1.2823 - accuracy: 0.5708 - val_loss: 0.4411 - val_accuracy: 0.9264
 -> id = 17  Epoch: 8   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 104s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 10/10
 -> id = 18  Epoch: 8   accuracy: 0.3080625  val_acc: 0.39208335
48000/48000 - 110s - loss: 1.6989 - accuracy: 0.3081 - val_loss: 1.3746 - val_accuracy: 0.3921
Epoch 10/10
 -> id = 7  Epoch: 7   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 126s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 9/10
 -> id = 1  Epoch: 7   accuracy: 0.9745  val_acc: 0.974
48000/48000 - 128s - loss: 0.0819 - accuracy: 0.9745 - val_loss: 0.0909 - val_accuracy: 0.9740
Epoch 9/10
 -> id = 11  Epoch: 8   accuracy: 0.98097914  val_acc: 0.9738333
48000/48000 - 97s - loss: 0.0609 - accuracy: 0.9810 - val_loss: 0.0988 - val_accuracy: 0.9738
Epoch 10/10
 -> id = 4  Epoch: 6   accuracy: 0.972  val_acc: 0.9744167
48000/48000 - 138s - loss: 0.0920 - accuracy: 0.9720 - val_loss: 0.0958 - val_accuracy: 0.9744
Epoch 8/10
 -> id = 5  Epoch: 7   accuracy: 0.9288125  val_acc: 0.94816667
48000/48000 - 110s - loss: 0.3321 - accuracy: 0.9288 - val_loss: 0.1939 - val_accuracy: 0.9482
Epoch 9/10
 -> id = 17  Epoch: 9   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 77s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
 -> id = 18  Epoch: 9   accuracy: 0.31235418  val_acc: 0.3985
48000/48000 - 94s - loss: 1.6775 - accuracy: 0.3124 - val_loss: 1.3537 - val_accuracy: 0.3985
 -> id = 11  Epoch: 9   accuracy: 0.98175  val_acc: 0.9684167
48000/48000 - 82s - loss: 0.0575 - accuracy: 0.9818 - val_loss: 0.1258 - val_accuracy: 0.9684
 -> id = 15  Epoch: 5   accuracy: 0.9647083  val_acc: 0.9579167
48000/48000 - 165s - loss: 0.1164 - accuracy: 0.9647 - val_loss: 0.1443 - val_accuracy: 0.9579
Epoch 7/10
 -> id = 7  Epoch: 8   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 103s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
Epoch 10/10
 -> id = 1  Epoch: 8   accuracy: 0.97508335  val_acc: 0.97358334
48000/48000 - 104s - loss: 0.0819 - accuracy: 0.9751 - val_loss: 0.0953 - val_accuracy: 0.9736
Epoch 10/10
 -> id = 4  Epoch: 7   accuracy: 0.97360414  val_acc: 0.9725
48000/48000 - 102s - loss: 0.0840 - accuracy: 0.9736 - val_loss: 0.1082 - val_accuracy: 0.9725
Epoch 9/10
 -> id = 5  Epoch: 8   accuracy: 0.93083334  val_acc: 0.9385
48000/48000 - 79s - loss: 0.3260 - accuracy: 0.9308 - val_loss: 0.2362 - val_accuracy: 0.9385
Epoch 10/10
 -> id = 7  Epoch: 9   accuracy: 0.09852083  val_acc: 0.0995
48000/48000 - 74s - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995
 -> id = 1  Epoch: 9   accuracy: 0.9787083  val_acc: 0.9701667
48000/48000 - 75s - loss: 0.0706 - accuracy: 0.9787 - val_loss: 0.1122 - val_accuracy: 0.9702
 -> id = 4  Epoch: 8   accuracy: 0.97475  val_acc: 0.97083336
48000/48000 - 72s - loss: 0.0816 - accuracy: 0.9747 - val_loss: 0.1071 - val_accuracy: 0.9708
Epoch 10/10
 -> id = 5  Epoch: 9   accuracy: 0.9303125  val_acc: 0.94233334
48000/48000 - 60s - loss: 0.3251 - accuracy: 0.9303 - val_loss: 0.2159 - val_accuracy: 0.9423
 -> id = 15  Epoch: 6   accuracy: 0.96477085  val_acc: 0.9665
48000/48000 - 100s - loss: 0.1136 - accuracy: 0.9648 - val_loss: 0.1128 - val_accuracy: 0.9665
Epoch 8/10
 -> id = 4  Epoch: 9   accuracy: 0.9760417  val_acc: 0.97033334
48000/48000 - 33s - loss: 0.0783 - accuracy: 0.9760 - val_loss: 0.1110 - val_accuracy: 0.9703
 -> id = 15  Epoch: 7   accuracy: 0.96827084  val_acc: 0.95783335
48000/48000 - 40s - loss: 0.1010 - accuracy: 0.9683 - val_loss: 0.1416 - val_accuracy: 0.9578
Epoch 9/10
 -> id = 15  Epoch: 8   accuracy: 0.97064584  val_acc: 0.96358335
48000/48000 - 29s - loss: 0.0967 - accuracy: 0.9706 - val_loss: 0.1249 - val_accuracy: 0.9636
Epoch 10/10
 -> id = 15  Epoch: 9   accuracy: 0.9719375  val_acc: 0.967
48000/48000 - 29s - loss: 0.0903 - accuracy: 0.9719 - val_loss: 0.1131 - val_accuracy: 0.9670
 id = 16  val_accuracy = 0.9772499799728394
 id = 0  val_accuracy = 0.9754166603088379
 id = 2  val_accuracy = 0.9753333330154419
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  2   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Model: "model_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_200 (Dense)            (None, 720)               565200
_________________________________________________________________
activation_159 (Activation)  (None, 720)               0
_________________________________________________________________
batch_normalization_83 (Batc (None, 720)               2880
_________________________________________________________________
dense_201 (Dense)            (None, 980)               706580
_________________________________________________________________
activation_160 (Activation)  (None, 980)               0
_________________________________________________________________
dropout_81 (Dropout)         (None, 980)               0
_________________________________________________________________
batch_normalization_84 (Batc (None, 980)               3920
_________________________________________________________________
dense_202 (Dense)            (None, 10)                9810
=================================================================
Total params: 1,288,390
Trainable params: 1,284,990
Non-trainable params: 3,400
_________________________________________________________________
None
Model: "model_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_203 (Dense)            (None, 180)               141300
_________________________________________________________________
activation_161 (Activation)  (None, 180)               0
_________________________________________________________________
dropout_82 (Dropout)         (None, 180)               0
_________________________________________________________________
batch_normalization_85 (Batc (None, 180)               720
_________________________________________________________________
dense_204 (Dense)            (None, 10)                1810
=================================================================
Total params: 143,830
Trainable params: 143,470
Non-trainable params: 360
_________________________________________________________________
None
Model: "model_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_205 (Dense)            (None, 110)               86350
_________________________________________________________________
activation_162 (Activation)  (None, 110)               0
_________________________________________________________________
dropout_83 (Dropout)         (None, 110)               0
_________________________________________________________________
batch_normalization_86 (Batc (None, 110)               440
_________________________________________________________________
dense_206 (Dense)            (None, 1520)              168720
_________________________________________________________________
activation_163 (Activation)  (None, 1520)              0
_________________________________________________________________
batch_normalization_87 (Batc (None, 1520)              6080
_________________________________________________________________
dense_207 (Dense)            (None, 10)                15210
=================================================================
Total params: 276,800
Trainable params: 273,540
Non-trainable params: 3,260
_________________________________________________________________
None
Model: "model_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_208 (Dense)            (None, 975)               765375
_________________________________________________________________
activation_164 (Activation)  (None, 975)               0
_________________________________________________________________
batch_normalization_88 (Batc (None, 975)               3900
_________________________________________________________________
dense_209 (Dense)            (None, 632)               616832
_________________________________________________________________
activation_165 (Activation)  (None, 632)               0
_________________________________________________________________
dropout_84 (Dropout)         (None, 632)               0
_________________________________________________________________
batch_normalization_89 (Batc (None, 632)               2528
_________________________________________________________________
dense_210 (Dense)            (None, 10)                6330
=================================================================
Total params: 1,394,965
Trainable params: 1,391,751
Non-trainable params: 3,214
_________________________________________________________________
None
Model: "model_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_211 (Dense)            (None, 234)               183690
_________________________________________________________________
activation_166 (Activation)  (None, 234)               0
_________________________________________________________________
dropout_85 (Dropout)         (None, 234)               0
_________________________________________________________________
batch_normalization_90 (Batc (None, 234)               936
_________________________________________________________________
dense_212 (Dense)            (None, 10)                2350
=================================================================
Total params: 186,976
Trainable params: 186,508
Non-trainable params: 468
_________________________________________________________________
None
Model: "model_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_213 (Dense)            (None, 1110)              871350
_________________________________________________________________
activation_167 (Activation)  (None, 1110)              0
_________________________________________________________________
dense_214 (Dense)            (None, 1490)              1655390
_________________________________________________________________
activation_168 (Activation)  (None, 1490)              0
_________________________________________________________________
dropout_86 (Dropout)         (None, 1490)              0
_________________________________________________________________
batch_normalization_91 (Batc (None, 1490)              5960
_________________________________________________________________
dense_215 (Dense)            (None, 10)                14910
=================================================================
Total params: 2,547,610
Trainable params: 2,544,630
Non-trainable params: 2,980
_________________________________________________________________
None
Model: "model_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_216 (Dense)            (None, 1700)              1334500
_________________________________________________________________
activation_169 (Activation)  (None, 1700)              0
_________________________________________________________________
dropout_87 (Dropout)         (None, 1700)              0
_________________________________________________________________
dense_217 (Dense)            (None, 10)                17010
=================================================================
Total params: 1,351,510
Trainable params: 1,351,510
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_218 (Dense)            (None, 1880)              1475800
_________________________________________________________________
activation_170 (Activation)  (None, 1880)              0
_________________________________________________________________
dropout_88 (Dropout)         (None, 1880)              0
_________________________________________________________________
batch_normalization_92 (Batc (None, 1880)              7520
_________________________________________________________________
dense_219 (Dense)            (None, 10)                18810
=================================================================
Total params: 1,502,130
Trainable params: 1,498,370
Non-trainable params: 3,760
_________________________________________________________________
None
Model: "model_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_220 (Dense)            (None, 1090)              855650
_________________________________________________________________
activation_171 (Activation)  (None, 1090)              0
_________________________________________________________________
dropout_89 (Dropout)         (None, 1090)              0
_________________________________________________________________
batch_normalization_93 (Batc (None, 1090)              4360
_________________________________________________________________
dense_221 (Dense)            (None, 1330)              1451030
_________________________________________________________________
activation_172 (Activation)  (None, 1330)              0
_________________________________________________________________
dropout_90 (Dropout)         (None, 1330)              0
_________________________________________________________________
dense_222 (Dense)            (None, 10)                13310
=================================================================
Total params: 2,324,350
Trainable params: 2,322,170
Non-trainable params: 2,180
_________________________________________________________________
None
Model: "model_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_223 (Dense)            (None, 690)               541650
_________________________________________________________________
activation_173 (Activation)  (None, 690)               0
_________________________________________________________________
dropout_91 (Dropout)         (None, 690)               0
_________________________________________________________________
dense_224 (Dense)            (None, 480)               331680
_________________________________________________________________
activation_174 (Activation)  (None, 480)               0
_________________________________________________________________
batch_normalization_94 (Batc (None, 480)               1920
_________________________________________________________________
dense_225 (Dense)            (None, 10)                4810
=================================================================
Total params: 880,060
Trainable params: 879,100
Non-trainable params: 960
_________________________________________________________________
None
Model: "model_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_226 (Dense)            (None, 1210)              949850
_________________________________________________________________
activation_175 (Activation)  (None, 1210)              0
_________________________________________________________________
batch_normalization_95 (Batc (None, 1210)              4840
_________________________________________________________________
dense_227 (Dense)            (None, 1080)              1307880
_________________________________________________________________
activation_176 (Activation)  (None, 1080)              0
_________________________________________________________________
dense_228 (Dense)            (None, 10)                10810
=================================================================
Total params: 2,273,380
Trainable params: 2,270,960
Non-trainable params: 2,420
_________________________________________________________________
None
Model: "model_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_229 (Dense)            (None, 250)               196250
_________________________________________________________________
activation_177 (Activation)  (None, 250)               0
_________________________________________________________________
batch_normalization_96 (Batc (None, 250)               1000
_________________________________________________________________
dense_230 (Dense)            (None, 400)               100400
_________________________________________________________________
activation_178 (Activation)  (None, 400)               0
_________________________________________________________________
dense_231 (Dense)            (None, 10)                4010
=================================================================
Total params: 301,660
Trainable params: 301,160
Non-trainable params: 500
_________________________________________________________________
None
Model: "model_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_232 (Dense)            (None, 1920)              1507200
_________________________________________________________________
activation_179 (Activation)  (None, 1920)              0
_________________________________________________________________
dropout_92 (Dropout)         (None, 1920)              0
_________________________________________________________________
dense_233 (Dense)            (None, 1480)              2843080
_________________________________________________________________
activation_180 (Activation)  (None, 1480)              0
_________________________________________________________________
batch_normalization_97 (Batc (None, 1480)              5920
_________________________________________________________________
dense_234 (Dense)            (None, 10)                14810
=================================================================
Total params: 4,371,010
Trainable params: 4,368,050
Non-trainable params: 2,960
_________________________________________________________________
None
Model: "model_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_235 (Dense)            (None, 630)               494550
_________________________________________________________________
activation_181 (Activation)  (None, 630)               0
_________________________________________________________________
batch_normalization_98 (Batc (None, 630)               2520
_________________________________________________________________
dense_236 (Dense)            (None, 10)                6310
=================================================================
Total params: 503,380
Trainable params: 502,120
Non-trainable params: 1,260
_________________________________________________________________
None
Model: "model_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_237 (Dense)            (None, 1050)              824250
_________________________________________________________________
activation_182 (Activation)  (None, 1050)              0
_________________________________________________________________
dropout_93 (Dropout)         (None, 1050)              0
_________________________________________________________________
batch_normalization_99 (Batc (None, 1050)              4200
_________________________________________________________________
dense_238 (Dense)            (None, 10)                10510
=================================================================
Total params: 838,960
Trainable params: 836,860
Non-trainable params: 2,100
_________________________________________________________________
None
Model: "model_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_239 (Dense)            (None, 50)                39250
_________________________________________________________________
activation_183 (Activation)  (None, 50)                0
_________________________________________________________________
dense_240 (Dense)            (None, 10)                510
=================================================================
Total params: 39,760
Trainable params: 39,760
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_241 (Dense)            (None, 1220)              957700
_________________________________________________________________
activation_184 (Activation)  (None, 1220)              0
_________________________________________________________________
dropout_94 (Dropout)         (None, 1220)              0
_________________________________________________________________
batch_normalization_100 (Bat (None, 1220)              4880
_________________________________________________________________
dense_242 (Dense)            (None, 10)                12210
=================================================================
Total params: 974,790
Trainable params: 972,350
Non-trainable params: 2,440
_________________________________________________________________
None
Model: "model_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_243 (Dense)            (None, 640)               502400
_________________________________________________________________
activation_185 (Activation)  (None, 640)               0
_________________________________________________________________
dense_244 (Dense)            (None, 10)                6410
=================================================================
Total params: 508,810
Trainable params: 508,810
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_245 (Dense)            (None, 480)               376800
_________________________________________________________________
activation_186 (Activation)  (None, 480)               0
_________________________________________________________________
batch_normalization_101 (Bat (None, 480)               1920
_________________________________________________________________
dense_246 (Dense)            (None, 10)                4810
=================================================================
Total params: 383,530
Trainable params: 382,570
Non-trainable params: 960
_________________________________________________________________
None
Model: "model_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_247 (Dense)            (None, 90)                70650
_________________________________________________________________
activation_187 (Activation)  (None, 90)                0
_________________________________________________________________
dense_248 (Dense)            (None, 1380)              125580
_________________________________________________________________
activation_188 (Activation)  (None, 1380)              0
_________________________________________________________________
batch_normalization_102 (Bat (None, 1380)              5520
_________________________________________________________________
dense_249 (Dense)            (None, 10)                13810
=================================================================
Total params: 215,560
Trainable params: 212,800
Non-trainable params: 2,760
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samplesTrain on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples

Epoch 1/10Epoch 1/10
Epoch 1/10Train on 48000 samples, validate on 12000 samplesTrain on 48000 samples, validate on 12000 samplesEpoch 1/10

Train on 48000 samples, validate on 12000 samples

Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples

Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Epoch 1/10

Epoch 1/10
Train on 48000 samples, validate on 12000 samplesEpoch 1/10Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples


Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10

Epoch 1/10
 -> id = 15  Epoch: 0   accuracy: 0.85772914  val_acc: 0.9245833
48000/48000 - 25s - loss: 0.5288 - accuracy: 0.8577 - val_loss: 0.2701 - val_accuracy: 0.9246
Epoch 2/10
 -> id = 17  Epoch: 0   accuracy: 0.858375  val_acc: 0.9145
48000/48000 - 30s - loss: 0.5223 - accuracy: 0.8584 - val_loss: 0.2984 - val_accuracy: 0.9145
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.8599167  val_acc: 0.92025
48000/48000 - 40s - loss: 0.4552 - accuracy: 0.8599 - val_loss: 0.2799 - val_accuracy: 0.9202
Epoch 2/10
 -> id = 4  Epoch: 0   accuracy: 0.8808542  val_acc: 0.9555
48000/48000 - 49s - loss: 0.3953 - accuracy: 0.8809 - val_loss: 0.1830 - val_accuracy: 0.9555
Epoch 2/10
 -> id = 13  Epoch: 0   accuracy: 0.8864167  val_acc: 0.89716667
48000/48000 - 55s - loss: 0.4115 - accuracy: 0.8864 - val_loss: 0.3554 - val_accuracy: 0.8972
Epoch 2/10
 -> id = 1  Epoch: 0   accuracy: 0.86508334  val_acc: 0.94766665
48000/48000 - 56s - loss: 0.4465 - accuracy: 0.8651 - val_loss: 0.2013 - val_accuracy: 0.9477
Epoch 2/10
 -> id = 18  Epoch: 0   accuracy: 0.91139585  val_acc: 0.94241667
48000/48000 - 57s - loss: 0.3071 - accuracy: 0.9114 - val_loss: 0.2287 - val_accuracy: 0.9424
Epoch 2/10
 -> id = 9  Epoch: 0   accuracy: 0.93095833  val_acc: 0.9475
48000/48000 - 62s - loss: 0.2359 - accuracy: 0.9310 - val_loss: 0.1697 - val_accuracy: 0.9475
Epoch 2/10
 -> id = 11  Epoch: 0   accuracy: 0.878125  val_acc: 0.93333334
48000/48000 - 62s - loss: 1.9108 - accuracy: 0.8781 - val_loss: 1.6210 - val_accuracy: 0.9333
Epoch 2/10
 -> id = 7  Epoch: 0   accuracy: 0.929625  val_acc: 0.9636667
48000/48000 - 64s - loss: 0.2372 - accuracy: 0.9296 - val_loss: 0.1351 - val_accuracy: 0.9637
Epoch 2/10
 -> id = 14  Epoch: 0   accuracy: 0.9245833  val_acc: 0.9590833
48000/48000 - 66s - loss: 0.2472 - accuracy: 0.9246 - val_loss: 0.1575 - val_accuracy: 0.9591
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.87616664  val_acc: 0.9295833
48000/48000 - 68s - loss: 0.4334 - accuracy: 0.8762 - val_loss: 0.2586 - val_accuracy: 0.9296
Epoch 2/10
 -> id = 15  Epoch: 1   accuracy: 0.9295833  val_acc: 0.9364167
48000/48000 - 44s - loss: 0.2534 - accuracy: 0.9296 - val_loss: 0.2207 - val_accuracy: 0.9364
Epoch 3/10
 -> id = 19  Epoch: 0   accuracy: 0.89227086  val_acc: 0.64425
48000/48000 - 72s - loss: 0.3687 - accuracy: 0.8923 - val_loss: 1.1271 - val_accuracy: 0.6442
Epoch 2/10
 -> id = 2  Epoch: 0   accuracy: 0.87929165  val_acc: 0.86433333
48000/48000 - 75s - loss: 0.4877 - accuracy: 0.8793 - val_loss: 1.4717 - val_accuracy: 0.8643
Epoch 2/10
 -> id = 17  Epoch: 1   accuracy: 0.9168958  val_acc: 0.92941666
48000/48000 - 48s - loss: 0.2882 - accuracy: 0.9169 - val_loss: 0.2500 - val_accuracy: 0.9294
Epoch 3/10
 -> id = 10  Epoch: 0   accuracy: 0.86908334  val_acc: 0.9123333
48000/48000 - 81s - loss: 0.6400 - accuracy: 0.8691 - val_loss: 0.3008 - val_accuracy: 0.9123
Epoch 2/10
 -> id = 4  Epoch: 1   accuracy: 0.94266665  val_acc: 0.96458334
48000/48000 - 33s - loss: 0.1954 - accuracy: 0.9427 - val_loss: 0.1244 - val_accuracy: 0.9646
Epoch 3/10
 -> id = 3  Epoch: 0   accuracy: 0.93841666  val_acc: 0.9540833
48000/48000 - 85s - loss: 0.2082 - accuracy: 0.9384 - val_loss: 0.1671 - val_accuracy: 0.9541
Epoch 2/10
 -> id = 5  Epoch: 0   accuracy: 0.91139585  val_acc: 0.94516665
48000/48000 - 86s - loss: 0.3061 - accuracy: 0.9114 - val_loss: 0.2024 - val_accuracy: 0.9452
Epoch 2/10
 -> id = 8  Epoch: 0   accuracy: 0.85983336  val_acc: 0.923
48000/48000 - 87s - loss: 0.6263 - accuracy: 0.8598 - val_loss: 0.2796 - val_accuracy: 0.9230
Epoch 2/10
 -> id = 6  Epoch: 1   accuracy: 0.9188542  val_acc: 0.9385833
48000/48000 - 50s - loss: 0.2729 - accuracy: 0.9189 - val_loss: 0.2149 - val_accuracy: 0.9386
Epoch 3/10
 -> id = 0  Epoch: 0   accuracy: 0.93789583  val_acc: 0.95841664
48000/48000 - 91s - loss: 0.2114 - accuracy: 0.9379 - val_loss: 0.1510 - val_accuracy: 0.9584
Epoch 2/10
 -> id = 1  Epoch: 1   accuracy: 0.93670833  val_acc: 0.96208334
48000/48000 - 42s - loss: 0.2253 - accuracy: 0.9367 - val_loss: 0.1342 - val_accuracy: 0.9621
Epoch 3/10
 -> id = 13  Epoch: 1   accuracy: 0.910125  val_acc: 0.9155833
48000/48000 - 46s - loss: 0.3197 - accuracy: 0.9101 - val_loss: 0.3132 - val_accuracy: 0.9156
Epoch 3/10
 -> id = 18  Epoch: 1   accuracy: 0.955375  val_acc: 0.9555
48000/48000 - 46s - loss: 0.1538 - accuracy: 0.9554 - val_loss: 0.1500 - val_accuracy: 0.9555
Epoch 3/10
 -> id = 9  Epoch: 1   accuracy: 0.9720625  val_acc: 0.96466666
48000/48000 - 44s - loss: 0.0929 - accuracy: 0.9721 - val_loss: 0.1157 - val_accuracy: 0.9647
Epoch 3/10
 -> id = 11  Epoch: 1   accuracy: 0.94439584  val_acc: 0.95266664
48000/48000 - 45s - loss: 1.3818 - accuracy: 0.9444 - val_loss: 1.1662 - val_accuracy: 0.9527
Epoch 3/10
 -> id = 15  Epoch: 2   accuracy: 0.9420417  val_acc: 0.94675
48000/48000 - 39s - loss: 0.2058 - accuracy: 0.9420 - val_loss: 0.1886 - val_accuracy: 0.9467
Epoch 4/10
 -> id = 12  Epoch: 0   accuracy: 0.8518125  val_acc: 0.34733334
48000/48000 - 109s - loss: 0.5637 - accuracy: 0.8518 - val_loss: 1.5816 - val_accuracy: 0.3473
Epoch 2/10
 -> id = 7  Epoch: 1   accuracy: 0.9666875  val_acc: 0.97008336
48000/48000 - 50s - loss: 0.1081 - accuracy: 0.9667 - val_loss: 0.0978 - val_accuracy: 0.9701
Epoch 3/10
 -> id = 4  Epoch: 2   accuracy: 0.95564586  val_acc: 0.97108334
48000/48000 - 34s - loss: 0.1507 - accuracy: 0.9556 - val_loss: 0.1030 - val_accuracy: 0.9711
Epoch 4/10
 -> id = 14  Epoch: 1   accuracy: 0.9668958  val_acc: 0.9715833
48000/48000 - 52s - loss: 0.1123 - accuracy: 0.9669 - val_loss: 0.0936 - val_accuracy: 0.9716
Epoch 3/10
 -> id = 17  Epoch: 2   accuracy: 0.9300625  val_acc: 0.9406667
48000/48000 - 43s - loss: 0.2419 - accuracy: 0.9301 - val_loss: 0.2134 - val_accuracy: 0.9407
Epoch 4/10
 -> id = 16  Epoch: 1   accuracy: 0.92725  val_acc: 0.9504167
48000/48000 - 53s - loss: 0.2495 - accuracy: 0.9273 - val_loss: 0.1783 - val_accuracy: 0.9504
Epoch 3/10
 -> id = 19  Epoch: 1   accuracy: 0.9405208  val_acc: 0.9378333
48000/48000 - 50s - loss: 0.2043 - accuracy: 0.9405 - val_loss: 0.2153 - val_accuracy: 0.9378
Epoch 3/10
 -> id = 2  Epoch: 1   accuracy: 0.95135415  val_acc: 0.9601667
48000/48000 - 49s - loss: 0.1569 - accuracy: 0.9514 - val_loss: 0.1763 - val_accuracy: 0.9602
Epoch 3/10
 -> id = 1  Epoch: 2   accuracy: 0.9496458  val_acc: 0.9669167
48000/48000 - 44s - loss: 0.1741 - accuracy: 0.9496 - val_loss: 0.1149 - val_accuracy: 0.9669
Epoch 4/10
 -> id = 6  Epoch: 2   accuracy: 0.938  val_acc: 0.9535
48000/48000 - 55s - loss: 0.2087 - accuracy: 0.9380 - val_loss: 0.1665 - val_accuracy: 0.9535
Epoch 4/10
 -> id = 10  Epoch: 1   accuracy: 0.9213125  val_acc: 0.93366665
48000/48000 - 64s - loss: 0.2707 - accuracy: 0.9213 - val_loss: 0.2321 - val_accuracy: 0.9337
Epoch 3/10
 -> id = 3  Epoch: 1   accuracy: 0.97291666  val_acc: 0.96975
48000/48000 - 65s - loss: 0.0917 - accuracy: 0.9729 - val_loss: 0.0990 - val_accuracy: 0.9697
Epoch 3/10
 -> id = 13  Epoch: 2   accuracy: 0.9147292  val_acc: 0.91433334
48000/48000 - 48s - loss: 0.3000 - accuracy: 0.9147 - val_loss: 0.3044 - val_accuracy: 0.9143
Epoch 4/10
 -> id = 15  Epoch: 3   accuracy: 0.9493333  val_acc: 0.9525
48000/48000 - 41s - loss: 0.1759 - accuracy: 0.9493 - val_loss: 0.1681 - val_accuracy: 0.9525
Epoch 5/10
 -> id = 18  Epoch: 2   accuracy: 0.96835417  val_acc: 0.96566665
48000/48000 - 47s - loss: 0.1067 - accuracy: 0.9684 - val_loss: 0.1186 - val_accuracy: 0.9657
Epoch 4/10
 -> id = 9  Epoch: 2   accuracy: 0.98075  val_acc: 0.9701667
48000/48000 - 45s - loss: 0.0609 - accuracy: 0.9808 - val_loss: 0.0986 - val_accuracy: 0.9702
Epoch 4/10
 -> id = 11  Epoch: 2   accuracy: 0.961875  val_acc: 0.96608335
48000/48000 - 45s - loss: 0.9869 - accuracy: 0.9619 - val_loss: 0.8353 - val_accuracy: 0.9661
Epoch 4/10
 -> id = 5  Epoch: 1   accuracy: 0.95979166  val_acc: 0.96133333
48000/48000 - 68s - loss: 0.1338 - accuracy: 0.9598 - val_loss: 0.2260 - val_accuracy: 0.9613
Epoch 3/10
 -> id = 8  Epoch: 1   accuracy: 0.9104375  val_acc: 0.94158334
48000/48000 - 67s - loss: 0.3106 - accuracy: 0.9104 - val_loss: 0.2031 - val_accuracy: 0.9416
Epoch 3/10
 -> id = 4  Epoch: 3   accuracy: 0.9626458  val_acc: 0.9715833
48000/48000 - 39s - loss: 0.1264 - accuracy: 0.9626 - val_loss: 0.0978 - val_accuracy: 0.9716
Epoch 5/10
 -> id = 0  Epoch: 1   accuracy: 0.9710625  val_acc: 0.9676667
48000/48000 - 67s - loss: 0.0926 - accuracy: 0.9711 - val_loss: 0.1142 - val_accuracy: 0.9677
Epoch 3/10
 -> id = 7  Epoch: 2   accuracy: 0.9747083  val_acc: 0.9744167
48000/48000 - 51s - loss: 0.0813 - accuracy: 0.9747 - val_loss: 0.0881 - val_accuracy: 0.9744
Epoch 4/10
 -> id = 17  Epoch: 3   accuracy: 0.94275  val_acc: 0.9475
48000/48000 - 46s - loss: 0.2009 - accuracy: 0.9427 - val_loss: 0.1863 - val_accuracy: 0.9475
Epoch 5/10
 -> id = 14  Epoch: 2   accuracy: 0.9741875  val_acc: 0.97325
48000/48000 - 51s - loss: 0.0823 - accuracy: 0.9742 - val_loss: 0.0864 - val_accuracy: 0.9732
Epoch 4/10
 -> id = 19  Epoch: 2   accuracy: 0.9550833  val_acc: 0.94266665
48000/48000 - 52s - loss: 0.1495 - accuracy: 0.9551 - val_loss: 0.1921 - val_accuracy: 0.9427
Epoch 4/10
 -> id = 16  Epoch: 2   accuracy: 0.948  val_acc: 0.96075
48000/48000 - 56s - loss: 0.1724 - accuracy: 0.9480 - val_loss: 0.1403 - val_accuracy: 0.9607
Epoch 4/10
 -> id = 2  Epoch: 2   accuracy: 0.96772915  val_acc: 0.96858335
48000/48000 - 56s - loss: 0.1072 - accuracy: 0.9677 - val_loss: 0.1023 - val_accuracy: 0.9686
Epoch 4/10
 -> id = 1  Epoch: 3   accuracy: 0.9566042  val_acc: 0.97041667
48000/48000 - 42s - loss: 0.1489 - accuracy: 0.9566 - val_loss: 0.1022 - val_accuracy: 0.9704
Epoch 5/10
 -> id = 15  Epoch: 4   accuracy: 0.9550833  val_acc: 0.95516664
48000/48000 - 38s - loss: 0.1549 - accuracy: 0.9551 - val_loss: 0.1564 - val_accuracy: 0.9552
Epoch 6/10
 -> id = 4  Epoch: 4   accuracy: 0.9670208  val_acc: 0.97241664
48000/48000 - 34s - loss: 0.1106 - accuracy: 0.9670 - val_loss: 0.0908 - val_accuracy: 0.9724
Epoch 6/10
 -> id = 12  Epoch: 1   accuracy: 0.9079792  val_acc: 0.9256667
48000/48000 - 84s - loss: 0.3095 - accuracy: 0.9080 - val_loss: 0.2540 - val_accuracy: 0.9257
Epoch 3/10
 -> id = 9  Epoch: 3   accuracy: 0.9862292  val_acc: 0.9745
48000/48000 - 44s - loss: 0.0421 - accuracy: 0.9862 - val_loss: 0.0954 - val_accuracy: 0.9745
Epoch 5/10
 -> id = 6  Epoch: 3   accuracy: 0.95108336  val_acc: 0.961
48000/48000 - 50s - loss: 0.1635 - accuracy: 0.9511 - val_loss: 0.1394 - val_accuracy: 0.9610
Epoch 5/10
 -> id = 13  Epoch: 3   accuracy: 0.9162083  val_acc: 0.91866666
48000/48000 - 46s - loss: 0.2954 - accuracy: 0.9162 - val_loss: 0.2935 - val_accuracy: 0.9187
Epoch 5/10
 -> id = 11  Epoch: 3   accuracy: 0.9716667  val_acc: 0.9684167
48000/48000 - 45s - loss: 0.7083 - accuracy: 0.9717 - val_loss: 0.6150 - val_accuracy: 0.9684
Epoch 5/10
 -> id = 18  Epoch: 3   accuracy: 0.9771042  val_acc: 0.9673333
48000/48000 - 48s - loss: 0.0778 - accuracy: 0.9771 - val_loss: 0.1074 - val_accuracy: 0.9673
Epoch 5/10
 -> id = 17  Epoch: 4   accuracy: 0.95122916  val_acc: 0.9529167
48000/48000 - 42s - loss: 0.1670 - accuracy: 0.9512 - val_loss: 0.1644 - val_accuracy: 0.9529
Epoch 6/10
 -> id = 10  Epoch: 2   accuracy: 0.9442292  val_acc: 0.9439167
48000/48000 - 65s - loss: 0.1901 - accuracy: 0.9442 - val_loss: 0.1894 - val_accuracy: 0.9439
Epoch 4/10
 -> id = 3  Epoch: 2   accuracy: 0.9797292  val_acc: 0.97425
48000/48000 - 62s - loss: 0.0643 - accuracy: 0.9797 - val_loss: 0.0896 - val_accuracy: 0.9743
Epoch 4/10
 -> id = 7  Epoch: 3   accuracy: 0.9785417  val_acc: 0.97758335
48000/48000 - 48s - loss: 0.0685 - accuracy: 0.9785 - val_loss: 0.0772 - val_accuracy: 0.9776
Epoch 5/10
 -> id = 14  Epoch: 3   accuracy: 0.980125  val_acc: 0.9755833
48000/48000 - 51s - loss: 0.0642 - accuracy: 0.9801 - val_loss: 0.0788 - val_accuracy: 0.9756
Epoch 5/10
 -> id = 19  Epoch: 3   accuracy: 0.9636458  val_acc: 0.95425
48000/48000 - 47s - loss: 0.1185 - accuracy: 0.9636 - val_loss: 0.1558 - val_accuracy: 0.9542
Epoch 5/10
 -> id = 4  Epoch: 5   accuracy: 0.9683958  val_acc: 0.97541666
48000/48000 - 32s - loss: 0.1020 - accuracy: 0.9684 - val_loss: 0.0853 - val_accuracy: 0.9754
Epoch 7/10
 -> id = 8  Epoch: 2   accuracy: 0.92758334  val_acc: 0.94633335
48000/48000 - 67s - loss: 0.2452 - accuracy: 0.9276 - val_loss: 0.1888 - val_accuracy: 0.9463
Epoch 4/10
 -> id = 1  Epoch: 4   accuracy: 0.96089584  val_acc: 0.9715
48000/48000 - 38s - loss: 0.1317 - accuracy: 0.9609 - val_loss: 0.0976 - val_accuracy: 0.9715
Epoch 6/10
 -> id = 5  Epoch: 2   accuracy: 0.96770835  val_acc: 0.93908334
48000/48000 - 69s - loss: 0.1085 - accuracy: 0.9677 - val_loss: 0.4125 - val_accuracy: 0.9391
Epoch 4/10
 -> id = 0  Epoch: 2   accuracy: 0.97979164  val_acc: 0.9701667
48000/48000 - 65s - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.0999 - val_accuracy: 0.9702
Epoch 4/10
 -> id = 15  Epoch: 5   accuracy: 0.9600833  val_acc: 0.95933336
48000/48000 - 40s - loss: 0.1389 - accuracy: 0.9601 - val_loss: 0.1449 - val_accuracy: 0.9593
Epoch 7/10
 -> id = 2  Epoch: 3   accuracy: 0.9748542  val_acc: 0.9685
48000/48000 - 51s - loss: 0.0820 - accuracy: 0.9749 - val_loss: 0.1040 - val_accuracy: 0.9685
Epoch 5/10
 -> id = 16  Epoch: 3   accuracy: 0.961  val_acc: 0.9645
48000/48000 - 55s - loss: 0.1275 - accuracy: 0.9610 - val_loss: 0.1183 - val_accuracy: 0.9645
Epoch 5/10
 -> id = 9  Epoch: 4   accuracy: 0.98852086  val_acc: 0.9695
48000/48000 - 44s - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.1147 - val_accuracy: 0.9695
Epoch 6/10
 -> id = 13  Epoch: 4   accuracy: 0.9195833  val_acc: 0.9199167
48000/48000 - 43s - loss: 0.2852 - accuracy: 0.9196 - val_loss: 0.2957 - val_accuracy: 0.9199
Epoch 6/10
 -> id = 11  Epoch: 4   accuracy: 0.978625  val_acc: 0.9691667
48000/48000 - 44s - loss: 0.5157 - accuracy: 0.9786 - val_loss: 0.4702 - val_accuracy: 0.9692
Epoch 6/10
 -> id = 18  Epoch: 4   accuracy: 0.98214585  val_acc: 0.9688333
48000/48000 - 44s - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.1067 - val_accuracy: 0.9688
Epoch 6/10
 -> id = 6  Epoch: 4   accuracy: 0.95875  val_acc: 0.961
48000/48000 - 51s - loss: 0.1340 - accuracy: 0.9588 - val_loss: 0.1304 - val_accuracy: 0.9610
Epoch 6/10
 -> id = 17  Epoch: 5   accuracy: 0.9600625  val_acc: 0.95925
48000/48000 - 43s - loss: 0.1399 - accuracy: 0.9601 - val_loss: 0.1440 - val_accuracy: 0.9592
Epoch 7/10
 -> id = 4  Epoch: 6   accuracy: 0.9713333  val_acc: 0.9755833
48000/48000 - 37s - loss: 0.0908 - accuracy: 0.9713 - val_loss: 0.0846 - val_accuracy: 0.9756
Epoch 8/10
 -> id = 7  Epoch: 4   accuracy: 0.9829375  val_acc: 0.9744167
48000/48000 - 53s - loss: 0.0569 - accuracy: 0.9829 - val_loss: 0.0868 - val_accuracy: 0.9744
Epoch 6/10
 -> id = 1  Epoch: 5   accuracy: 0.9633542  val_acc: 0.97275
 -> id = 15  Epoch: 6   accuracy: 0.96389586  val_acc: 0.960166748000/48000 - 46s - loss: 0.1200 - accuracy: 0.9634 - val_loss: 0.0945 - val_accuracy: 0.9728
Epoch 7/10

48000/48000 - 42s - loss: 0.1246 - accuracy: 0.9639 - val_loss: 0.1381 - val_accuracy: 0.9602
Epoch 8/10
 -> id = 10  Epoch: 3   accuracy: 0.9555  val_acc: 0.9575
48000/48000 - 62s - loss: 0.1443 - accuracy: 0.9555 - val_loss: 0.1470 - val_accuracy: 0.9575
Epoch 5/10
 -> id = 14  Epoch: 4   accuracy: 0.98245835  val_acc: 0.9776667
48000/48000 - 53s - loss: 0.0560 - accuracy: 0.9825 - val_loss: 0.0788 - val_accuracy: 0.9777
Epoch 6/10
 -> id = 19  Epoch: 4   accuracy: 0.96991664  val_acc: 0.9594167
48000/48000 - 53s - loss: 0.0962 - accuracy: 0.9699 - val_loss: 0.1476 - val_accuracy: 0.9594
Epoch 6/10
 -> id = 3  Epoch: 3   accuracy: 0.98377085  val_acc: 0.9709167
48000/48000 - 65s - loss: 0.0507 - accuracy: 0.9838 - val_loss: 0.0983 - val_accuracy: 0.9709
Epoch 5/10
 -> id = 12  Epoch: 2   accuracy: 0.9299167  val_acc: 0.94425
48000/48000 - 87s - loss: 0.2347 - accuracy: 0.9299 - val_loss: 0.1911 - val_accuracy: 0.9442
Epoch 4/10
 -> id = 9  Epoch: 5   accuracy: 0.99139583  val_acc: 0.97533333
48000/48000 - 44s - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.0976 - val_accuracy: 0.9753
Epoch 7/10
 -> id = 13  Epoch: 5   accuracy: 0.9196875  val_acc: 0.9184167
48000/48000 - 44s - loss: 0.2831 - accuracy: 0.9197 - val_loss: 0.2999 - val_accuracy: 0.9184
Epoch 7/10
 -> id = 2  Epoch: 4   accuracy: 0.98052084  val_acc: 0.9716667
48000/48000 - 51s - loss: 0.0635 - accuracy: 0.9805 - val_loss: 0.0946 - val_accuracy: 0.9717
Epoch 6/10
 -> id = 16  Epoch: 4   accuracy: 0.9689583  val_acc: 0.9691667
48000/48000 - 53s - loss: 0.1010 - accuracy: 0.9690 - val_loss: 0.1060 - val_accuracy: 0.9692
Epoch 6/10
 -> id = 11  Epoch: 5   accuracy: 0.98235416  val_acc: 0.97225
48000/48000 - 45s - loss: 0.3856 - accuracy: 0.9824 - val_loss: 0.3685 - val_accuracy: 0.9722
Epoch 7/10
 -> id = 0  Epoch: 3   accuracy: 0.9826667  val_acc: 0.97033334
48000/48000 - 64s - loss: 0.0550 - accuracy: 0.9827 - val_loss: 0.1064 - val_accuracy: 0.9703
Epoch 5/10
 -> id = 18  Epoch: 5   accuracy: 0.9866875  val_acc: 0.97291666
48000/48000 - 47s - loss: 0.0467 - accuracy: 0.9867 - val_loss: 0.0905 - val_accuracy: 0.9729
Epoch 7/10
 -> id = 5  Epoch: 3   accuracy: 0.9690625  val_acc: 0.93808335
48000/48000 - 68s - loss: 0.1003 - accuracy: 0.9691 - val_loss: 0.4462 - val_accuracy: 0.9381
Epoch 5/10
 -> id = 4  Epoch: 7   accuracy: 0.97302085  val_acc: 0.9763333
48000/48000 - 33s - loss: 0.0882 - accuracy: 0.9730 - val_loss: 0.0840 - val_accuracy: 0.9763
Epoch 9/10
 -> id = 6  Epoch: 5   accuracy: 0.96552086  val_acc: 0.96258336
48000/48000 - 48s - loss: 0.1103 - accuracy: 0.9655 - val_loss: 0.1221 - val_accuracy: 0.9626
Epoch 7/10
 -> id = 8  Epoch: 3   accuracy: 0.93720835  val_acc: 0.95608336
48000/48000 - 72s - loss: 0.2110 - accuracy: 0.9372 - val_loss: 0.1557 - val_accuracy: 0.9561
Epoch 5/10
 -> id = 17  Epoch: 6   accuracy: 0.9663333  val_acc: 0.96025
48000/48000 - 42s - loss: 0.1186 - accuracy: 0.9663 - val_loss: 0.1337 - val_accuracy: 0.9603
Epoch 8/10
 -> id = 15  Epoch: 7   accuracy: 0.9671875  val_acc: 0.96133333
48000/48000 - 41s - loss: 0.1135 - accuracy: 0.9672 - val_loss: 0.1322 - val_accuracy: 0.9613
Epoch 9/10
 -> id = 1  Epoch: 6   accuracy: 0.96739584  val_acc: 0.9744167
48000/48000 - 43s - loss: 0.1093 - accuracy: 0.9674 - val_loss: 0.0881 - val_accuracy: 0.9744
Epoch 8/10
 -> id = 7  Epoch: 5   accuracy: 0.9835208  val_acc: 0.977
48000/48000 - 52s - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.0776 - val_accuracy: 0.9770
Epoch 7/10
 -> id = 19  Epoch: 5   accuracy: 0.97360414  val_acc: 0.95383334
48000/48000 - 51s - loss: 0.0827 - accuracy: 0.9736 - val_loss: 0.1582 - val_accuracy: 0.9538
Epoch 7/10
 -> id = 14  Epoch: 5   accuracy: 0.98422915  val_acc: 0.97775
48000/48000 - 52s - loss: 0.0495 - accuracy: 0.9842 - val_loss: 0.0776 - val_accuracy: 0.9778
Epoch 7/10
 -> id = 9  Epoch: 6   accuracy: 0.991125  val_acc: 0.9755
48000/48000 - 45s - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.0875 - val_accuracy: 0.9755
Epoch 8/10
 -> id = 13  Epoch: 6   accuracy: 0.9191667  val_acc: 0.9155833
48000/48000 - 44s - loss: 0.2800 - accuracy: 0.9192 - val_loss: 0.2983 - val_accuracy: 0.9156
Epoch 8/10
 -> id = 4  Epoch: 8   accuracy: 0.97435415  val_acc: 0.97783333
48000/48000 - 38s - loss: 0.0816 - accuracy: 0.9744 - val_loss: 0.0790 - val_accuracy: 0.9778
Epoch 10/10
 -> id = 11  Epoch: 6   accuracy: 0.9847083  val_acc: 0.9723333
48000/48000 - 48s - loss: 0.2969 - accuracy: 0.9847 - val_loss: 0.2997 - val_accuracy: 0.9723
Epoch 8/10
 -> id = 2  Epoch: 5   accuracy: 0.9838333  val_acc: 0.9738333
48000/48000 - 52s - loss: 0.0508 - accuracy: 0.9838 - val_loss: 0.0905 - val_accuracy: 0.9738
Epoch 7/10
 -> id = 18  Epoch: 6   accuracy: 0.98910415  val_acc: 0.97108334
48000/48000 - 47s - loss: 0.0370 - accuracy: 0.9891 - val_loss: 0.1025 - val_accuracy: 0.9711
Epoch 8/10
 -> id = 10  Epoch: 4   accuracy: 0.96460414  val_acc: 0.9605833
48000/48000 - 65s - loss: 0.1161 - accuracy: 0.9646 - val_loss: 0.1436 - val_accuracy: 0.9606
Epoch 6/10
 -> id = 16  Epoch: 5   accuracy: 0.97520834  val_acc: 0.9686667
48000/48000 - 55s - loss: 0.0786 - accuracy: 0.9752 - val_loss: 0.1036 - val_accuracy: 0.9687
Epoch 7/10
 -> id = 3  Epoch: 4   accuracy: 0.98604167  val_acc: 0.97466666
48000/48000 - 65s - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.0894 - val_accuracy: 0.9747
Epoch 6/10
 -> id = 17  Epoch: 7   accuracy: 0.9720208  val_acc: 0.9635
48000/48000 - 48s - loss: 0.1002 - accuracy: 0.9720 - val_loss: 0.1276 - val_accuracy: 0.9635
Epoch 9/10
 -> id = 6  Epoch: 6   accuracy: 0.9720208  val_acc: 0.96725
48000/48000 - 53s - loss: 0.0925 - accuracy: 0.9720 - val_loss: 0.1082 - val_accuracy: 0.9672
Epoch 8/10
 -> id = 15  Epoch: 8   accuracy: 0.97022915  val_acc: 0.96416664
48000/48000 - 44s - loss: 0.1036 - accuracy: 0.9702 - val_loss: 0.1297 - val_accuracy: 0.9642
Epoch 10/10
 -> id = 0  Epoch: 4   accuracy: 0.98745835  val_acc: 0.9745
48000/48000 - 68s - loss: 0.0397 - accuracy: 0.9875 - val_loss: 0.0887 - val_accuracy: 0.9745
Epoch 6/10
 -> id = 1  Epoch: 7   accuracy: 0.9679792  val_acc: 0.97366667
48000/48000 - 43s - loss: 0.1027 - accuracy: 0.9680 - val_loss: 0.0872 - val_accuracy: 0.9737
Epoch 9/10
 -> id = 8  Epoch: 4   accuracy: 0.94570833  val_acc: 0.959
48000/48000 - 68s - loss: 0.1805 - accuracy: 0.9457 - val_loss: 0.1439 - val_accuracy: 0.9590
Epoch 6/10
 -> id = 5  Epoch: 4   accuracy: 0.9704792  val_acc: 0.904
48000/48000 - 73s - loss: 0.0953 - accuracy: 0.9705 - val_loss: 0.7040 - val_accuracy: 0.9040
Epoch 6/10
 -> id = 4  Epoch: 9   accuracy: 0.97595835  val_acc: 0.9784167
48000/48000 - 36s - loss: 0.0756 - accuracy: 0.9760 - val_loss: 0.0756 - val_accuracy: 0.9784
 -> id = 12  Epoch: 3   accuracy: 0.9442292  val_acc: 0.949
48000/48000 - 86s - loss: 0.1816 - accuracy: 0.9442 - val_loss: 0.1613 - val_accuracy: 0.9490
Epoch 5/10
 -> id = 7  Epoch: 6   accuracy: 0.9844375  val_acc: 0.97716665
48000/48000 - 51s - loss: 0.0463 - accuracy: 0.9844 - val_loss: 0.0808 - val_accuracy: 0.9772
Epoch 8/10
 -> id = 9  Epoch: 7   accuracy: 0.9939375  val_acc: 0.9715
48000/48000 - 44s - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.1190 - val_accuracy: 0.9715
Epoch 9/10
 -> id = 13  Epoch: 7   accuracy: 0.92095834  val_acc: 0.92258334
48000/48000 - 43s - loss: 0.2779 - accuracy: 0.9210 - val_loss: 0.2862 - val_accuracy: 0.9226
Epoch 9/10
 -> id = 19  Epoch: 6   accuracy: 0.9775417  val_acc: 0.9496667
48000/48000 - 48s - loss: 0.0702 - accuracy: 0.9775 - val_loss: 0.1893 - val_accuracy: 0.9497
Epoch 8/10
 -> id = 11  Epoch: 7   accuracy: 0.9876875  val_acc: 0.976
48000/48000 - 40s - loss: 0.2316 - accuracy: 0.9877 - val_loss: 0.2462 - val_accuracy: 0.9760
Epoch 9/10
 -> id = 14  Epoch: 6   accuracy: 0.9855  val_acc: 0.97616667
48000/48000 - 53s - loss: 0.0428 - accuracy: 0.9855 - val_loss: 0.0801 - val_accuracy: 0.9762
Epoch 8/10
 -> id = 18  Epoch: 7   accuracy: 0.99175  val_acc: 0.97541666
48000/48000 - 44s - loss: 0.0287 - accuracy: 0.9918 - val_loss: 0.0851 - val_accuracy: 0.9754
Epoch 9/10
 -> id = 2  Epoch: 6   accuracy: 0.986625  val_acc: 0.9748333
48000/48000 - 51s - loss: 0.0412 - accuracy: 0.9866 - val_loss: 0.0898 - val_accuracy: 0.9748
Epoch 8/10
 -> id = 17  Epoch: 8   accuracy: 0.9759375  val_acc: 0.96725
48000/48000 - 45s - loss: 0.0860 - accuracy: 0.9759 - val_loss: 0.1101 - val_accuracy: 0.9672
Epoch 10/10
 -> id = 15  Epoch: 9   accuracy: 0.97227085  val_acc: 0.96241665
48000/48000 - 38s - loss: 0.0958 - accuracy: 0.9723 - val_loss: 0.1259 - val_accuracy: 0.9624
 -> id = 16  Epoch: 6   accuracy: 0.97945833  val_acc: 0.97241664
48000/48000 - 55s - loss: 0.0663 - accuracy: 0.9795 - val_loss: 0.0933 - val_accuracy: 0.9724
Epoch 8/10
 -> id = 6  Epoch: 7   accuracy: 0.975375  val_acc: 0.9711667
48000/48000 - 50s - loss: 0.0796 - accuracy: 0.9754 - val_loss: 0.0981 - val_accuracy: 0.9712
Epoch 9/10
 -> id = 1  Epoch: 8   accuracy: 0.9693125  val_acc: 0.97675
48000/48000 - 41s - loss: 0.0979 - accuracy: 0.9693 - val_loss: 0.0836 - val_accuracy: 0.9768
Epoch 10/10
 -> id = 10  Epoch: 5   accuracy: 0.9698125  val_acc: 0.9683333
48000/48000 - 62s - loss: 0.0962 - accuracy: 0.9698 - val_loss: 0.1144 - val_accuracy: 0.9683
Epoch 7/10
 -> id = 3  Epoch: 5   accuracy: 0.9891667  val_acc: 0.97566664
48000/48000 - 64s - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.0845 - val_accuracy: 0.9757
Epoch 7/10
 -> id = 9  Epoch: 8   accuracy: 0.99366665  val_acc: 0.97908336
48000/48000 - 43s - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.0856 - val_accuracy: 0.9791
Epoch 10/10
 -> id = 13  Epoch: 8   accuracy: 0.92291665  val_acc: 0.9184167
48000/48000 - 45s - loss: 0.2734 - accuracy: 0.9229 - val_loss: 0.3006 - val_accuracy: 0.9184
Epoch 10/10
 -> id = 0  Epoch: 5   accuracy: 0.9884375  val_acc: 0.9744167
48000/48000 - 63s - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.0886 - val_accuracy: 0.9744
Epoch 7/10
 -> id = 7  Epoch: 7   accuracy: 0.98672915  val_acc: 0.97866666
48000/48000 - 50s - loss: 0.0411 - accuracy: 0.9867 - val_loss: 0.0750 - val_accuracy: 0.9787
Epoch 9/10
 -> id = 11  Epoch: 8   accuracy: 0.9894375  val_acc: 0.9770833
48000/48000 - 46s - loss: 0.1860 - accuracy: 0.9894 - val_loss: 0.2108 - val_accuracy: 0.9771
Epoch 10/10
 -> id = 19  Epoch: 7   accuracy: 0.980375  val_acc: 0.96533334
48000/48000 - 50s - loss: 0.0617 - accuracy: 0.9804 - val_loss: 0.1288 - val_accuracy: 0.9653
Epoch 9/10
 -> id = 18  Epoch: 8   accuracy: 0.99322915  val_acc: 0.9748333
48000/48000 - 45s - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.0859 - val_accuracy: 0.9748
Epoch 10/10
 -> id = 17  Epoch: 9   accuracy: 0.9796875  val_acc: 0.9691667
48000/48000 - 43s - loss: 0.0734 - accuracy: 0.9797 - val_loss: 0.1020 - val_accuracy: 0.9692
 -> id = 14  Epoch: 7   accuracy: 0.98641664  val_acc: 0.9775
48000/48000 - 51s - loss: 0.0412 - accuracy: 0.9864 - val_loss: 0.0796 - val_accuracy: 0.9775
Epoch 9/10
 -> id = 8  Epoch: 5   accuracy: 0.95135415  val_acc: 0.9644167
48000/48000 - 68s - loss: 0.1611 - accuracy: 0.9514 - val_loss: 0.1202 - val_accuracy: 0.9644
Epoch 7/10
 -> id = 5  Epoch: 5   accuracy: 0.9691042  val_acc: 0.784
48000/48000 - 67s - loss: 0.0982 - accuracy: 0.9691 - val_loss: 1.4525 - val_accuracy: 0.7840
Epoch 7/10
 -> id = 2  Epoch: 7   accuracy: 0.9887083  val_acc: 0.97541666
48000/48000 - 49s - loss: 0.0343 - accuracy: 0.9887 - val_loss: 0.0906 - val_accuracy: 0.9754
Epoch 9/10
 -> id = 1  Epoch: 9   accuracy: 0.9711875  val_acc: 0.97675
48000/48000 - 42s - loss: 0.0900 - accuracy: 0.9712 - val_loss: 0.0811 - val_accuracy: 0.9768
 -> id = 6  Epoch: 8   accuracy: 0.97802085  val_acc: 0.9709167
48000/48000 - 48s - loss: 0.0692 - accuracy: 0.9780 - val_loss: 0.0966 - val_accuracy: 0.9709
Epoch 10/10
 -> id = 16  Epoch: 7   accuracy: 0.9825208  val_acc: 0.97533333
48000/48000 - 51s - loss: 0.0537 - accuracy: 0.9825 - val_loss: 0.0824 - val_accuracy: 0.9753
Epoch 9/10
 -> id = 12  Epoch: 4   accuracy: 0.9571875  val_acc: 0.9558333
48000/48000 - 84s - loss: 0.1382 - accuracy: 0.9572 - val_loss: 0.1359 - val_accuracy: 0.9558
Epoch 6/10
 -> id = 9  Epoch: 9   accuracy: 0.994  val_acc: 0.978
48000/48000 - 43s - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0855 - val_accuracy: 0.9780
 -> id = 13  Epoch: 9   accuracy: 0.921875  val_acc: 0.9255
48000/48000 - 42s - loss: 0.2737 - accuracy: 0.9219 - val_loss: 0.2794 - val_accuracy: 0.9255
 -> id = 10  Epoch: 6   accuracy: 0.97327083  val_acc: 0.9690833
48000/48000 - 61s - loss: 0.0842 - accuracy: 0.9733 - val_loss: 0.1138 - val_accuracy: 0.9691
Epoch 8/10
 -> id = 11  Epoch: 9   accuracy: 0.99072915  val_acc: 0.9776667
48000/48000 - 40s - loss: 0.1516 - accuracy: 0.9907 - val_loss: 0.1861 - val_accuracy: 0.9777
 -> id = 18  Epoch: 9   accuracy: 0.9950208  val_acc: 0.97675
48000/48000 - 39s - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.0826 - val_accuracy: 0.9768
 -> id = 3  Epoch: 6   accuracy: 0.99016666  val_acc: 0.97575
48000/48000 - 59s - loss: 0.0305 - accuracy: 0.9902 - val_loss: 0.0841 - val_accuracy: 0.9758
Epoch 8/10
 -> id = 19  Epoch: 8   accuracy: 0.9826667  val_acc: 0.96716666
48000/48000 - 42s - loss: 0.0548 - accuracy: 0.9827 - val_loss: 0.1364 - val_accuracy: 0.9672
Epoch 10/10
 -> id = 7  Epoch: 8   accuracy: 0.98658335  val_acc: 0.98025
48000/48000 - 46s - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.0705 - val_accuracy: 0.9803
Epoch 10/10
 -> id = 14  Epoch: 8   accuracy: 0.9874167  val_acc: 0.9769167
48000/48000 - 45s - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0833 - val_accuracy: 0.9769
Epoch 10/10
 -> id = 0  Epoch: 6   accuracy: 0.989875  val_acc: 0.978
48000/48000 - 58s - loss: 0.0319 - accuracy: 0.9899 - val_loss: 0.0796 - val_accuracy: 0.9780
Epoch 8/10
 -> id = 2  Epoch: 8   accuracy: 0.98920834  val_acc: 0.975
48000/48000 - 44s - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.0949 - val_accuracy: 0.9750
Epoch 10/10
 -> id = 6  Epoch: 9   accuracy: 0.98114586  val_acc: 0.97425
48000/48000 - 41s - loss: 0.0606 - accuracy: 0.9811 - val_loss: 0.0824 - val_accuracy: 0.9743
 -> id = 16  Epoch: 8   accuracy: 0.98616666  val_acc: 0.97825
48000/48000 - 43s - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.0797 - val_accuracy: 0.9783
Epoch 10/10
 -> id = 8  Epoch: 6   accuracy: 0.95558333  val_acc: 0.9645
48000/48000 - 60s - loss: 0.1479 - accuracy: 0.9556 - val_loss: 0.1267 - val_accuracy: 0.9645
Epoch 8/10
 -> id = 5  Epoch: 6   accuracy: 0.96920836  val_acc: 0.7071667
48000/48000 - 60s - loss: 0.0984 - accuracy: 0.9692 - val_loss: 3.7824 - val_accuracy: 0.7072
Epoch 8/10
 -> id = 19  Epoch: 9   accuracy: 0.98354167  val_acc: 0.96875
48000/48000 - 37s - loss: 0.0503 - accuracy: 0.9835 - val_loss: 0.1353 - val_accuracy: 0.9688
 -> id = 7  Epoch: 9   accuracy: 0.9885625  val_acc: 0.9785
48000/48000 - 41s - loss: 0.0356 - accuracy: 0.9886 - val_loss: 0.0766 - val_accuracy: 0.9785
 -> id = 10  Epoch: 7   accuracy: 0.9759375  val_acc: 0.96475
48000/48000 - 50s - loss: 0.0758 - accuracy: 0.9759 - val_loss: 0.1370 - val_accuracy: 0.9647
Epoch 9/10
 -> id = 14  Epoch: 9   accuracy: 0.9883958  val_acc: 0.9791667
48000/48000 - 35s - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.0760 - val_accuracy: 0.9792
 -> id = 2  Epoch: 9   accuracy: 0.99225  val_acc: 0.97583336
48000/48000 - 33s - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0989 - val_accuracy: 0.9758
 -> id = 3  Epoch: 7   accuracy: 0.9911042  val_acc: 0.97583336
48000/48000 - 48s - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.0884 - val_accuracy: 0.9758
Epoch 9/10
 -> id = 12  Epoch: 5   accuracy: 0.96402085  val_acc: 0.95775
48000/48000 - 68s - loss: 0.1144 - accuracy: 0.9640 - val_loss: 0.1304 - val_accuracy: 0.9578
Epoch 7/10
 -> id = 16  Epoch: 9   accuracy: 0.9874167  val_acc: 0.97625
48000/48000 - 31s - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0831 - val_accuracy: 0.9762
 -> id = 0  Epoch: 7   accuracy: 0.990375  val_acc: 0.9765
48000/48000 - 45s - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.0892 - val_accuracy: 0.9765
Epoch 9/10
 -> id = 5  Epoch: 7   accuracy: 0.9689583  val_acc: 0.0995
48000/48000 - 42s - loss: 0.1006 - accuracy: 0.9690 - val_loss: nan - val_accuracy: 0.0995
Epoch 9/10
 -> id = 8  Epoch: 7   accuracy: 0.9580625  val_acc: 0.9655
48000/48000 - 44s - loss: 0.1393 - accuracy: 0.9581 - val_loss: 0.1262 - val_accuracy: 0.9655
Epoch 9/10
 -> id = 10  Epoch: 8   accuracy: 0.9795  val_acc: 0.96641666
48000/48000 - 34s - loss: 0.0640 - accuracy: 0.9795 - val_loss: 0.1335 - val_accuracy: 0.9664
Epoch 10/10
 -> id = 3  Epoch: 8   accuracy: 0.9931458  val_acc: 0.97683334
48000/48000 - 33s - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0841 - val_accuracy: 0.9768
Epoch 10/10
 -> id = 0  Epoch: 8   accuracy: 0.99258333  val_acc: 0.9775
48000/48000 - 35s - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0941 - val_accuracy: 0.9775
Epoch 10/10
 -> id = 12  Epoch: 6   accuracy: 0.9694375  val_acc: 0.965
48000/48000 - 48s - loss: 0.0950 - accuracy: 0.9694 - val_loss: 0.1129 - val_accuracy: 0.9650
Epoch 8/10
 -> id = 5  Epoch: 8   accuracy: 0.9675  val_acc: 0.0995
48000/48000 - 34s - loss: 0.1049 - accuracy: 0.9675 - val_loss: nan - val_accuracy: 0.0995
Epoch 10/10
 -> id = 8  Epoch: 8   accuracy: 0.9628125  val_acc: 0.96933335
48000/48000 - 36s - loss: 0.1235 - accuracy: 0.9628 - val_loss: 0.1106 - val_accuracy: 0.9693
Epoch 10/10
 -> id = 10  Epoch: 9   accuracy: 0.9830625  val_acc: 0.9685
48000/48000 - 32s - loss: 0.0540 - accuracy: 0.9831 - val_loss: 0.1268 - val_accuracy: 0.9685
 -> id = 3  Epoch: 9   accuracy: 0.99310416  val_acc: 0.9755
48000/48000 - 32s - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0948 - val_accuracy: 0.9755
 -> id = 0  Epoch: 9   accuracy: 0.993375  val_acc: 0.97833335
48000/48000 - 30s - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.0946 - val_accuracy: 0.9783
 -> id = 5  Epoch: 9   accuracy: 0.8215208  val_acc: 0.0995
48000/48000 - 27s - loss: nan - accuracy: 0.8215 - val_loss: nan - val_accuracy: 0.0995
 -> id = 8  Epoch: 9   accuracy: 0.96402085  val_acc: 0.96933335
48000/48000 - 25s - loss: 0.1225 - accuracy: 0.9640 - val_loss: 0.1104 - val_accuracy: 0.9693
 -> id = 12  Epoch: 7   accuracy: 0.97510415  val_acc: 0.96283334
48000/48000 - 31s - loss: 0.0778 - accuracy: 0.9751 - val_loss: 0.1251 - val_accuracy: 0.9628
Epoch 9/10
 -> id = 12  Epoch: 8   accuracy: 0.9791458  val_acc: 0.96325
48000/48000 - 12s - loss: 0.0647 - accuracy: 0.9791 - val_loss: 0.1180 - val_accuracy: 0.9632
Epoch 10/10
 -> id = 12  Epoch: 9   accuracy: 0.98127085  val_acc: 0.97175
48000/48000 - 12s - loss: 0.0568 - accuracy: 0.9813 - val_loss: 0.0937 - val_accuracy: 0.9718
 id = 14  val_accuracy = 0.9791666865348816
 id = 7  val_accuracy = 0.9785000085830688
 id = 4  val_accuracy = 0.9784166812896729
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  3   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Model: "model_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_250 (Dense)            (None, 1050)              824250
_________________________________________________________________
activation_189 (Activation)  (None, 1050)              0
_________________________________________________________________
dropout_95 (Dropout)         (None, 1050)              0
_________________________________________________________________
batch_normalization_103 (Bat (None, 1050)              4200
_________________________________________________________________
dense_251 (Dense)            (None, 10)                10510
=================================================================
Total params: 838,960
Trainable params: 836,860
Non-trainable params: 2,100
_________________________________________________________________
None
Model: "model_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_252 (Dense)            (None, 1880)              1475800
_________________________________________________________________
activation_190 (Activation)  (None, 1880)              0
_________________________________________________________________
dropout_96 (Dropout)         (None, 1880)              0
_________________________________________________________________
batch_normalization_104 (Bat (None, 1880)              7520
_________________________________________________________________
dense_253 (Dense)            (None, 10)                18810
=================================================================
Total params: 1,502,130
Trainable params: 1,498,370
Non-trainable params: 3,760
_________________________________________________________________
None
Model: "model_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_254 (Dense)            (None, 234)               183690
_________________________________________________________________
activation_191 (Activation)  (None, 234)               0
_________________________________________________________________
dropout_97 (Dropout)         (None, 234)               0
_________________________________________________________________
batch_normalization_105 (Bat (None, 234)               936
_________________________________________________________________
dense_255 (Dense)            (None, 10)                2350
=================================================================
Total params: 186,976
Trainable params: 186,508
Non-trainable params: 468
_________________________________________________________________
None
Model: "model_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_256 (Dense)            (None, 1542)              1210470
_________________________________________________________________
activation_192 (Activation)  (None, 1542)              0
_________________________________________________________________
dropout_98 (Dropout)         (None, 1542)              0
_________________________________________________________________
batch_normalization_106 (Bat (None, 1542)              6168
_________________________________________________________________
dense_257 (Dense)            (None, 10)                15430
=================================================================
Total params: 1,232,068
Trainable params: 1,228,984
Non-trainable params: 3,084
_________________________________________________________________
None
Model: "model_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_258 (Dense)            (None, 1554)              1219890
_________________________________________________________________
activation_193 (Activation)  (None, 1554)              0
_________________________________________________________________
dropout_99 (Dropout)         (None, 1554)              0
_________________________________________________________________
batch_normalization_107 (Bat (None, 1554)              6216
_________________________________________________________________
dense_259 (Dense)            (None, 10)                15550
=================================================================
Total params: 1,241,656
Trainable params: 1,238,548
Non-trainable params: 3,108
_________________________________________________________________
None
Model: "model_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_260 (Dense)            (None, 1210)              949850
_________________________________________________________________
activation_194 (Activation)  (None, 1210)              0
_________________________________________________________________
batch_normalization_108 (Bat (None, 1210)              4840
_________________________________________________________________
dense_261 (Dense)            (None, 10)                12110
=================================================================
Total params: 966,800
Trainable params: 964,380
Non-trainable params: 2,420
_________________________________________________________________
None
Model: "model_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_262 (Dense)            (None, 390)               306150
_________________________________________________________________
activation_195 (Activation)  (None, 390)               0
_________________________________________________________________
batch_normalization_109 (Bat (None, 390)               1560
_________________________________________________________________
dense_263 (Dense)            (None, 10)                3910
=================================================================
Total params: 311,620
Trainable params: 310,840
Non-trainable params: 780
_________________________________________________________________
None
Model: "model_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_264 (Dense)            (None, 1210)              949850
_________________________________________________________________
activation_196 (Activation)  (None, 1210)              0
_________________________________________________________________
dropout_100 (Dropout)        (None, 1210)              0
_________________________________________________________________
dense_265 (Dense)            (None, 10)                12110
=================================================================
Total params: 961,960
Trainable params: 961,960
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_266 (Dense)            (None, 1280)              1004800
_________________________________________________________________
activation_197 (Activation)  (None, 1280)              0
_________________________________________________________________
dropout_101 (Dropout)        (None, 1280)              0
_________________________________________________________________
dense_267 (Dense)            (None, 10)                12810
=================================================================
Total params: 1,017,610
Trainable params: 1,017,610
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_268 (Dense)            (None, 1220)              957700
_________________________________________________________________
activation_198 (Activation)  (None, 1220)              0
_________________________________________________________________
dropout_102 (Dropout)        (None, 1220)              0
_________________________________________________________________
batch_normalization_110 (Bat (None, 1220)              4880
_________________________________________________________________
dense_269 (Dense)            (None, 10)                12210
=================================================================
Total params: 974,790
Trainable params: 972,350
Non-trainable params: 2,440
_________________________________________________________________
None
Model: "model_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_270 (Dense)            (None, 170)               133450
_________________________________________________________________
activation_199 (Activation)  (None, 170)               0
_________________________________________________________________
dropout_103 (Dropout)        (None, 170)               0
_________________________________________________________________
batch_normalization_111 (Bat (None, 170)               680
_________________________________________________________________
dense_271 (Dense)            (None, 10)                1710
=================================================================
Total params: 135,840
Trainable params: 135,500
Non-trainable params: 340
_________________________________________________________________
None
Model: "model_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_272 (Dense)            (None, 1990)              1562150
_________________________________________________________________
activation_200 (Activation)  (None, 1990)              0
_________________________________________________________________
dense_273 (Dense)            (None, 10)                19910
=================================================================
Total params: 1,582,060
Trainable params: 1,582,060
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_274 (Dense)            (None, 840)               659400
_________________________________________________________________
activation_201 (Activation)  (None, 840)               0
_________________________________________________________________
dropout_104 (Dropout)        (None, 840)               0
_________________________________________________________________
batch_normalization_112 (Bat (None, 840)               3360
_________________________________________________________________
dense_275 (Dense)            (None, 10)                8410
=================================================================
Total params: 671,170
Trainable params: 669,490
Non-trainable params: 1,680
_________________________________________________________________
None
Model: "model_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_276 (Dense)            (None, 60)                47100
_________________________________________________________________
activation_202 (Activation)  (None, 60)                0
_________________________________________________________________
batch_normalization_113 (Bat (None, 60)                240
_________________________________________________________________
dense_277 (Dense)            (None, 10)                610
=================================================================
Total params: 47,950
Trainable params: 47,830
Non-trainable params: 120
_________________________________________________________________
None
Model: "model_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_278 (Dense)            (None, 1880)              1475800
_________________________________________________________________
activation_203 (Activation)  (None, 1880)              0
_________________________________________________________________
dropout_105 (Dropout)        (None, 1880)              0
_________________________________________________________________
dense_279 (Dense)            (None, 10)                18810
=================================================================
Total params: 1,494,610
Trainable params: 1,494,610
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_280 (Dense)            (None, 1790)              1405150
_________________________________________________________________
activation_204 (Activation)  (None, 1790)              0
_________________________________________________________________
batch_normalization_114 (Bat (None, 1790)              7160
_________________________________________________________________
dense_281 (Dense)            (None, 10)                17910
=================================================================
Total params: 1,430,220
Trainable params: 1,426,640
Non-trainable params: 3,580
_________________________________________________________________
None
Model: "model_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_282 (Dense)            (None, 860)               675100
_________________________________________________________________
activation_205 (Activation)  (None, 860)               0
_________________________________________________________________
dense_283 (Dense)            (None, 10)                8610
=================================================================
Total params: 683,710
Trainable params: 683,710
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_284 (Dense)            (None, 740)               580900
_________________________________________________________________
activation_206 (Activation)  (None, 740)               0
_________________________________________________________________
dense_285 (Dense)            (None, 10)                7410
=================================================================
Total params: 588,310
Trainable params: 588,310
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_286 (Dense)            (None, 340)               266900
_________________________________________________________________
activation_207 (Activation)  (None, 340)               0
_________________________________________________________________
batch_normalization_115 (Bat (None, 340)               1360
_________________________________________________________________
dense_287 (Dense)            (None, 10)                3410
=================================================================
Total params: 271,670
Trainable params: 270,990
Non-trainable params: 680
_________________________________________________________________
None
Model: "model_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_288 (Dense)            (None, 1610)              1263850
_________________________________________________________________
activation_208 (Activation)  (None, 1610)              0
_________________________________________________________________
dense_289 (Dense)            (None, 10)                16110
=================================================================
Total params: 1,279,960
Trainable params: 1,279,960
Non-trainable params: 0
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesEpoch 1/10

Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Epoch 1/10

Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samplesEpoch 1/10
Epoch 1/10

Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
Epoch 1/10
Epoch 1/10
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10
 -> id = 7  Epoch: 0   accuracy: 0.88883334  val_acc: 0.91525
48000/48000 - 47s - loss: 0.3844 - accuracy: 0.8888 - val_loss: 0.3025 - val_accuracy: 0.9153
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.9009375  val_acc: 0.94775
48000/48000 - 48s - loss: 0.3356 - accuracy: 0.9009 - val_loss: 0.1908 - val_accuracy: 0.9477
Epoch 2/10
 -> id = 11  Epoch: 0   accuracy: 0.8895208  val_acc: 0.92825
48000/48000 - 49s - loss: 0.3716 - accuracy: 0.8895 - val_loss: 0.2418 - val_accuracy: 0.9283
Epoch 2/10
 -> id = 19  Epoch: 0   accuracy: 0.900375  val_acc: 0.9360833
48000/48000 - 48s - loss: 0.3361 - accuracy: 0.9004 - val_loss: 0.2266 - val_accuracy: 0.9361
Epoch 2/10
 -> id = 17  Epoch: 0   accuracy: 0.8948542  val_acc: 0.93258333
48000/48000 - 49s - loss: 0.3574 - accuracy: 0.8949 - val_loss: 0.2358 - val_accuracy: 0.9326
Epoch 2/10
 -> id = 14  Epoch: 0   accuracy: 0.8778333  val_acc: 0.9396667
48000/48000 - 55s - loss: 0.4193 - accuracy: 0.8778 - val_loss: 0.2119 - val_accuracy: 0.9397
Epoch 2/10
 -> id = 8  Epoch: 0   accuracy: 0.83710414  val_acc: 0.91675
48000/48000 - 56s - loss: 0.5399 - accuracy: 0.8371 - val_loss: 0.2942 - val_accuracy: 0.9168
Epoch 2/10
 -> id = 2  Epoch: 0   accuracy: 0.88252085  val_acc: 0.9571667
48000/48000 - 57s - loss: 0.3949 - accuracy: 0.8825 - val_loss: 0.1811 - val_accuracy: 0.9572
Epoch 2/10
 -> id = 18  Epoch: 0   accuracy: 0.8970417  val_acc: 0.927
48000/48000 - 57s - loss: 0.3554 - accuracy: 0.8970 - val_loss: 0.2776 - val_accuracy: 0.9270
Epoch 2/10
 -> id = 10  Epoch: 0   accuracy: 0.8751875  val_acc: 0.9450833
48000/48000 - 58s - loss: 0.4077 - accuracy: 0.8752 - val_loss: 0.1981 - val_accuracy: 0.9451
Epoch 2/10
 -> id = 13  Epoch: 0   accuracy: 0.8834583  val_acc: 0.931
48000/48000 - 58s - loss: 0.3995 - accuracy: 0.8835 - val_loss: 0.2719 - val_accuracy: 0.9310
Epoch 2/10
 -> id = 12  Epoch: 0   accuracy: 0.8764167  val_acc: 0.9264167
48000/48000 - 64s - loss: 0.4241 - accuracy: 0.8764 - val_loss: 0.2618 - val_accuracy: 0.9264
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.93354166  val_acc: 0.95841664
48000/48000 - 63s - loss: 0.2210 - accuracy: 0.9335 - val_loss: 0.1678 - val_accuracy: 0.9584
Epoch 2/10
 -> id = 5  Epoch: 0   accuracy: 0.9105625  val_acc: 0.9303333
48000/48000 - 67s - loss: 0.3352 - accuracy: 0.9106 - val_loss: 0.2477 - val_accuracy: 0.9303
Epoch 2/10
 -> id = 4  Epoch: 0   accuracy: 0.9278125  val_acc: 0.96183336
48000/48000 - 68s - loss: 0.2388 - accuracy: 0.9278 - val_loss: 0.1416 - val_accuracy: 0.9618
Epoch 2/10
 -> id = 3  Epoch: 0   accuracy: 0.9305  val_acc: 0.95891666
48000/48000 - 73s - loss: 0.2308 - accuracy: 0.9305 - val_loss: 0.1506 - val_accuracy: 0.9589
Epoch 2/10
 -> id = 15  Epoch: 0   accuracy: 0.90585417  val_acc: 0.92983335
48000/48000 - 73s - loss: 0.3819 - accuracy: 0.9059 - val_loss: 0.2430 - val_accuracy: 0.9298
Epoch 2/10
 -> id = 0  Epoch: 0   accuracy: 0.9235  val_acc: 0.96383333
48000/48000 - 74s - loss: 0.2511 - accuracy: 0.9235 - val_loss: 0.1434 - val_accuracy: 0.9638
Epoch 2/10
 -> id = 1  Epoch: 0   accuracy: 0.92897916  val_acc: 0.96325
48000/48000 - 75s - loss: 0.2381 - accuracy: 0.9290 - val_loss: 0.1379 - val_accuracy: 0.9632
Epoch 2/10
 -> id = 9  Epoch: 0   accuracy: 0.8632708  val_acc: 0.9234167
48000/48000 - 77s - loss: 0.5680 - accuracy: 0.8633 - val_loss: 1.3093 - val_accuracy: 0.9234
Epoch 2/10
 -> id = 7  Epoch: 1   accuracy: 0.91289586  val_acc: 0.9203333
48000/48000 - 36s - loss: 0.3113 - accuracy: 0.9129 - val_loss: 0.2957 - val_accuracy: 0.9203
Epoch 3/10
 -> id = 16  Epoch: 1   accuracy: 0.95358336  val_acc: 0.961
48000/48000 - 36s - loss: 0.1615 - accuracy: 0.9536 - val_loss: 0.1357 - val_accuracy: 0.9610
Epoch 3/10
 -> id = 17  Epoch: 1   accuracy: 0.9390625  val_acc: 0.95133334
48000/48000 - 36s - loss: 0.2109 - accuracy: 0.9391 - val_loss: 0.1738 - val_accuracy: 0.9513
Epoch 3/10
 -> id = 11  Epoch: 1   accuracy: 0.9459375  val_acc: 0.9533333
48000/48000 - 39s - loss: 0.1860 - accuracy: 0.9459 - val_loss: 0.1637 - val_accuracy: 0.9533
Epoch 3/10
 -> id = 19  Epoch: 1   accuracy: 0.9424792  val_acc: 0.9518333
48000/48000 - 39s - loss: 0.1976 - accuracy: 0.9425 - val_loss: 0.1693 - val_accuracy: 0.9518
Epoch 3/10
 -> id = 2  Epoch: 1   accuracy: 0.94404167  val_acc: 0.96508336
48000/48000 - 34s - loss: 0.1933 - accuracy: 0.9440 - val_loss: 0.1233 - val_accuracy: 0.9651
Epoch 3/10
 -> id = 13  Epoch: 1   accuracy: 0.93570834  val_acc: 0.94708335
48000/48000 - 32s - loss: 0.2233 - accuracy: 0.9357 - val_loss: 0.1940 - val_accuracy: 0.9471
Epoch 3/10
 -> id = 10  Epoch: 1   accuracy: 0.93925  val_acc: 0.959
48000/48000 - 34s - loss: 0.2063 - accuracy: 0.9392 - val_loss: 0.1520 - val_accuracy: 0.9590
Epoch 3/10
 -> id = 18  Epoch: 1   accuracy: 0.937875  val_acc: 0.94633335
48000/48000 - 38s - loss: 0.2144 - accuracy: 0.9379 - val_loss: 0.1877 - val_accuracy: 0.9463
Epoch 3/10
 -> id = 14  Epoch: 1   accuracy: 0.9374375  val_acc: 0.95558333
48000/48000 - 45s - loss: 0.2083 - accuracy: 0.9374 - val_loss: 0.1508 - val_accuracy: 0.9556
Epoch 3/10
 -> id = 12  Epoch: 1   accuracy: 0.913125  val_acc: 0.93908334
48000/48000 - 37s - loss: 0.2920 - accuracy: 0.9131 - val_loss: 0.2118 - val_accuracy: 0.9391
Epoch 3/10
 -> id = 6  Epoch: 1   accuracy: 0.9758958  val_acc: 0.96741664
48000/48000 - 37s - loss: 0.0857 - accuracy: 0.9759 - val_loss: 0.1056 - val_accuracy: 0.9674
Epoch 3/10
 -> id = 8  Epoch: 1   accuracy: 0.9115  val_acc: 0.92875
48000/48000 - 46s - loss: 0.3034 - accuracy: 0.9115 - val_loss: 0.2501 - val_accuracy: 0.9287
Epoch 3/10
 -> id = 4  Epoch: 1   accuracy: 0.9666042  val_acc: 0.972
48000/48000 - 43s - loss: 0.1083 - accuracy: 0.9666 - val_loss: 0.0934 - val_accuracy: 0.9720
Epoch 3/10
 -> id = 5  Epoch: 1   accuracy: 0.95383334  val_acc: 0.95533335
48000/48000 - 46s - loss: 0.1551 - accuracy: 0.9538 - val_loss: 0.1477 - val_accuracy: 0.9553
Epoch 3/10
 -> id = 17  Epoch: 2   accuracy: 0.9569375  val_acc: 0.96166664
48000/48000 - 35s - loss: 0.1497 - accuracy: 0.9569 - val_loss: 0.1349 - val_accuracy: 0.9617
Epoch 4/10
 -> id = 0  Epoch: 1   accuracy: 0.9649792  val_acc: 0.972
48000/48000 - 46s - loss: 0.1114 - accuracy: 0.9650 - val_loss: 0.0930 - val_accuracy: 0.9720
Epoch 3/10
 -> id = 7  Epoch: 2   accuracy: 0.915625  val_acc: 0.9216667
48000/48000 - 38s - loss: 0.3013 - accuracy: 0.9156 - val_loss: 0.2883 - val_accuracy: 0.9217
Epoch 4/10
 -> id = 3  Epoch: 1   accuracy: 0.96816665  val_acc: 0.9723333
48000/48000 - 47s - loss: 0.1061 - accuracy: 0.9682 - val_loss: 0.0964 - val_accuracy: 0.9723
Epoch 3/10
 -> id = 16  Epoch: 2   accuracy: 0.96875  val_acc: 0.9615
48000/48000 - 37s - loss: 0.1054 - accuracy: 0.9688 - val_loss: 0.1364 - val_accuracy: 0.9615
Epoch 4/10
 -> id = 15  Epoch: 1   accuracy: 0.95283335  val_acc: 0.95066667
48000/48000 - 49s - loss: 0.1577 - accuracy: 0.9528 - val_loss: 0.1674 - val_accuracy: 0.9507
Epoch 3/10
 -> id = 13  Epoch: 2   accuracy: 0.95091665  val_acc: 0.955
48000/48000 - 33s - loss: 0.1725 - accuracy: 0.9509 - val_loss: 0.1651 - val_accuracy: 0.9550
Epoch 4/10
 -> id = 2  Epoch: 2   accuracy: 0.9555  val_acc: 0.97083336
48000/48000 - 34s - loss: 0.1519 - accuracy: 0.9555 - val_loss: 0.1031 - val_accuracy: 0.9708
Epoch 4/10
 -> id = 10  Epoch: 2   accuracy: 0.95372915  val_acc: 0.9655
48000/48000 - 34s - loss: 0.1525 - accuracy: 0.9537 - val_loss: 0.1207 - val_accuracy: 0.9655
Epoch 4/10
 -> id = 1  Epoch: 1   accuracy: 0.96795833  val_acc: 0.9723333
48000/48000 - 50s - loss: 0.1077 - accuracy: 0.9680 - val_loss: 0.0921 - val_accuracy: 0.9723
Epoch 3/10
 -> id = 19  Epoch: 2   accuracy: 0.9579167  val_acc: 0.96091664
48000/48000 - 39s - loss: 0.1417 - accuracy: 0.9579 - val_loss: 0.1352 - val_accuracy: 0.9609
Epoch 4/10
 -> id = 11  Epoch: 2   accuracy: 0.9635417  val_acc: 0.95891666
48000/48000 - 40s - loss: 0.1218 - accuracy: 0.9635 - val_loss: 0.1420 - val_accuracy: 0.9589
Epoch 4/10
 -> id = 9  Epoch: 1   accuracy: 0.95295835  val_acc: 0.96491665
48000/48000 - 52s - loss: 0.1640 - accuracy: 0.9530 - val_loss: 0.1608 - val_accuracy: 0.9649
Epoch 3/10
 -> id = 18  Epoch: 2   accuracy: 0.95666665  val_acc: 0.9634167
48000/48000 - 36s - loss: 0.1497 - accuracy: 0.9567 - val_loss: 0.1340 - val_accuracy: 0.9634
Epoch 4/10
 -> id = 12  Epoch: 2   accuracy: 0.92975  val_acc: 0.95325
48000/48000 - 36s - loss: 0.2355 - accuracy: 0.9298 - val_loss: 0.1723 - val_accuracy: 0.9532
Epoch 4/10
 -> id = 6  Epoch: 2   accuracy: 0.985  val_acc: 0.97175
48000/48000 - 37s - loss: 0.0527 - accuracy: 0.9850 - val_loss: 0.0939 - val_accuracy: 0.9718
Epoch 4/10
 -> id = 14  Epoch: 2   accuracy: 0.9575625  val_acc: 0.96175
48000/48000 - 46s - loss: 0.1397 - accuracy: 0.9576 - val_loss: 0.1304 - val_accuracy: 0.9617
Epoch 4/10
 -> id = 8  Epoch: 2   accuracy: 0.92679167  val_acc: 0.94175
48000/48000 - 45s - loss: 0.2488 - accuracy: 0.9268 - val_loss: 0.2111 - val_accuracy: 0.9417
Epoch 4/10
 -> id = 4  Epoch: 2   accuracy: 0.97454166  val_acc: 0.977
48000/48000 - 43s - loss: 0.0813 - accuracy: 0.9745 - val_loss: 0.0791 - val_accuracy: 0.9770
Epoch 4/10
 -> id = 17  Epoch: 3   accuracy: 0.9673333  val_acc: 0.96508336
48000/48000 - 38s - loss: 0.1124 - accuracy: 0.9673 - val_loss: 0.1209 - val_accuracy: 0.9651
Epoch 5/10
 -> id = 7  Epoch: 3   accuracy: 0.91658336  val_acc: 0.9213333
48000/48000 - 38s - loss: 0.2965 - accuracy: 0.9166 - val_loss: 0.2892 - val_accuracy: 0.9213
Epoch 5/10
 -> id = 5  Epoch: 2   accuracy: 0.9680833  val_acc: 0.95966667
48000/48000 - 46s - loss: 0.1043 - accuracy: 0.9681 - val_loss: 0.1307 - val_accuracy: 0.9597
Epoch 4/10
 -> id = 13  Epoch: 3   accuracy: 0.959625  val_acc: 0.95675
48000/48000 - 35s - loss: 0.1403 - accuracy: 0.9596 - val_loss: 0.1539 - val_accuracy: 0.9567
Epoch 5/10
 -> id = 16  Epoch: 3   accuracy: 0.97652084  val_acc: 0.96966666
48000/48000 - 40s - loss: 0.0766 - accuracy: 0.9765 - val_loss: 0.1130 - val_accuracy: 0.9697
Epoch 5/10
 -> id = 10  Epoch: 3   accuracy: 0.96379167  val_acc: 0.97
48000/48000 - 37s - loss: 0.1204 - accuracy: 0.9638 - val_loss: 0.1083 - val_accuracy: 0.9700
Epoch 5/10
 -> id = 2  Epoch: 3   accuracy: 0.96110415  val_acc: 0.9713333
48000/48000 - 37s - loss: 0.1306 - accuracy: 0.9611 - val_loss: 0.0969 - val_accuracy: 0.9713
Epoch 5/10
 -> id = 19  Epoch: 3   accuracy: 0.96958333  val_acc: 0.9655
48000/48000 - 39s - loss: 0.1034 - accuracy: 0.9696 - val_loss: 0.1209 - val_accuracy: 0.9655
Epoch 5/10
 -> id = 0  Epoch: 2   accuracy: 0.9741667  val_acc: 0.97525
48000/48000 - 46s - loss: 0.0843 - accuracy: 0.9742 - val_loss: 0.0821 - val_accuracy: 0.9753
Epoch 4/10
 -> id = 11  Epoch: 3   accuracy: 0.9720625  val_acc: 0.96791667
48000/48000 - 40s - loss: 0.0900 - accuracy: 0.9721 - val_loss: 0.1176 - val_accuracy: 0.9679
Epoch 5/10
 -> id = 3  Epoch: 2   accuracy: 0.9772083  val_acc: 0.97375
48000/48000 - 47s - loss: 0.0761 - accuracy: 0.9772 - val_loss: 0.0879 - val_accuracy: 0.9737
Epoch 4/10
 -> id = 18  Epoch: 3   accuracy: 0.9676458  val_acc: 0.96758336
48000/48000 - 38s - loss: 0.1118 - accuracy: 0.9676 - val_loss: 0.1146 - val_accuracy: 0.9676
Epoch 5/10
 -> id = 15  Epoch: 2   accuracy: 0.96525  val_acc: 0.9583333
48000/48000 - 49s - loss: 0.1116 - accuracy: 0.9653 - val_loss: 0.1405 - val_accuracy: 0.9583
Epoch 4/10
 -> id = 12  Epoch: 3   accuracy: 0.9413125  val_acc: 0.95525
48000/48000 - 37s - loss: 0.1969 - accuracy: 0.9413 - val_loss: 0.1568 - val_accuracy: 0.9553
Epoch 5/10
 -> id = 6  Epoch: 3   accuracy: 0.9903125  val_acc: 0.97316664
48000/48000 - 36s - loss: 0.0350 - accuracy: 0.9903 - val_loss: 0.0883 - val_accuracy: 0.9732
Epoch 5/10
 -> id = 1  Epoch: 2   accuracy: 0.9748542  val_acc: 0.97508335
48000/48000 - 51s - loss: 0.0805 - accuracy: 0.9749 - val_loss: 0.0839 - val_accuracy: 0.9751
Epoch 4/10
 -> id = 9  Epoch: 2   accuracy: 0.9649583  val_acc: 0.96858335
48000/48000 - 50s - loss: 0.1197 - accuracy: 0.9650 - val_loss: 0.1054 - val_accuracy: 0.9686
Epoch 4/10
 -> id = 8  Epoch: 3   accuracy: 0.9394792  val_acc: 0.951
48000/48000 - 44s - loss: 0.2044 - accuracy: 0.9395 - val_loss: 0.1770 - val_accuracy: 0.9510
Epoch 5/10
 -> id = 14  Epoch: 3   accuracy: 0.96827084  val_acc: 0.96966666
48000/48000 - 45s - loss: 0.1043 - accuracy: 0.9683 - val_loss: 0.1064 - val_accuracy: 0.9697
Epoch 5/10
 -> id = 13  Epoch: 4   accuracy: 0.9656875  val_acc: 0.9615833
48000/48000 - 33s - loss: 0.1180 - accuracy: 0.9657 - val_loss: 0.1344 - val_accuracy: 0.9616
Epoch 6/10
 -> id = 17  Epoch: 4   accuracy: 0.97541666  val_acc: 0.96925
48000/48000 - 35s - loss: 0.0860 - accuracy: 0.9754 - val_loss: 0.1040 - val_accuracy: 0.9693
Epoch 6/10
 -> id = 4  Epoch: 3   accuracy: 0.9796042  val_acc: 0.97683334
48000/48000 - 41s - loss: 0.0657 - accuracy: 0.9796 - val_loss: 0.0768 - val_accuracy: 0.9768
Epoch 5/10
 -> id = 2  Epoch: 4   accuracy: 0.96460414  val_acc: 0.97241664
48000/48000 - 35s - loss: 0.1177 - accuracy: 0.9646 - val_loss: 0.0916 - val_accuracy: 0.9724
Epoch 6/10
 -> id = 7  Epoch: 4   accuracy: 0.92020833  val_acc: 0.9199167
48000/48000 - 39s - loss: 0.2868 - accuracy: 0.9202 - val_loss: 0.2940 - val_accuracy: 0.9199
Epoch 6/10
 -> id = 10  Epoch: 4   accuracy: 0.96933335  val_acc: 0.9725
48000/48000 - 36s - loss: 0.1008 - accuracy: 0.9693 - val_loss: 0.0980 - val_accuracy: 0.9725
Epoch 6/10
 -> id = 16  Epoch: 4   accuracy: 0.9811875  val_acc: 0.96775
48000/48000 - 40s - loss: 0.0609 - accuracy: 0.9812 - val_loss: 0.1216 - val_accuracy: 0.9678
Epoch 6/10
 -> id = 5  Epoch: 3   accuracy: 0.9752708  val_acc: 0.968
48000/48000 - 45s - loss: 0.0792 - accuracy: 0.9753 - val_loss: 0.1129 - val_accuracy: 0.9680
Epoch 5/10
 -> id = 19  Epoch: 4   accuracy: 0.97479165  val_acc: 0.9663333
48000/48000 - 39s - loss: 0.0831 - accuracy: 0.9748 - val_loss: 0.1101 - val_accuracy: 0.9663
Epoch 6/10
 -> id = 18  Epoch: 4   accuracy: 0.9740833  val_acc: 0.9665
48000/48000 - 38s - loss: 0.0862 - accuracy: 0.9741 - val_loss: 0.1102 - val_accuracy: 0.9665
Epoch 6/10
 -> id = 11  Epoch: 4   accuracy: 0.97866666  val_acc: 0.9665833
48000/48000 - 41s - loss: 0.0676 - accuracy: 0.9787 - val_loss: 0.1196 - val_accuracy: 0.9666
Epoch 6/10
 -> id = 12  Epoch: 4   accuracy: 0.94754165  val_acc: 0.9611667
48000/48000 - 38s - loss: 0.1739 - accuracy: 0.9475 - val_loss: 0.1418 - val_accuracy: 0.9612
Epoch 6/10
 -> id = 6  Epoch: 4   accuracy: 0.99395835  val_acc: 0.9730833
48000/48000 - 38s - loss: 0.0232 - accuracy: 0.9940 - val_loss: 0.0921 - val_accuracy: 0.9731
Epoch 6/10
 -> id = 0  Epoch: 3   accuracy: 0.97952086  val_acc: 0.976
48000/48000 - 47s - loss: 0.0656 - accuracy: 0.9795 - val_loss: 0.0820 - val_accuracy: 0.9760
Epoch 5/10
 -> id = 3  Epoch: 3   accuracy: 0.98029166  val_acc: 0.97316664
48000/48000 - 46s - loss: 0.0616 - accuracy: 0.9803 - val_loss: 0.0902 - val_accuracy: 0.9732
Epoch 5/10
 -> id = 15  Epoch: 3   accuracy: 0.973  val_acc: 0.96508336
48000/48000 - 50s - loss: 0.0871 - accuracy: 0.9730 - val_loss: 0.1226 - val_accuracy: 0.9651
Epoch 5/10
 -> id = 13  Epoch: 5   accuracy: 0.9710208  val_acc: 0.9644167
48000/48000 - 34s - loss: 0.1014 - accuracy: 0.9710 - val_loss: 0.1244 - val_accuracy: 0.9644
Epoch 7/10
 -> id = 9  Epoch: 3   accuracy: 0.973  val_acc: 0.97125
48000/48000 - 51s - loss: 0.0951 - accuracy: 0.9730 - val_loss: 0.0981 - val_accuracy: 0.9712
Epoch 5/10
 -> id = 1  Epoch: 3   accuracy: 0.97864586  val_acc: 0.9776667
48000/48000 - 54s - loss: 0.0683 - accuracy: 0.9786 - val_loss: 0.0782 - val_accuracy: 0.9777
Epoch 5/10
 -> id = 17  Epoch: 5   accuracy: 0.9799375  val_acc: 0.9683333
48000/48000 - 37s - loss: 0.0682 - accuracy: 0.9799 - val_loss: 0.1024 - val_accuracy: 0.9683
Epoch 7/10
 -> id = 2  Epoch: 5   accuracy: 0.9681875  val_acc: 0.9741667
48000/48000 - 35s - loss: 0.1051 - accuracy: 0.9682 - val_loss: 0.0880 - val_accuracy: 0.9742
Epoch 7/10
 -> id = 8  Epoch: 4   accuracy: 0.950875  val_acc: 0.9585
48000/48000 - 43s - loss: 0.1695 - accuracy: 0.9509 - val_loss: 0.1490 - val_accuracy: 0.9585
Epoch 6/10
 -> id = 14  Epoch: 4   accuracy: 0.973125  val_acc: 0.9685
48000/48000 - 43s - loss: 0.0876 - accuracy: 0.9731 - val_loss: 0.1070 - val_accuracy: 0.9685
Epoch 6/10
 -> id = 10  Epoch: 5   accuracy: 0.97477084  val_acc: 0.974
48000/48000 - 37s - loss: 0.0849 - accuracy: 0.9748 - val_loss: 0.0927 - val_accuracy: 0.9740
Epoch 7/10
 -> id = 7  Epoch: 5   accuracy: 0.91997916  val_acc: 0.91791666
48000/48000 - 37s - loss: 0.2867 - accuracy: 0.9200 - val_loss: 0.3104 - val_accuracy: 0.9179
Epoch 7/10
 -> id = 16  Epoch: 5   accuracy: 0.98564583  val_acc: 0.97291666
48000/48000 - 36s - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.1178 - val_accuracy: 0.9729
Epoch 7/10
 -> id = 4  Epoch: 4   accuracy: 0.9814583  val_acc: 0.97816664
48000/48000 - 42s - loss: 0.0590 - accuracy: 0.9815 - val_loss: 0.0717 - val_accuracy: 0.9782
Epoch 6/10
 -> id = 18  Epoch: 5   accuracy: 0.9789792  val_acc: 0.97041667
48000/48000 - 38s - loss: 0.0693 - accuracy: 0.9790 - val_loss: 0.0973 - val_accuracy: 0.9704
Epoch 7/10
 -> id = 19  Epoch: 5   accuracy: 0.980875  val_acc: 0.97066665
48000/48000 - 40s - loss: 0.0645 - accuracy: 0.9809 - val_loss: 0.0976 - val_accuracy: 0.9707
Epoch 7/10
 -> id = 12  Epoch: 5   accuracy: 0.9538125  val_acc: 0.96141666
48000/48000 - 37s - loss: 0.1516 - accuracy: 0.9538 - val_loss: 0.1288 - val_accuracy: 0.9614
Epoch 7/10
 -> id = 5  Epoch: 4   accuracy: 0.98085415  val_acc: 0.9690833
48000/48000 - 44s - loss: 0.0607 - accuracy: 0.9809 - val_loss: 0.1020 - val_accuracy: 0.9691
Epoch 6/10
 -> id = 6  Epoch: 5   accuracy: 0.99558336  val_acc: 0.9741667
48000/48000 - 38s - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.0957 - val_accuracy: 0.9742
Epoch 7/10
 -> id = 11  Epoch: 5   accuracy: 0.9850208  val_acc: 0.97033334
48000/48000 - 42s - loss: 0.0498 - accuracy: 0.9850 - val_loss: 0.1221 - val_accuracy: 0.9703
Epoch 7/10
 -> id = 13  Epoch: 6   accuracy: 0.97585416  val_acc: 0.96491665
48000/48000 - 34s - loss: 0.0866 - accuracy: 0.9759 - val_loss: 0.1207 - val_accuracy: 0.9649
Epoch 8/10
 -> id = 0  Epoch: 4   accuracy: 0.98322916  val_acc: 0.97575
48000/48000 - 49s - loss: 0.0556 - accuracy: 0.9832 - val_loss: 0.0783 - val_accuracy: 0.9758
Epoch 6/10
 -> id = 3  Epoch: 4   accuracy: 0.98320836  val_acc: 0.9755833
48000/48000 - 49s - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.0843 - val_accuracy: 0.9756
Epoch 6/10
 -> id = 17  Epoch: 6   accuracy: 0.98354167  val_acc: 0.9726667
48000/48000 - 37s - loss: 0.0563 - accuracy: 0.9835 - val_loss: 0.0896 - val_accuracy: 0.9727
Epoch 8/10
 -> id = 2  Epoch: 6   accuracy: 0.9700625  val_acc: 0.9755833
48000/48000 - 36s - loss: 0.0941 - accuracy: 0.9701 - val_loss: 0.0836 - val_accuracy: 0.9756
Epoch 8/10
 -> id = 15  Epoch: 4   accuracy: 0.9774167  val_acc: 0.96533334
48000/48000 - 49s - loss: 0.0693 - accuracy: 0.9774 - val_loss: 0.1256 - val_accuracy: 0.9653
Epoch 6/10
 -> id = 10  Epoch: 6   accuracy: 0.9775208  val_acc: 0.97391665
48000/48000 - 36s - loss: 0.0741 - accuracy: 0.9775 - val_loss: 0.0883 - val_accuracy: 0.9739
Epoch 8/10
 -> id = 16  Epoch: 6   accuracy: 0.98802084  val_acc: 0.9698333
48000/48000 - 39s - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.1309 - val_accuracy: 0.9698
Epoch 8/10
 -> id = 7  Epoch: 6   accuracy: 0.9205625  val_acc: 0.92433333
48000/48000 - 40s - loss: 0.2839 - accuracy: 0.9206 - val_loss: 0.2796 - val_accuracy: 0.9243
Epoch 8/10
 -> id = 8  Epoch: 5   accuracy: 0.95883334  val_acc: 0.9608333
48000/48000 - 44s - loss: 0.1427 - accuracy: 0.9588 - val_loss: 0.1364 - val_accuracy: 0.9608
Epoch 7/10
 -> id = 14  Epoch: 5   accuracy: 0.97902083  val_acc: 0.97066665
48000/48000 - 44s - loss: 0.0670 - accuracy: 0.9790 - val_loss: 0.1053 - val_accuracy: 0.9707
Epoch 7/10
 -> id = 4  Epoch: 5   accuracy: 0.98314583  val_acc: 0.9773333
48000/48000 - 42s - loss: 0.0536 - accuracy: 0.9831 - val_loss: 0.0748 - val_accuracy: 0.9773
Epoch 7/10
 -> id = 9  Epoch: 4   accuracy: 0.97658336  val_acc: 0.97391665
48000/48000 - 51s - loss: 0.0783 - accuracy: 0.9766 - val_loss: 0.0926 - val_accuracy: 0.9739
Epoch 6/10
 -> id = 1  Epoch: 4   accuracy: 0.9817917  val_acc: 0.9744167
48000/48000 - 52s - loss: 0.0568 - accuracy: 0.9818 - val_loss: 0.0889 - val_accuracy: 0.9744
Epoch 6/10
 -> id = 18  Epoch: 6   accuracy: 0.9836042  val_acc: 0.97225
48000/48000 - 38s - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.0947 - val_accuracy: 0.9722
Epoch 8/10
 -> id = 19  Epoch: 6   accuracy: 0.98464584  val_acc: 0.97241664
48000/48000 - 38s - loss: 0.0512 - accuracy: 0.9846 - val_loss: 0.0918 - val_accuracy: 0.9724
Epoch 8/10
 -> id = 12  Epoch: 6   accuracy: 0.957875  val_acc: 0.9673333
48000/48000 - 37s - loss: 0.1371 - accuracy: 0.9579 - val_loss: 0.1156 - val_accuracy: 0.9673
Epoch 8/10
 -> id = 6  Epoch: 6   accuracy: 0.99714583  val_acc: 0.9759167
48000/48000 - 40s - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.0881 - val_accuracy: 0.9759
Epoch 8/10
 -> id = 13  Epoch: 7   accuracy: 0.97835416  val_acc: 0.96675
48000/48000 - 32s - loss: 0.0756 - accuracy: 0.9784 - val_loss: 0.1163 - val_accuracy: 0.9668
Epoch 9/10
 -> id = 11  Epoch: 6   accuracy: 0.98497915  val_acc: 0.97083336
48000/48000 - 42s - loss: 0.0506 - accuracy: 0.9850 - val_loss: 0.1263 - val_accuracy: 0.9708
Epoch 8/10
 -> id = 5  Epoch: 5   accuracy: 0.98477083  val_acc: 0.96875
48000/48000 - 46s - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.1049 - val_accuracy: 0.9688
Epoch 7/10
 -> id = 2  Epoch: 7   accuracy: 0.9725417  val_acc: 0.97575
48000/48000 - 36s - loss: 0.0870 - accuracy: 0.9725 - val_loss: 0.0830 - val_accuracy: 0.9758
Epoch 9/10
 -> id = 17  Epoch: 7   accuracy: 0.98833334  val_acc: 0.97258335
48000/48000 - 37s - loss: 0.0422 - accuracy: 0.9883 - val_loss: 0.0887 - val_accuracy: 0.9726
Epoch 9/10
 -> id = 10  Epoch: 7   accuracy: 0.980625  val_acc: 0.9763333
48000/48000 - 36s - loss: 0.0627 - accuracy: 0.9806 - val_loss: 0.0844 - val_accuracy: 0.9763
Epoch 9/10
 -> id = 3  Epoch: 5   accuracy: 0.98375  val_acc: 0.9784167
48000/48000 - 46s - loss: 0.0491 - accuracy: 0.9837 - val_loss: 0.0768 - val_accuracy: 0.9784
Epoch 7/10
 -> id = 0  Epoch: 5   accuracy: 0.98389584  val_acc: 0.97908336
48000/48000 - 48s - loss: 0.0494 - accuracy: 0.9839 - val_loss: 0.0725 - val_accuracy: 0.9791
Epoch 7/10
 -> id = 16  Epoch: 7   accuracy: 0.98875  val_acc: 0.9740833
48000/48000 - 38s - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.1210 - val_accuracy: 0.9741
Epoch 9/10
 -> id = 7  Epoch: 7   accuracy: 0.92072916  val_acc: 0.92116666
48000/48000 - 39s - loss: 0.2807 - accuracy: 0.9207 - val_loss: 0.2905 - val_accuracy: 0.9212
Epoch 9/10
 -> id = 15  Epoch: 5   accuracy: 0.98160416  val_acc: 0.96975
48000/48000 - 48s - loss: 0.0547 - accuracy: 0.9816 - val_loss: 0.1040 - val_accuracy: 0.9697
Epoch 7/10
 -> id = 4  Epoch: 6   accuracy: 0.98485416  val_acc: 0.97625
48000/48000 - 41s - loss: 0.0467 - accuracy: 0.9849 - val_loss: 0.0775 - val_accuracy: 0.9762
Epoch 8/10
 -> id = 18  Epoch: 7   accuracy: 0.9875  val_acc: 0.97391665
48000/48000 - 38s - loss: 0.0438 - accuracy: 0.9875 - val_loss: 0.0909 - val_accuracy: 0.9739
Epoch 9/10
 -> id = 19  Epoch: 7   accuracy: 0.98775  val_acc: 0.96775
48000/48000 - 38s - loss: 0.0406 - accuracy: 0.9877 - val_loss: 0.1011 - val_accuracy: 0.9678
Epoch 9/10
 -> id = 12  Epoch: 7   accuracy: 0.96152085  val_acc: 0.96816665
48000/48000 - 38s - loss: 0.1241 - accuracy: 0.9615 - val_loss: 0.1133 - val_accuracy: 0.9682
Epoch 9/10
 -> id = 8  Epoch: 6   accuracy: 0.964875  val_acc: 0.9659167
48000/48000 - 44s - loss: 0.1207 - accuracy: 0.9649 - val_loss: 0.1201 - val_accuracy: 0.9659
Epoch 8/10
 -> id = 14  Epoch: 6   accuracy: 0.98170835  val_acc: 0.97291666
48000/48000 - 46s - loss: 0.0564 - accuracy: 0.9817 - val_loss: 0.1117 - val_accuracy: 0.9729
Epoch 8/10
 -> id = 13  Epoch: 8   accuracy: 0.98097914  val_acc: 0.9690833
48000/48000 - 34s - loss: 0.0663 - accuracy: 0.9810 - val_loss: 0.1072 - val_accuracy: 0.9691
Epoch 10/10
 -> id = 6  Epoch: 7   accuracy: 0.99691665  val_acc: 0.97333336
48000/48000 - 39s - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.1019 - val_accuracy: 0.9733
Epoch 9/10
 -> id = 11  Epoch: 7   accuracy: 0.98852086  val_acc: 0.96975
48000/48000 - 38s - loss: 0.0370 - accuracy: 0.9885 - val_loss: 0.1322 - val_accuracy: 0.9697
Epoch 9/10
 -> id = 9  Epoch: 5   accuracy: 0.9800417  val_acc: 0.9735
48000/48000 - 53s - loss: 0.0680 - accuracy: 0.9800 - val_loss: 0.0916 - val_accuracy: 0.9735
Epoch 7/10
 -> id = 1  Epoch: 5   accuracy: 0.98258334  val_acc: 0.977
48000/48000 - 52s - loss: 0.0540 - accuracy: 0.9826 - val_loss: 0.0791 - val_accuracy: 0.9770
Epoch 7/10
 -> id = 2  Epoch: 8   accuracy: 0.9744167  val_acc: 0.97608334
48000/48000 - 33s - loss: 0.0802 - accuracy: 0.9744 - val_loss: 0.0816 - val_accuracy: 0.9761
Epoch 10/10
 -> id = 5  Epoch: 6   accuracy: 0.987  val_acc: 0.97358334
48000/48000 - 47s - loss: 0.0397 - accuracy: 0.9870 - val_loss: 0.0983 - val_accuracy: 0.9736
Epoch 8/10
 -> id = 17  Epoch: 8   accuracy: 0.9906875  val_acc: 0.9755
48000/48000 - 38s - loss: 0.0340 - accuracy: 0.9907 - val_loss: 0.0835 - val_accuracy: 0.9755
Epoch 10/10
 -> id = 10  Epoch: 8   accuracy: 0.9824375  val_acc: 0.9751667
48000/48000 - 35s - loss: 0.0562 - accuracy: 0.9824 - val_loss: 0.0869 - val_accuracy: 0.9752
Epoch 10/10
 -> id = 16  Epoch: 8   accuracy: 0.9914375  val_acc: 0.9713333
48000/48000 - 38s - loss: 0.0282 - accuracy: 0.9914 - val_loss: 0.1316 - val_accuracy: 0.9713
Epoch 10/10
 -> id = 7  Epoch: 8   accuracy: 0.921625  val_acc: 0.91858333
48000/48000 - 38s - loss: 0.2778 - accuracy: 0.9216 - val_loss: 0.2954 - val_accuracy: 0.9186
Epoch 10/10
 -> id = 0  Epoch: 6   accuracy: 0.98525  val_acc: 0.979
48000/48000 - 46s - loss: 0.0454 - accuracy: 0.9852 - val_loss: 0.0726 - val_accuracy: 0.9790
Epoch 8/10
 -> id = 3  Epoch: 6   accuracy: 0.98529166  val_acc: 0.97758335
48000/48000 - 48s - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.0785 - val_accuracy: 0.9776
Epoch 8/10
 -> id = 18  Epoch: 8   accuracy: 0.989125  val_acc: 0.97375
48000/48000 - 37s - loss: 0.0368 - accuracy: 0.9891 - val_loss: 0.0918 - val_accuracy: 0.9737
Epoch 10/10
 -> id = 12  Epoch: 8   accuracy: 0.96552086  val_acc: 0.969
48000/48000 - 37s - loss: 0.1119 - accuracy: 0.9655 - val_loss: 0.1023 - val_accuracy: 0.9690
Epoch 10/10
 -> id = 19  Epoch: 8   accuracy: 0.99010414  val_acc: 0.96925
48000/48000 - 39s - loss: 0.0329 - accuracy: 0.9901 - val_loss: 0.1032 - val_accuracy: 0.9693
Epoch 10/10
 -> id = 13  Epoch: 9   accuracy: 0.98358333  val_acc: 0.96858335
48000/48000 - 34s - loss: 0.0584 - accuracy: 0.9836 - val_loss: 0.1038 - val_accuracy: 0.9686
 -> id = 4  Epoch: 7   accuracy: 0.98616666  val_acc: 0.97908336
48000/48000 - 41s - loss: 0.0431 - accuracy: 0.9862 - val_loss: 0.0747 - val_accuracy: 0.9791
Epoch 9/10
 -> id = 6  Epoch: 8   accuracy: 0.99725  val_acc: 0.97491664
48000/48000 - 37s - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.0974 - val_accuracy: 0.9749
Epoch 10/10
 -> id = 15  Epoch: 6   accuracy: 0.986  val_acc: 0.9715
48000/48000 - 49s - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.1032 - val_accuracy: 0.9715
Epoch 8/10
 -> id = 8  Epoch: 7   accuracy: 0.969125  val_acc: 0.96683335
48000/48000 - 45s - loss: 0.1056 - accuracy: 0.9691 - val_loss: 0.1114 - val_accuracy: 0.9668
Epoch 9/10
 -> id = 14  Epoch: 7   accuracy: 0.9841458  val_acc: 0.9730833
48000/48000 - 45s - loss: 0.0502 - accuracy: 0.9841 - val_loss: 0.1097 - val_accuracy: 0.9731
Epoch 9/10
 -> id = 11  Epoch: 8   accuracy: 0.990125  val_acc: 0.97208333
48000/48000 - 41s - loss: 0.0306 - accuracy: 0.9901 - val_loss: 0.1243 - val_accuracy: 0.9721
Epoch 10/10
 -> id = 2  Epoch: 9   accuracy: 0.97641665  val_acc: 0.97716665
48000/48000 - 35s - loss: 0.0736 - accuracy: 0.9764 - val_loss: 0.0804 - val_accuracy: 0.9772
 -> id = 10  Epoch: 9   accuracy: 0.9848125  val_acc: 0.9773333
48000/48000 - 35s - loss: 0.0503 - accuracy: 0.9848 - val_loss: 0.0825 - val_accuracy: 0.9773
 -> id = 17  Epoch: 9   accuracy: 0.99310416  val_acc: 0.9751667
48000/48000 - 36s - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0803 - val_accuracy: 0.9752
 -> id = 5  Epoch: 7   accuracy: 0.9897708  val_acc: 0.97258335
48000/48000 - 43s - loss: 0.0320 - accuracy: 0.9898 - val_loss: 0.1014 - val_accuracy: 0.9726
Epoch 9/10
 -> id = 1  Epoch: 6   accuracy: 0.98354167  val_acc: 0.9785
48000/48000 - 50s - loss: 0.0493 - accuracy: 0.9835 - val_loss: 0.0737 - val_accuracy: 0.9785
Epoch 8/10
 -> id = 9  Epoch: 6   accuracy: 0.9832708  val_acc: 0.9740833
48000/48000 - 51s - loss: 0.0576 - accuracy: 0.9833 - val_loss: 0.0876 - val_accuracy: 0.9741
Epoch 8/10
 -> id = 16  Epoch: 9   accuracy: 0.99114585  val_acc: 0.9716667
48000/48000 - 34s - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.1554 - val_accuracy: 0.9717
 -> id = 7  Epoch: 9   accuracy: 0.92275  val_acc: 0.92325
48000/48000 - 35s - loss: 0.2784 - accuracy: 0.9227 - val_loss: 0.2804 - val_accuracy: 0.9233
 -> id = 18  Epoch: 9   accuracy: 0.9916458  val_acc: 0.97333336
48000/48000 - 34s - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.0965 - val_accuracy: 0.9733
 -> id = 12  Epoch: 9   accuracy: 0.9678958  val_acc: 0.9701667
48000/48000 - 35s - loss: 0.1032 - accuracy: 0.9679 - val_loss: 0.0988 - val_accuracy: 0.9702
 -> id = 19  Epoch: 9   accuracy: 0.992625  val_acc: 0.97275
48000/48000 - 35s - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.0948 - val_accuracy: 0.9728
 -> id = 6  Epoch: 9   accuracy: 0.997375  val_acc: 0.9716667
48000/48000 - 32s - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.1100 - val_accuracy: 0.9717
 -> id = 3  Epoch: 7   accuracy: 0.98854166  val_acc: 0.97941667
48000/48000 - 41s - loss: 0.0364 - accuracy: 0.9885 - val_loss: 0.0713 - val_accuracy: 0.9794
Epoch 9/10
 -> id = 0  Epoch: 7   accuracy: 0.9858125  val_acc: 0.98
48000/48000 - 41s - loss: 0.0427 - accuracy: 0.9858 - val_loss: 0.0686 - val_accuracy: 0.9800
Epoch 9/10
 -> id = 4  Epoch: 8   accuracy: 0.9863125  val_acc: 0.97858334
48000/48000 - 37s - loss: 0.0420 - accuracy: 0.9863 - val_loss: 0.0778 - val_accuracy: 0.9786
Epoch 10/10
 -> id = 11  Epoch: 9   accuracy: 0.990125  val_acc: 0.97108334
48000/48000 - 31s - loss: 0.0388 - accuracy: 0.9901 - val_loss: 0.1594 - val_accuracy: 0.9711
 -> id = 8  Epoch: 8   accuracy: 0.97316664  val_acc: 0.96966666
48000/48000 - 36s - loss: 0.0923 - accuracy: 0.9732 - val_loss: 0.1032 - val_accuracy: 0.9697
Epoch 10/10
 -> id = 14  Epoch: 8   accuracy: 0.98564583  val_acc: 0.9723333
48000/48000 - 35s - loss: 0.0459 - accuracy: 0.9856 - val_loss: 0.1174 - val_accuracy: 0.9723
Epoch 10/10
 -> id = 15  Epoch: 7   accuracy: 0.98889583  val_acc: 0.97316664
48000/48000 - 40s - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.0972 - val_accuracy: 0.9732
Epoch 9/10
 -> id = 5  Epoch: 8   accuracy: 0.9910833  val_acc: 0.9713333
48000/48000 - 30s - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.1075 - val_accuracy: 0.9713
Epoch 10/10
 -> id = 1  Epoch: 7   accuracy: 0.9869375  val_acc: 0.97825
48000/48000 - 36s - loss: 0.0406 - accuracy: 0.9869 - val_loss: 0.0776 - val_accuracy: 0.9783
Epoch 9/10
 -> id = 9  Epoch: 7   accuracy: 0.9854375  val_acc: 0.97375
48000/48000 - 36s - loss: 0.0484 - accuracy: 0.9854 - val_loss: 0.0878 - val_accuracy: 0.9737
Epoch 9/10
 -> id = 3  Epoch: 8   accuracy: 0.9881458  val_acc: 0.9795833
48000/48000 - 29s - loss: 0.0352 - accuracy: 0.9881 - val_loss: 0.0751 - val_accuracy: 0.9796
Epoch 10/10
 -> id = 0  Epoch: 8   accuracy: 0.9874375  val_acc: 0.9788333
48000/48000 - 28s - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0769 - val_accuracy: 0.9788
Epoch 10/10
 -> id = 4  Epoch: 9   accuracy: 0.9876875  val_acc: 0.9795
48000/48000 - 29s - loss: 0.0368 - accuracy: 0.9877 - val_loss: 0.0708 - val_accuracy: 0.9795
 -> id = 8  Epoch: 9   accuracy: 0.97702086  val_acc: 0.97141665
48000/48000 - 24s - loss: 0.0802 - accuracy: 0.9770 - val_loss: 0.0976 - val_accuracy: 0.9714
 -> id = 14  Epoch: 9   accuracy: 0.98702085  val_acc: 0.976
48000/48000 - 24s - loss: 0.0393 - accuracy: 0.9870 - val_loss: 0.1134 - val_accuracy: 0.9760
 -> id = 15  Epoch: 8   accuracy: 0.9904583  val_acc: 0.9745833
48000/48000 - 27s - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.1013 - val_accuracy: 0.9746
Epoch 10/10
 -> id = 5  Epoch: 9   accuracy: 0.9937292  val_acc: 0.9744167
48000/48000 - 22s - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.0991 - val_accuracy: 0.9744
 -> id = 9  Epoch: 8   accuracy: 0.9865208  val_acc: 0.976
48000/48000 - 22s - loss: 0.0446 - accuracy: 0.9865 - val_loss: 0.0874 - val_accuracy: 0.9760
Epoch 10/10
 -> id = 0  Epoch: 9   accuracy: 0.98833334  val_acc: 0.9805
48000/48000 - 16s - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.0754 - val_accuracy: 0.9805
 -> id = 1  Epoch: 8   accuracy: 0.98747915  val_acc: 0.97933334
48000/48000 - 23s - loss: 0.0388 - accuracy: 0.9875 - val_loss: 0.0736 - val_accuracy: 0.9793
Epoch 10/10
 -> id = 3  Epoch: 9   accuracy: 0.98933333  val_acc: 0.97925
48000/48000 - 18s - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.0742 - val_accuracy: 0.9793
 -> id = 15  Epoch: 9   accuracy: 0.9906875  val_acc: 0.97291666
48000/48000 - 15s - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.1090 - val_accuracy: 0.9729
 -> id = 9  Epoch: 9   accuracy: 0.9887292  val_acc: 0.97608334
48000/48000 - 10s - loss: 0.0371 - accuracy: 0.9887 - val_loss: 0.0868 - val_accuracy: 0.9761
 -> id = 1  Epoch: 9   accuracy: 0.98810416  val_acc: 0.97975
48000/48000 - 10s - loss: 0.0361 - accuracy: 0.9881 - val_loss: 0.0738 - val_accuracy: 0.9797
 id = 0  val_accuracy = 0.9804999828338623
 id = 1  val_accuracy = 0.9797499775886536
 id = 4  val_accuracy = 0.9794999957084656
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!  4   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Model: "model_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_290 (Dense)            (None, 1050)              824250
_________________________________________________________________
activation_209 (Activation)  (None, 1050)              0
_________________________________________________________________
dropout_106 (Dropout)        (None, 1050)              0
_________________________________________________________________
batch_normalization_116 (Bat (None, 1050)              4200
_________________________________________________________________
dense_291 (Dense)            (None, 10)                10510
=================================================================
Total params: 838,960
Trainable params: 836,860
Non-trainable params: 2,100
_________________________________________________________________
None
Model: "model_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_292 (Dense)            (None, 1880)              1475800
_________________________________________________________________
activation_210 (Activation)  (None, 1880)              0
_________________________________________________________________
dropout_107 (Dropout)        (None, 1880)              0
_________________________________________________________________
batch_normalization_117 (Bat (None, 1880)              7520
_________________________________________________________________
dense_293 (Dense)            (None, 10)                18810
=================================================================
Total params: 1,502,130
Trainable params: 1,498,370
Non-trainable params: 3,760
_________________________________________________________________
None
Model: "model_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_294 (Dense)            (None, 1554)              1219890
_________________________________________________________________
activation_211 (Activation)  (None, 1554)              0
_________________________________________________________________
dropout_108 (Dropout)        (None, 1554)              0
_________________________________________________________________
batch_normalization_118 (Bat (None, 1554)              6216
_________________________________________________________________
dense_295 (Dense)            (None, 10)                15550
=================================================================
Total params: 1,241,656
Trainable params: 1,238,548
Non-trainable params: 3,108
_________________________________________________________________
None
Model: "model_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_296 (Dense)            (None, 1103)              865855
_________________________________________________________________
activation_212 (Activation)  (None, 1103)              0
_________________________________________________________________
dropout_109 (Dropout)        (None, 1103)              0
_________________________________________________________________
batch_normalization_119 (Bat (None, 1103)              4412
_________________________________________________________________
dense_297 (Dense)            (None, 10)                11040
=================================================================
Total params: 881,307
Trainable params: 879,101
Non-trainable params: 2,206
_________________________________________________________________
None
Model: "model_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_298 (Dense)            (None, 1511)              1186135
_________________________________________________________________
activation_213 (Activation)  (None, 1511)              0
_________________________________________________________________
dropout_110 (Dropout)        (None, 1511)              0
_________________________________________________________________
batch_normalization_120 (Bat (None, 1511)              6044
_________________________________________________________________
dense_299 (Dense)            (None, 10)                15120
=================================================================
Total params: 1,207,299
Trainable params: 1,204,277
Non-trainable params: 3,022
_________________________________________________________________
None
Model: "model_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_300 (Dense)            (None, 1820)              1428700
_________________________________________________________________
activation_214 (Activation)  (None, 1820)              0
_________________________________________________________________
dropout_111 (Dropout)        (None, 1820)              0
_________________________________________________________________
dense_301 (Dense)            (None, 10)                18210
=================================================================
Total params: 1,446,910
Trainable params: 1,446,910
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_302 (Dense)            (None, 910)               714350
_________________________________________________________________
activation_215 (Activation)  (None, 910)               0
_________________________________________________________________
dropout_112 (Dropout)        (None, 910)               0
_________________________________________________________________
dense_303 (Dense)            (None, 10)                9110
=================================================================
Total params: 723,460
Trainable params: 723,460
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_304 (Dense)            (None, 880)               690800
_________________________________________________________________
activation_216 (Activation)  (None, 880)               0
_________________________________________________________________
batch_normalization_121 (Bat (None, 880)               3520
_________________________________________________________________
dense_305 (Dense)            (None, 10)                8810
=================================================================
Total params: 703,130
Trainable params: 701,370
Non-trainable params: 1,760
_________________________________________________________________
None
Model: "model_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_306 (Dense)            (None, 1570)              1232450
_________________________________________________________________
activation_217 (Activation)  (None, 1570)              0
_________________________________________________________________
dropout_113 (Dropout)        (None, 1570)              0
_________________________________________________________________
dense_307 (Dense)            (None, 10)                15710
=================================================================
Total params: 1,248,160
Trainable params: 1,248,160
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_308 (Dense)            (None, 1830)              1436550
_________________________________________________________________
activation_218 (Activation)  (None, 1830)              0
_________________________________________________________________
dropout_114 (Dropout)        (None, 1830)              0
_________________________________________________________________
batch_normalization_122 (Bat (None, 1830)              7320
_________________________________________________________________
dense_309 (Dense)            (None, 10)                18310
=================================================================
Total params: 1,462,180
Trainable params: 1,458,520
Non-trainable params: 3,660
_________________________________________________________________
None
Model: "model_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_310 (Dense)            (None, 1810)              1420850
_________________________________________________________________
activation_219 (Activation)  (None, 1810)              0
_________________________________________________________________
dropout_115 (Dropout)        (None, 1810)              0
_________________________________________________________________
batch_normalization_123 (Bat (None, 1810)              7240
_________________________________________________________________
dense_311 (Dense)            (None, 10)                18110
=================================================================
Total params: 1,446,200
Trainable params: 1,442,580
Non-trainable params: 3,620
_________________________________________________________________
None
Model: "model_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_312 (Dense)            (None, 1250)              981250
_________________________________________________________________
activation_220 (Activation)  (None, 1250)              0
_________________________________________________________________
dropout_116 (Dropout)        (None, 1250)              0
_________________________________________________________________
batch_normalization_124 (Bat (None, 1250)              5000
_________________________________________________________________
dense_313 (Dense)            (None, 10)                12510
=================================================================
Total params: 998,760
Trainable params: 996,260
Non-trainable params: 2,500
_________________________________________________________________
None
Model: "model_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_314 (Dense)            (None, 1800)              1413000
_________________________________________________________________
activation_221 (Activation)  (None, 1800)              0
_________________________________________________________________
batch_normalization_125 (Bat (None, 1800)              7200
_________________________________________________________________
dense_315 (Dense)            (None, 10)                18010
=================================================================
Total params: 1,438,210
Trainable params: 1,434,610
Non-trainable params: 3,600
_________________________________________________________________
None
Model: "model_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_316 (Dense)            (None, 990)               777150
_________________________________________________________________
activation_222 (Activation)  (None, 990)               0
_________________________________________________________________
batch_normalization_126 (Bat (None, 990)               3960
_________________________________________________________________
dense_317 (Dense)            (None, 10)                9910
=================================================================
Total params: 791,020
Trainable params: 789,040
Non-trainable params: 1,980
_________________________________________________________________
None
Model: "model_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_318 (Dense)            (None, 600)               471000
_________________________________________________________________
activation_223 (Activation)  (None, 600)               0
_________________________________________________________________
dropout_117 (Dropout)        (None, 600)               0
_________________________________________________________________
batch_normalization_127 (Bat (None, 600)               2400
_________________________________________________________________
dense_319 (Dense)            (None, 10)                6010
=================================================================
Total params: 479,410
Trainable params: 478,210
Non-trainable params: 1,200
_________________________________________________________________
None
Model: "model_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_320 (Dense)            (None, 1110)              871350
_________________________________________________________________
activation_224 (Activation)  (None, 1110)              0
_________________________________________________________________
dropout_118 (Dropout)        (None, 1110)              0
_________________________________________________________________
batch_normalization_128 (Bat (None, 1110)              4440
_________________________________________________________________
dense_321 (Dense)            (None, 10)                11110
=================================================================
Total params: 886,900
Trainable params: 884,680
Non-trainable params: 2,220
_________________________________________________________________
None
Model: "model_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_322 (Dense)            (None, 1570)              1232450
_________________________________________________________________
activation_225 (Activation)  (None, 1570)              0
_________________________________________________________________
dropout_119 (Dropout)        (None, 1570)              0
_________________________________________________________________
batch_normalization_129 (Bat (None, 1570)              6280
_________________________________________________________________
dense_323 (Dense)            (None, 10)                15710
=================================================================
Total params: 1,254,440
Trainable params: 1,251,300
Non-trainable params: 3,140
_________________________________________________________________
None
Model: "model_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_324 (Dense)            (None, 330)               259050
_________________________________________________________________
activation_226 (Activation)  (None, 330)               0
_________________________________________________________________
dense_325 (Dense)            (None, 10)                3310
=================================================================
Total params: 262,360
Trainable params: 262,360
Non-trainable params: 0
_________________________________________________________________
None
Model: "model_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_326 (Dense)            (None, 1560)              1224600
_________________________________________________________________
activation_227 (Activation)  (None, 1560)              0
_________________________________________________________________
dropout_120 (Dropout)        (None, 1560)              0
_________________________________________________________________
batch_normalization_130 (Bat (None, 1560)              6240
_________________________________________________________________
dense_327 (Dense)            (None, 10)                15610
=================================================================
Total params: 1,246,450
Trainable params: 1,243,330
Non-trainable params: 3,120
_________________________________________________________________
None
Model: "model_100"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
inputs_basa (InputLayer)     [(None, 784)]             0
_________________________________________________________________
dense_328 (Dense)            (None, 1480)              1161800
_________________________________________________________________
activation_228 (Activation)  (None, 1480)              0
_________________________________________________________________
dense_329 (Dense)            (None, 10)                14810
=================================================================
Total params: 1,176,610
Trainable params: 1,176,610
Non-trainable params: 0
_________________________________________________________________
None
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10Train on 48000 samples, validate on 12000 samples

Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesEpoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10

Train on 48000 samples, validate on 12000 samples
Train on 48000 samples, validate on 12000 samplesEpoch 1/10
Epoch 1/10

Epoch 1/10Epoch 1/10
Train on 48000 samples, validate on 12000 samples
Epoch 1/10
Epoch 1/10

 -> id = 17  Epoch: 0   accuracy: 0.887875  val_acc: 0.916
48000/48000 - 40s - loss: 0.3953 - accuracy: 0.8879 - val_loss: 0.2972 - val_accuracy: 0.9160
Epoch 2/10
 -> id = 6  Epoch: 0   accuracy: 0.85202086  val_acc: 0.93
48000/48000 - 44s - loss: 0.4849 - accuracy: 0.8520 - val_loss: 0.2311 - val_accuracy: 0.9300
Epoch 2/10
 -> id = 19  Epoch: 0   accuracy: 0.92477083  val_acc: 0.96166664
48000/48000 - 46s - loss: 0.2577 - accuracy: 0.9248 - val_loss: 0.1278 - val_accuracy: 0.9617
Epoch 2/10
 -> id = 5  Epoch: 0   accuracy: 0.88614583  val_acc: 0.92275
48000/48000 - 49s - loss: 0.3815 - accuracy: 0.8861 - val_loss: 0.2740 - val_accuracy: 0.9227
Epoch 2/10
 -> id = 8  Epoch: 0   accuracy: 0.89922917  val_acc: 0.9335
48000/48000 - 52s - loss: 0.3462 - accuracy: 0.8992 - val_loss: 0.2310 - val_accuracy: 0.9335
Epoch 2/10
 -> id = 3  Epoch: 0   accuracy: 0.9268542  val_acc: 0.96125
48000/48000 - 72s - loss: 0.2429 - accuracy: 0.9269 - val_loss: 0.1468 - val_accuracy: 0.9613
Epoch 2/10
 -> id = 16  Epoch: 0   accuracy: 0.8975  val_acc: 0.94208336
48000/48000 - 73s - loss: 0.3716 - accuracy: 0.8975 - val_loss: 0.2076 - val_accuracy: 0.9421
Epoch 2/10
 -> id = 18  Epoch: 0   accuracy: 0.8519167  val_acc: 0.8398333
48000/48000 - 74s - loss: 0.6046 - accuracy: 0.8519 - val_loss: 1.3840 - val_accuracy: 0.8398
Epoch 2/10
 -> id = 12  Epoch: 0   accuracy: 0.9405625  val_acc: 0.963
48000/48000 - 76s - loss: 0.2057 - accuracy: 0.9406 - val_loss: 0.1503 - val_accuracy: 0.9630
Epoch 2/10
 -> id = 0  Epoch: 0   accuracy: 0.9264167  val_acc: 0.9669167
48000/48000 - 76s - loss: 0.2435 - accuracy: 0.9264 - val_loss: 0.1403 - val_accuracy: 0.9669
Epoch 2/10
 -> id = 14  Epoch: 0   accuracy: 0.89727086  val_acc: 0.9350833
48000/48000 - 77s - loss: 0.3618 - accuracy: 0.8973 - val_loss: 0.2306 - val_accuracy: 0.9351
Epoch 2/10
 -> id = 7  Epoch: 0   accuracy: 0.9111458  val_acc: 0.9399167
48000/48000 - 78s - loss: 0.3176 - accuracy: 0.9111 - val_loss: 0.2075 - val_accuracy: 0.9399
Epoch 2/10
 -> id = 4  Epoch: 0   accuracy: 0.9274167  val_acc: 0.96325
48000/48000 - 79s - loss: 0.2430 - accuracy: 0.9274 - val_loss: 0.1389 - val_accuracy: 0.9632
Epoch 2/10
 -> id = 13  Epoch: 0   accuracy: 0.88602084  val_acc: 0.87383336
48000/48000 - 78s - loss: 0.4226 - accuracy: 0.8860 - val_loss: 0.5841 - val_accuracy: 0.8738
Epoch 2/10
 -> id = 15  Epoch: 0   accuracy: 0.8782708  val_acc: 0.92466664
48000/48000 - 79s - loss: 0.4233 - accuracy: 0.8783 - val_loss: 0.2640 - val_accuracy: 0.9247
Epoch 2/10
 -> id = 2  Epoch: 0   accuracy: 0.9290208  val_acc: 0.9633333
48000/48000 - 82s - loss: 0.2385 - accuracy: 0.9290 - val_loss: 0.1378 - val_accuracy: 0.9633
Epoch 2/10
 -> id = 1  Epoch: 0   accuracy: 0.9279583  val_acc: 0.96458334
48000/48000 - 82s - loss: 0.2376 - accuracy: 0.9280 - val_loss: 0.1380 - val_accuracy: 0.9646
Epoch 2/10
 -> id = 17  Epoch: 1   accuracy: 0.91525  val_acc: 0.9231667
48000/48000 - 42s - loss: 0.3004 - accuracy: 0.9153 - val_loss: 0.2774 - val_accuracy: 0.9232
Epoch 3/10
 -> id = 6  Epoch: 1   accuracy: 0.926625  val_acc: 0.9565833
48000/48000 - 39s - loss: 0.2388 - accuracy: 0.9266 - val_loss: 0.1508 - val_accuracy: 0.9566
Epoch 3/10
 -> id = 11  Epoch: 0   accuracy: 0.8819375  val_acc: 0.9270833
48000/48000 - 84s - loss: 0.4151 - accuracy: 0.8819 - val_loss: 0.2575 - val_accuracy: 0.9271
Epoch 2/10
 -> id = 9  Epoch: 0   accuracy: 0.851625  val_acc: 0.918
48000/48000 - 87s - loss: 0.4956 - accuracy: 0.8516 - val_loss: 0.2787 - val_accuracy: 0.9180
Epoch 2/10
 -> id = 10  Epoch: 0   accuracy: 0.86266667  val_acc: 0.90966666
48000/48000 - 88s - loss: 0.4844 - accuracy: 0.8627 - val_loss: 0.3154 - val_accuracy: 0.9097
Epoch 2/10
 -> id = 19  Epoch: 1   accuracy: 0.9711875  val_acc: 0.97125
48000/48000 - 47s - loss: 0.0977 - accuracy: 0.9712 - val_loss: 0.0956 - val_accuracy: 0.9712
Epoch 3/10
 -> id = 8  Epoch: 1   accuracy: 0.9366458  val_acc: 0.9496667
48000/48000 - 53s - loss: 0.2190 - accuracy: 0.9366 - val_loss: 0.1798 - val_accuracy: 0.9497
Epoch 3/10
 -> id = 5  Epoch: 1   accuracy: 0.9180833  val_acc: 0.93691665
48000/48000 - 56s - loss: 0.2780 - accuracy: 0.9181 - val_loss: 0.2178 - val_accuracy: 0.9369
Epoch 3/10
 -> id = 3  Epoch: 1   accuracy: 0.96695834  val_acc: 0.97041667
48000/48000 - 48s - loss: 0.1105 - accuracy: 0.9670 - val_loss: 0.0941 - val_accuracy: 0.9704
Epoch 3/10
 -> id = 6  Epoch: 2   accuracy: 0.94310415  val_acc: 0.96241665
48000/48000 - 41s - loss: 0.1783 - accuracy: 0.9431 - val_loss: 0.1297 - val_accuracy: 0.9624
Epoch 4/10
 -> id = 16  Epoch: 1   accuracy: 0.9489375  val_acc: 0.95891666
48000/48000 - 51s - loss: 0.1688 - accuracy: 0.9489 - val_loss: 0.1424 - val_accuracy: 0.9589
Epoch 3/10
 -> id = 18  Epoch: 1   accuracy: 0.94829166  val_acc: 0.96066666
48000/48000 - 53s - loss: 0.1810 - accuracy: 0.9483 - val_loss: 0.1702 - val_accuracy: 0.9607
Epoch 3/10
 -> id = 14  Epoch: 1   accuracy: 0.94341666  val_acc: 0.9565833
48000/48000 - 52s - loss: 0.1945 - accuracy: 0.9434 - val_loss: 0.1517 - val_accuracy: 0.9566
Epoch 3/10
 -> id = 17  Epoch: 2   accuracy: 0.91995835  val_acc: 0.921
48000/48000 - 47s - loss: 0.2861 - accuracy: 0.9200 - val_loss: 0.2830 - val_accuracy: 0.9210
Epoch 4/10
 -> id = 7  Epoch: 1   accuracy: 0.9561667  val_acc: 0.96241665
48000/48000 - 56s - loss: 0.1478 - accuracy: 0.9562 - val_loss: 0.1328 - val_accuracy: 0.9624
Epoch 3/10
 -> id = 0  Epoch: 1   accuracy: 0.96589583  val_acc: 0.9725
48000/48000 - 58s - loss: 0.1120 - accuracy: 0.9659 - val_loss: 0.0942 - val_accuracy: 0.9725
Epoch 3/10
 -> id = 12  Epoch: 1   accuracy: 0.97908336  val_acc: 0.96966666
48000/48000 - 60s - loss: 0.0674 - accuracy: 0.9791 - val_loss: 0.0985 - val_accuracy: 0.9697
Epoch 3/10
 -> id = 15  Epoch: 1   accuracy: 0.9166875  val_acc: 0.94166666
48000/48000 - 59s - loss: 0.2849 - accuracy: 0.9167 - val_loss: 0.2043 - val_accuracy: 0.9417
Epoch 3/10
 -> id = 4  Epoch: 1   accuracy: 0.96760416  val_acc: 0.97183335
48000/48000 - 60s - loss: 0.1092 - accuracy: 0.9676 - val_loss: 0.0942 - val_accuracy: 0.9718
Epoch 3/10
 -> id = 13  Epoch: 1   accuracy: 0.9084167  val_acc: 0.91683334
48000/48000 - 61s - loss: 0.3291 - accuracy: 0.9084 - val_loss: 0.3076 - val_accuracy: 0.9168
Epoch 3/10
 -> id = 11  Epoch: 1   accuracy: 0.9222083  val_acc: 0.9445
48000/48000 - 60s - loss: 0.2625 - accuracy: 0.9222 - val_loss: 0.1943 - val_accuracy: 0.9445
Epoch 3/10
 -> id = 2  Epoch: 1   accuracy: 0.966875  val_acc: 0.9695
48000/48000 - 63s - loss: 0.1100 - accuracy: 0.9669 - val_loss: 0.0979 - val_accuracy: 0.9695
Epoch 3/10
 -> id = 19  Epoch: 2   accuracy: 0.98225  val_acc: 0.9751667
48000/48000 - 50s - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.0817 - val_accuracy: 0.9752
Epoch 4/10
 -> id = 1  Epoch: 1   accuracy: 0.9681042  val_acc: 0.97391665
48000/48000 - 64s - loss: 0.1048 - accuracy: 0.9681 - val_loss: 0.0875 - val_accuracy: 0.9739
Epoch 3/10
 -> id = 9  Epoch: 1   accuracy: 0.9147292  val_acc: 0.9490833
48000/48000 - 65s - loss: 0.2894 - accuracy: 0.9147 - val_loss: 0.1876 - val_accuracy: 0.9491
Epoch 3/10
 -> id = 10  Epoch: 1   accuracy: 0.9030625  val_acc: 0.933
48000/48000 - 66s - loss: 0.3335 - accuracy: 0.9031 - val_loss: 0.2422 - val_accuracy: 0.9330
Epoch 3/10
 -> id = 8  Epoch: 2   accuracy: 0.9505  val_acc: 0.95533335
48000/48000 - 51s - loss: 0.1702 - accuracy: 0.9505 - val_loss: 0.1542 - val_accuracy: 0.9553
Epoch 4/10
 -> id = 5  Epoch: 2   accuracy: 0.93385416  val_acc: 0.9468333
48000/48000 - 54s - loss: 0.2212 - accuracy: 0.9339 - val_loss: 0.1922 - val_accuracy: 0.9468
Epoch 4/10
 -> id = 6  Epoch: 3   accuracy: 0.9545  val_acc: 0.9658333
48000/48000 - 38s - loss: 0.1438 - accuracy: 0.9545 - val_loss: 0.1138 - val_accuracy: 0.9658
Epoch 5/10
 -> id = 3  Epoch: 2   accuracy: 0.97489583  val_acc: 0.9730833
48000/48000 - 49s - loss: 0.0818 - accuracy: 0.9749 - val_loss: 0.0892 - val_accuracy: 0.9731
Epoch 4/10
 -> id = 16  Epoch: 2   accuracy: 0.96360415  val_acc: 0.96741664
48000/48000 - 50s - loss: 0.1176 - accuracy: 0.9636 - val_loss: 0.1157 - val_accuracy: 0.9674
Epoch 4/10
 -> id = 17  Epoch: 3   accuracy: 0.921875  val_acc: 0.92583334
48000/48000 - 45s - loss: 0.2786 - accuracy: 0.9219 - val_loss: 0.2748 - val_accuracy: 0.9258
Epoch 5/10
 -> id = 14  Epoch: 2   accuracy: 0.9580208  val_acc: 0.96241665
48000/48000 - 50s - loss: 0.1378 - accuracy: 0.9580 - val_loss: 0.1268 - val_accuracy: 0.9624
Epoch 4/10
 -> id = 18  Epoch: 2   accuracy: 0.9610625  val_acc: 0.9663333
48000/48000 - 52s - loss: 0.1344 - accuracy: 0.9611 - val_loss: 0.1087 - val_accuracy: 0.9663
Epoch 4/10
 -> id = 7  Epoch: 2   accuracy: 0.969875  val_acc: 0.9675
48000/48000 - 54s - loss: 0.1006 - accuracy: 0.9699 - val_loss: 0.1165 - val_accuracy: 0.9675
Epoch 4/10
 -> id = 0  Epoch: 2   accuracy: 0.9764375  val_acc: 0.9773333
48000/48000 - 55s - loss: 0.0782 - accuracy: 0.9764 - val_loss: 0.0837 - val_accuracy: 0.9773
Epoch 4/10
 -> id = 15  Epoch: 2   accuracy: 0.93441665  val_acc: 0.9536667
48000/48000 - 57s - loss: 0.2224 - accuracy: 0.9344 - val_loss: 0.1683 - val_accuracy: 0.9537
Epoch 4/10
 -> id = 12  Epoch: 2   accuracy: 0.9863333  val_acc: 0.97125
48000/48000 - 60s - loss: 0.0429 - accuracy: 0.9863 - val_loss: 0.1021 - val_accuracy: 0.9712
Epoch 4/10
 -> id = 19  Epoch: 3   accuracy: 0.9876875  val_acc: 0.9745
48000/48000 - 52s - loss: 0.0412 - accuracy: 0.9877 - val_loss: 0.0805 - val_accuracy: 0.9745
Epoch 5/10
 -> id = 4  Epoch: 2   accuracy: 0.974375  val_acc: 0.97325
48000/48000 - 61s - loss: 0.0835 - accuracy: 0.9744 - val_loss: 0.0878 - val_accuracy: 0.9732
Epoch 4/10
 -> id = 13  Epoch: 2   accuracy: 0.9125417  val_acc: 0.9123333
48000/48000 - 61s - loss: 0.3088 - accuracy: 0.9125 - val_loss: 0.3106 - val_accuracy: 0.9123
Epoch 4/10
 -> id = 6  Epoch: 4   accuracy: 0.9635  val_acc: 0.9695
48000/48000 - 43s - loss: 0.1176 - accuracy: 0.9635 - val_loss: 0.1034 - val_accuracy: 0.9695
Epoch 6/10
 -> id = 11  Epoch: 2   accuracy: 0.94027084  val_acc: 0.95633334
48000/48000 - 61s - loss: 0.2006 - accuracy: 0.9403 - val_loss: 0.1526 - val_accuracy: 0.9563
Epoch 4/10
 -> id = 2  Epoch: 2   accuracy: 0.9741667  val_acc: 0.97616667
48000/48000 - 61s - loss: 0.0827 - accuracy: 0.9742 - val_loss: 0.0825 - val_accuracy: 0.9762
Epoch 4/10
 -> id = 8  Epoch: 3   accuracy: 0.9598542  val_acc: 0.96258336
48000/48000 - 53s - loss: 0.1359 - accuracy: 0.9599 - val_loss: 0.1311 - val_accuracy: 0.9626
Epoch 5/10
 -> id = 1  Epoch: 2   accuracy: 0.9751667  val_acc: 0.97333336
48000/48000 - 64s - loss: 0.0799 - accuracy: 0.9752 - val_loss: 0.0913 - val_accuracy: 0.9733
Epoch 4/10
 -> id = 5  Epoch: 3   accuracy: 0.9448125  val_acc: 0.95641667
48000/48000 - 54s - loss: 0.1828 - accuracy: 0.9448 - val_loss: 0.1576 - val_accuracy: 0.9564
Epoch 5/10
 -> id = 9  Epoch: 2   accuracy: 0.93983334  val_acc: 0.96025
48000/48000 - 64s - loss: 0.2043 - accuracy: 0.9398 - val_loss: 0.1415 - val_accuracy: 0.9603
Epoch 4/10
 -> id = 3  Epoch: 3   accuracy: 0.9800208  val_acc: 0.97508335
48000/48000 - 48s - loss: 0.0647 - accuracy: 0.9800 - val_loss: 0.0837 - val_accuracy: 0.9751
Epoch 5/10
 -> id = 10  Epoch: 2   accuracy: 0.92733335  val_acc: 0.9468333
48000/48000 - 65s - loss: 0.2478 - accuracy: 0.9273 - val_loss: 0.1865 - val_accuracy: 0.9468
Epoch 4/10
 -> id = 17  Epoch: 4   accuracy: 0.92291665  val_acc: 0.9165
48000/48000 - 46s - loss: 0.2754 - accuracy: 0.9229 - val_loss: 0.2954 - val_accuracy: 0.9165
Epoch 6/10
 -> id = 16  Epoch: 3   accuracy: 0.97333336  val_acc: 0.972
48000/48000 - 50s - loss: 0.0844 - accuracy: 0.9733 - val_loss: 0.0975 - val_accuracy: 0.9720
Epoch 5/10
 -> id = 18  Epoch: 3   accuracy: 0.9689583  val_acc: 0.97025
48000/48000 - 53s - loss: 0.1085 - accuracy: 0.9690 - val_loss: 0.0980 - val_accuracy: 0.9703
Epoch 5/10
 -> id = 14  Epoch: 3   accuracy: 0.96697915  val_acc: 0.96533334
48000/48000 - 55s - loss: 0.1074 - accuracy: 0.9670 - val_loss: 0.1173 - val_accuracy: 0.9653
Epoch 5/10
 -> id = 7  Epoch: 3   accuracy: 0.9772292  val_acc: 0.97033334
48000/48000 - 54s - loss: 0.0737 - accuracy: 0.9772 - val_loss: 0.0996 - val_accuracy: 0.9703
Epoch 5/10
 -> id = 19  Epoch: 4   accuracy: 0.991875  val_acc: 0.97866666
48000/48000 - 50s - loss: 0.0279 - accuracy: 0.9919 - val_loss: 0.0726 - val_accuracy: 0.9787
Epoch 6/10
 -> id = 0  Epoch: 3   accuracy: 0.9796875  val_acc: 0.9759167
48000/48000 - 56s - loss: 0.0655 - accuracy: 0.9797 - val_loss: 0.0789 - val_accuracy: 0.9759
Epoch 5/10
 -> id = 6  Epoch: 5   accuracy: 0.9665  val_acc: 0.97141665
48000/48000 - 44s - loss: 0.1050 - accuracy: 0.9665 - val_loss: 0.1048 - val_accuracy: 0.9714
Epoch 7/10
 -> id = 15  Epoch: 3   accuracy: 0.9435625  val_acc: 0.9595
48000/48000 - 56s - loss: 0.1885 - accuracy: 0.9436 - val_loss: 0.1501 - val_accuracy: 0.9595
Epoch 5/10
 -> id = 12  Epoch: 3   accuracy: 0.9899167  val_acc: 0.97491664
48000/48000 - 61s - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.0865 - val_accuracy: 0.9749
Epoch 5/10
 -> id = 13  Epoch: 3   accuracy: 0.91941667  val_acc: 0.92575
48000/48000 - 57s - loss: 0.2877 - accuracy: 0.9194 - val_loss: 0.2762 - val_accuracy: 0.9258
Epoch 5/10
 -> id = 4  Epoch: 3   accuracy: 0.9785625  val_acc: 0.97683334
48000/48000 - 60s - loss: 0.0690 - accuracy: 0.9786 - val_loss: 0.0795 - val_accuracy: 0.9768
Epoch 5/10
 -> id = 8  Epoch: 4   accuracy: 0.9643125  val_acc: 0.96475
48000/48000 - 54s - loss: 0.1172 - accuracy: 0.9643 - val_loss: 0.1195 - val_accuracy: 0.9647
Epoch 6/10
 -> id = 17  Epoch: 5   accuracy: 0.92395836  val_acc: 0.9245833
48000/48000 - 44s - loss: 0.2698 - accuracy: 0.9240 - val_loss: 0.2733 - val_accuracy: 0.9246
Epoch 7/10
 -> id = 11  Epoch: 3   accuracy: 0.94872916  val_acc: 0.9615833
48000/48000 - 60s - loss: 0.1667 - accuracy: 0.9487 - val_loss: 0.1370 - val_accuracy: 0.9616
Epoch 5/10
 -> id = 2  Epoch: 3   accuracy: 0.97833335  val_acc: 0.9765
48000/48000 - 61s - loss: 0.0690 - accuracy: 0.9783 - val_loss: 0.0814 - val_accuracy: 0.9765
Epoch 5/10
 -> id = 3  Epoch: 4   accuracy: 0.98272914  val_acc: 0.97608334
48000/48000 - 52s - loss: 0.0563 - accuracy: 0.9827 - val_loss: 0.0807 - val_accuracy: 0.9761
Epoch 6/10
 -> id = 5  Epoch: 4   accuracy: 0.95241666  val_acc: 0.9608333
48000/48000 - 57s - loss: 0.1548 - accuracy: 0.9524 - val_loss: 0.1374 - val_accuracy: 0.9608
Epoch 6/10
 -> id = 1  Epoch: 3   accuracy: 0.977875  val_acc: 0.9759167
48000/48000 - 63s - loss: 0.0693 - accuracy: 0.9779 - val_loss: 0.0809 - val_accuracy: 0.9759
Epoch 5/10
 -> id = 16  Epoch: 4   accuracy: 0.9794792  val_acc: 0.9730833
48000/48000 - 53s - loss: 0.0642 - accuracy: 0.9795 - val_loss: 0.0878 - val_accuracy: 0.9731
Epoch 6/10
 -> id = 10  Epoch: 3   accuracy: 0.9451875  val_acc: 0.9601667
48000/48000 - 62s - loss: 0.1862 - accuracy: 0.9452 - val_loss: 0.1502 - val_accuracy: 0.9602
Epoch 5/10
 -> id = 9  Epoch: 3   accuracy: 0.95058334  val_acc: 0.96775
48000/48000 - 67s - loss: 0.1619 - accuracy: 0.9506 - val_loss: 0.1159 - val_accuracy: 0.9678
Epoch 5/10
 -> id = 14  Epoch: 4   accuracy: 0.9752708  val_acc: 0.96875
48000/48000 - 50s - loss: 0.0823 - accuracy: 0.9753 - val_loss: 0.1035 - val_accuracy: 0.9688
Epoch 6/10
 -> id = 18  Epoch: 4   accuracy: 0.9724375  val_acc: 0.9734167
48000/48000 - 53s - loss: 0.0919 - accuracy: 0.9724 - val_loss: 0.0889 - val_accuracy: 0.9734
Epoch 6/10
 -> id = 6  Epoch: 6   accuracy: 0.9715833  val_acc: 0.97541666
48000/48000 - 41s - loss: 0.0914 - accuracy: 0.9716 - val_loss: 0.0897 - val_accuracy: 0.9754
Epoch 8/10
 -> id = 7  Epoch: 4   accuracy: 0.983125  val_acc: 0.97391665
48000/48000 - 51s - loss: 0.0559 - accuracy: 0.9831 - val_loss: 0.0924 - val_accuracy: 0.9739
Epoch 6/10
 -> id = 19  Epoch: 5   accuracy: 0.99379164  val_acc: 0.97466666
48000/48000 - 53s - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0820 - val_accuracy: 0.9747
Epoch 7/10
 -> id = 0  Epoch: 4   accuracy: 0.9829375  val_acc: 0.9755
48000/48000 - 58s - loss: 0.0539 - accuracy: 0.9829 - val_loss: 0.0845 - val_accuracy: 0.9755
Epoch 6/10
 -> id = 15  Epoch: 4   accuracy: 0.9494375  val_acc: 0.9608333
48000/48000 - 58s - loss: 0.1660 - accuracy: 0.9494 - val_loss: 0.1346 - val_accuracy: 0.9608
Epoch 6/10
 -> id = 12  Epoch: 4   accuracy: 0.9932708  val_acc: 0.97258335
48000/48000 - 58s - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0981 - val_accuracy: 0.9726
Epoch 6/10
 -> id = 17  Epoch: 6   accuracy: 0.92483336  val_acc: 0.92325
48000/48000 - 50s - loss: 0.2659 - accuracy: 0.9248 - val_loss: 0.2780 - val_accuracy: 0.9233
Epoch 8/10
 -> id = 3  Epoch: 5   accuracy: 0.9850208  val_acc: 0.978
48000/48000 - 49s - loss: 0.0486 - accuracy: 0.9850 - val_loss: 0.0733 - val_accuracy: 0.9780
Epoch 7/10
 -> id = 13  Epoch: 4   accuracy: 0.9260833  val_acc: 0.93258333
48000/48000 - 61s - loss: 0.2583 - accuracy: 0.9261 - val_loss: 0.2478 - val_accuracy: 0.9326
Epoch 6/10
 -> id = 8  Epoch: 5   accuracy: 0.9683958  val_acc: 0.96575
48000/48000 - 56s - loss: 0.1006 - accuracy: 0.9684 - val_loss: 0.1182 - val_accuracy: 0.9657
Epoch 7/10
 -> id = 4  Epoch: 4   accuracy: 0.9824167  val_acc: 0.97783333
48000/48000 - 60s - loss: 0.0575 - accuracy: 0.9824 - val_loss: 0.0740 - val_accuracy: 0.9778
Epoch 6/10
 -> id = 5  Epoch: 5   accuracy: 0.9577917  val_acc: 0.96358335
48000/48000 - 55s - loss: 0.1383 - accuracy: 0.9578 - val_loss: 0.1311 - val_accuracy: 0.9636
Epoch 7/10
 -> id = 11  Epoch: 4   accuracy: 0.9577708  val_acc: 0.9645
48000/48000 - 62s - loss: 0.1372 - accuracy: 0.9578 - val_loss: 0.1202 - val_accuracy: 0.9645
Epoch 6/10
 -> id = 2  Epoch: 4   accuracy: 0.98029166  val_acc: 0.97775
48000/48000 - 62s - loss: 0.0603 - accuracy: 0.9803 - val_loss: 0.0734 - val_accuracy: 0.9778
Epoch 6/10
 -> id = 16  Epoch: 5   accuracy: 0.9829792  val_acc: 0.97108334
48000/48000 - 52s - loss: 0.0537 - accuracy: 0.9830 - val_loss: 0.1014 - val_accuracy: 0.9711
Epoch 7/10
 -> id = 6  Epoch: 7   accuracy: 0.9745625  val_acc: 0.9745
48000/48000 - 43s - loss: 0.0782 - accuracy: 0.9746 - val_loss: 0.0943 - val_accuracy: 0.9745
Epoch 9/10
 -> id = 1  Epoch: 4   accuracy: 0.98139584  val_acc: 0.9769167
48000/48000 - 65s - loss: 0.0584 - accuracy: 0.9814 - val_loss: 0.0800 - val_accuracy: 0.9769
Epoch 6/10
 -> id = 18  Epoch: 5   accuracy: 0.97641665  val_acc: 0.9741667
48000/48000 - 53s - loss: 0.0803 - accuracy: 0.9764 - val_loss: 0.0894 - val_accuracy: 0.9742
Epoch 7/10
 -> id = 14  Epoch: 5   accuracy: 0.97845834  val_acc: 0.9735
48000/48000 - 55s - loss: 0.0677 - accuracy: 0.9785 - val_loss: 0.0882 - val_accuracy: 0.9735
Epoch 7/10
 -> id = 10  Epoch: 4   accuracy: 0.9576875  val_acc: 0.96358335
48000/48000 - 62s - loss: 0.1400 - accuracy: 0.9577 - val_loss: 0.1261 - val_accuracy: 0.9636
Epoch 6/10
 -> id = 9  Epoch: 4   accuracy: 0.96014583  val_acc: 0.9705
48000/48000 - 66s - loss: 0.1317 - accuracy: 0.9601 - val_loss: 0.1034 - val_accuracy: 0.9705
Epoch 6/10
 -> id = 19  Epoch: 6   accuracy: 0.9965208  val_acc: 0.97783333
48000/48000 - 50s - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0748 - val_accuracy: 0.9778
Epoch 8/10
 -> id = 7  Epoch: 5   accuracy: 0.98683333  val_acc: 0.96775
48000/48000 - 57s - loss: 0.0436 - accuracy: 0.9868 - val_loss: 0.1117 - val_accuracy: 0.9678
Epoch 7/10
 -> id = 17  Epoch: 7   accuracy: 0.9254583  val_acc: 0.92516667
48000/48000 - 45s - loss: 0.2652 - accuracy: 0.9255 - val_loss: 0.2787 - val_accuracy: 0.9252
Epoch 9/10
 -> id = 0  Epoch: 5   accuracy: 0.9839375  val_acc: 0.9769167
48000/48000 - 57s - loss: 0.0500 - accuracy: 0.9839 - val_loss: 0.0769 - val_accuracy: 0.9769
Epoch 7/10
 -> id = 3  Epoch: 6   accuracy: 0.98585415  val_acc: 0.97941667
48000/48000 - 49s - loss: 0.0433 - accuracy: 0.9859 - val_loss: 0.0713 - val_accuracy: 0.9794
Epoch 8/10
 -> id = 15  Epoch: 5   accuracy: 0.95558333  val_acc: 0.96533334
48000/48000 - 59s - loss: 0.1436 - accuracy: 0.9556 - val_loss: 0.1192 - val_accuracy: 0.9653
Epoch 7/10
 -> id = 8  Epoch: 6   accuracy: 0.972  val_acc: 0.9675
48000/48000 - 52s - loss: 0.0894 - accuracy: 0.9720 - val_loss: 0.1036 - val_accuracy: 0.9675
Epoch 8/10
 -> id = 6  Epoch: 8   accuracy: 0.9780833  val_acc: 0.97716665
48000/48000 - 41s - loss: 0.0695 - accuracy: 0.9781 - val_loss: 0.0891 - val_accuracy: 0.9772
Epoch 10/10
 -> id = 12  Epoch: 5   accuracy: 0.9936875  val_acc: 0.97566664
48000/48000 - 59s - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0836 - val_accuracy: 0.9757
Epoch 7/10
 -> id = 13  Epoch: 5   accuracy: 0.93754166  val_acc: 0.93941665
48000/48000 - 59s - loss: 0.2182 - accuracy: 0.9375 - val_loss: 0.2189 - val_accuracy: 0.9394
Epoch 7/10
 -> id = 16  Epoch: 6   accuracy: 0.9857708  val_acc: 0.97725
48000/48000 - 50s - loss: 0.0428 - accuracy: 0.9858 - val_loss: 0.0849 - val_accuracy: 0.9772
Epoch 8/10
 -> id = 5  Epoch: 6   accuracy: 0.9622292  val_acc: 0.96783334
48000/48000 - 56s - loss: 0.1235 - accuracy: 0.9622 - val_loss: 0.1149 - val_accuracy: 0.9678
Epoch 8/10
 -> id = 4  Epoch: 5   accuracy: 0.982375  val_acc: 0.97616667
48000/48000 - 61s - loss: 0.0536 - accuracy: 0.9824 - val_loss: 0.0842 - val_accuracy: 0.9762
Epoch 7/10
 -> id = 11  Epoch: 5   accuracy: 0.9629375  val_acc: 0.9691667
48000/48000 - 60s - loss: 0.1182 - accuracy: 0.9629 - val_loss: 0.1067 - val_accuracy: 0.9692
Epoch 7/10
 -> id = 2  Epoch: 5   accuracy: 0.984125  val_acc: 0.97875
48000/48000 - 61s - loss: 0.0504 - accuracy: 0.9841 - val_loss: 0.0720 - val_accuracy: 0.9787
Epoch 7/10
 -> id = 14  Epoch: 6   accuracy: 0.9816667  val_acc: 0.97533333
48000/48000 - 55s - loss: 0.0571 - accuracy: 0.9817 - val_loss: 0.0861 - val_accuracy: 0.9753
Epoch 8/10
 -> id = 18  Epoch: 6   accuracy: 0.9797083  val_acc: 0.9744167
48000/48000 - 56s - loss: 0.0693 - accuracy: 0.9797 - val_loss: 0.0883 - val_accuracy: 0.9744
Epoch 8/10
 -> id = 19  Epoch: 7   accuracy: 0.99735415  val_acc: 0.9780833
48000/48000 - 49s - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0732 - val_accuracy: 0.9781
Epoch 9/10
 -> id = 1  Epoch: 5   accuracy: 0.9840625  val_acc: 0.97775
48000/48000 - 65s - loss: 0.0504 - accuracy: 0.9841 - val_loss: 0.0786 - val_accuracy: 0.9778
Epoch 7/10
 -> id = 7  Epoch: 6   accuracy: 0.98910415  val_acc: 0.97583336
48000/48000 - 54s - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0876 - val_accuracy: 0.9758
Epoch 8/10
 -> id = 17  Epoch: 8   accuracy: 0.9261875  val_acc: 0.9270833
48000/48000 - 45s - loss: 0.2620 - accuracy: 0.9262 - val_loss: 0.2741 - val_accuracy: 0.9271
Epoch 10/10
 -> id = 10  Epoch: 5   accuracy: 0.9644375  val_acc: 0.9683333
48000/48000 - 64s - loss: 0.1146 - accuracy: 0.9644 - val_loss: 0.1127 - val_accuracy: 0.9683
Epoch 7/10
 -> id = 9  Epoch: 5   accuracy: 0.9651875  val_acc: 0.96975
48000/48000 - 64s - loss: 0.1117 - accuracy: 0.9652 - val_loss: 0.0978 - val_accuracy: 0.9697
Epoch 7/10
 -> id = 6  Epoch: 9   accuracy: 0.97964585  val_acc: 0.9745833
48000/48000 - 40s - loss: 0.0647 - accuracy: 0.9796 - val_loss: 0.0921 - val_accuracy: 0.9746
 -> id = 3  Epoch: 7   accuracy: 0.9863125  val_acc: 0.9785
48000/48000 - 48s - loss: 0.0411 - accuracy: 0.9863 - val_loss: 0.0728 - val_accuracy: 0.9785
Epoch 9/10
 -> id = 0  Epoch: 6   accuracy: 0.98552084  val_acc: 0.9801667
48000/48000 - 58s - loss: 0.0437 - accuracy: 0.9855 - val_loss: 0.0727 - val_accuracy: 0.9802
Epoch 8/10
 -> id = 8  Epoch: 7   accuracy: 0.9763542  val_acc: 0.96858335
48000/48000 - 50s - loss: 0.0776 - accuracy: 0.9764 - val_loss: 0.0995 - val_accuracy: 0.9686
Epoch 9/10
 -> id = 15  Epoch: 6   accuracy: 0.96014583  val_acc: 0.96741664
48000/48000 - 58s - loss: 0.1282 - accuracy: 0.9601 - val_loss: 0.1143 - val_accuracy: 0.9674
Epoch 8/10
 -> id = 16  Epoch: 7   accuracy: 0.988625  val_acc: 0.9780833
48000/48000 - 49s - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.0789 - val_accuracy: 0.9781
Epoch 9/10
 -> id = 12  Epoch: 6   accuracy: 0.9940625  val_acc: 0.97425
48000/48000 - 58s - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.1072 - val_accuracy: 0.9743
Epoch 8/10
 -> id = 5  Epoch: 7   accuracy: 0.965125  val_acc: 0.9676667
48000/48000 - 55s - loss: 0.1111 - accuracy: 0.9651 - val_loss: 0.1118 - val_accuracy: 0.9677
Epoch 9/10
 -> id = 13  Epoch: 6   accuracy: 0.94797915  val_acc: 0.9460833
48000/48000 - 59s - loss: 0.1770 - accuracy: 0.9480 - val_loss: 0.1969 - val_accuracy: 0.9461
Epoch 8/10
 -> id = 4  Epoch: 6   accuracy: 0.9847917  val_acc: 0.97716665
48000/48000 - 60s - loss: 0.0457 - accuracy: 0.9848 - val_loss: 0.0771 - val_accuracy: 0.9772
Epoch 8/10
 -> id = 14  Epoch: 7   accuracy: 0.98510414  val_acc: 0.9755833
48000/48000 - 49s - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.0812 - val_accuracy: 0.9756
Epoch 9/10
 -> id = 19  Epoch: 8   accuracy: 0.9987917  val_acc: 0.98041666
48000/48000 - 47s - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0731 - val_accuracy: 0.9804
Epoch 10/10
 -> id = 11  Epoch: 6   accuracy: 0.96685416  val_acc: 0.9705
48000/48000 - 59s - loss: 0.1053 - accuracy: 0.9669 - val_loss: 0.1001 - val_accuracy: 0.9705
Epoch 8/10
 -> id = 18  Epoch: 7   accuracy: 0.98141664  val_acc: 0.9769167
48000/48000 - 51s - loss: 0.0615 - accuracy: 0.9814 - val_loss: 0.0823 - val_accuracy: 0.9769
Epoch 9/10
 -> id = 2  Epoch: 6   accuracy: 0.98410416  val_acc: 0.97816664
48000/48000 - 59s - loss: 0.0470 - accuracy: 0.9841 - val_loss: 0.0726 - val_accuracy: 0.9782
Epoch 8/10
 -> id = 17  Epoch: 9   accuracy: 0.92554164  val_acc: 0.9259167
48000/48000 - 47s - loss: 0.2603 - accuracy: 0.9255 - val_loss: 0.2766 - val_accuracy: 0.9259
 -> id = 7  Epoch: 7   accuracy: 0.992125  val_acc: 0.97491664
48000/48000 - 53s - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.0962 - val_accuracy: 0.9749
Epoch 9/10
 -> id = 3  Epoch: 8   accuracy: 0.988125  val_acc: 0.9791667
48000/48000 - 47s - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.0733 - val_accuracy: 0.9792
Epoch 10/10
 -> id = 1  Epoch: 6   accuracy: 0.9850208  val_acc: 0.9775
48000/48000 - 62s - loss: 0.0452 - accuracy: 0.9850 - val_loss: 0.0787 - val_accuracy: 0.9775
Epoch 8/10
 -> id = 10  Epoch: 6   accuracy: 0.97066665  val_acc: 0.97041667
48000/48000 - 63s - loss: 0.0934 - accuracy: 0.9707 - val_loss: 0.1017 - val_accuracy: 0.9704
Epoch 8/10
 -> id = 8  Epoch: 8   accuracy: 0.9778542  val_acc: 0.97141665
48000/48000 - 52s - loss: 0.0698 - accuracy: 0.9779 - val_loss: 0.0944 - val_accuracy: 0.9714
Epoch 10/10
 -> id = 0  Epoch: 7   accuracy: 0.98604167  val_acc: 0.979
48000/48000 - 54s - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.0720 - val_accuracy: 0.9790
Epoch 9/10
 -> id = 9  Epoch: 6   accuracy: 0.9699583  val_acc: 0.97375
48000/48000 - 62s - loss: 0.0956 - accuracy: 0.9700 - val_loss: 0.0880 - val_accuracy: 0.9737
Epoch 8/10
 -> id = 16  Epoch: 8   accuracy: 0.991375  val_acc: 0.9780833
48000/48000 - 48s - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.0874 - val_accuracy: 0.9781
Epoch 10/10
 -> id = 15  Epoch: 7   accuracy: 0.9633125  val_acc: 0.97033334
48000/48000 - 54s - loss: 0.1169 - accuracy: 0.9633 - val_loss: 0.1016 - val_accuracy: 0.9703
Epoch 9/10
 -> id = 12  Epoch: 7   accuracy: 0.9945625  val_acc: 0.97325
48000/48000 - 55s - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.1048 - val_accuracy: 0.9732
Epoch 9/10
 -> id = 19  Epoch: 9   accuracy: 0.9984792  val_acc: 0.97683334
48000/48000 - 45s - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0862 - val_accuracy: 0.9768
 -> id = 5  Epoch: 8   accuracy: 0.96891665  val_acc: 0.9698333
48000/48000 - 54s - loss: 0.0999 - accuracy: 0.9689 - val_loss: 0.1096 - val_accuracy: 0.9698
Epoch 10/10
 -> id = 14  Epoch: 8   accuracy: 0.9869375  val_acc: 0.975
48000/48000 - 50s - loss: 0.0403 - accuracy: 0.9869 - val_loss: 0.0816 - val_accuracy: 0.9750
Epoch 10/10
 -> id = 13  Epoch: 7   accuracy: 0.95752084  val_acc: 0.95575
48000/48000 - 57s - loss: 0.1466 - accuracy: 0.9575 - val_loss: 0.1577 - val_accuracy: 0.9557
Epoch 9/10
 -> id = 18  Epoch: 8   accuracy: 0.9833958  val_acc: 0.97608334
48000/48000 - 49s - loss: 0.0538 - accuracy: 0.9834 - val_loss: 0.0825 - val_accuracy: 0.9761
Epoch 10/10
 -> id = 4  Epoch: 7   accuracy: 0.9867708  val_acc: 0.9780833
48000/48000 - 57s - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.0789 - val_accuracy: 0.9781
Epoch 9/10
 -> id = 11  Epoch: 7   accuracy: 0.96954167  val_acc: 0.97141665
48000/48000 - 55s - loss: 0.0945 - accuracy: 0.9695 - val_loss: 0.0980 - val_accuracy: 0.9714
Epoch 9/10
 -> id = 3  Epoch: 9   accuracy: 0.9885  val_acc: 0.97866666
48000/48000 - 44s - loss: 0.0330 - accuracy: 0.9885 - val_loss: 0.0769 - val_accuracy: 0.9787
 -> id = 2  Epoch: 7   accuracy: 0.98595834  val_acc: 0.97875
48000/48000 - 56s - loss: 0.0435 - accuracy: 0.9860 - val_loss: 0.0787 - val_accuracy: 0.9787
Epoch 9/10
 -> id = 7  Epoch: 8   accuracy: 0.9927083  val_acc: 0.9776667
48000/48000 - 51s - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.0847 - val_accuracy: 0.9777
Epoch 10/10
 -> id = 8  Epoch: 9   accuracy: 0.97952086  val_acc: 0.9735
48000/48000 - 47s - loss: 0.0619 - accuracy: 0.9795 - val_loss: 0.0907 - val_accuracy: 0.9735
 -> id = 16  Epoch: 9   accuracy: 0.992  val_acc: 0.97908336
48000/48000 - 45s - loss: 0.0230 - accuracy: 0.9920 - val_loss: 0.0866 - val_accuracy: 0.9791
 -> id = 1  Epoch: 7   accuracy: 0.9869375  val_acc: 0.97775
48000/48000 - 58s - loss: 0.0406 - accuracy: 0.9869 - val_loss: 0.0772 - val_accuracy: 0.9778
Epoch 9/10
 -> id = 0  Epoch: 8   accuracy: 0.9881667  val_acc: 0.97908336
48000/48000 - 49s - loss: 0.0360 - accuracy: 0.9882 - val_loss: 0.0728 - val_accuracy: 0.9791
Epoch 10/10
 -> id = 10  Epoch: 7   accuracy: 0.97541666  val_acc: 0.97358334
48000/48000 - 56s - loss: 0.0796 - accuracy: 0.9754 - val_loss: 0.0926 - val_accuracy: 0.9736
Epoch 9/10
 -> id = 15  Epoch: 8   accuracy: 0.96652085  val_acc: 0.971
48000/48000 - 50s - loss: 0.1053 - accuracy: 0.9665 - val_loss: 0.0979 - val_accuracy: 0.9710
Epoch 10/10
 -> id = 9  Epoch: 7   accuracy: 0.9737292  val_acc: 0.97391665
48000/48000 - 56s - loss: 0.0827 - accuracy: 0.9737 - val_loss: 0.0870 - val_accuracy: 0.9739
Epoch 9/10
 -> id = 5  Epoch: 9   accuracy: 0.9716667  val_acc: 0.97083336
48000/48000 - 43s - loss: 0.0888 - accuracy: 0.9717 - val_loss: 0.1038 - val_accuracy: 0.9708
 -> id = 14  Epoch: 9   accuracy: 0.98866665  val_acc: 0.97625
48000/48000 - 40s - loss: 0.0348 - accuracy: 0.9887 - val_loss: 0.0801 - val_accuracy: 0.9762
 -> id = 12  Epoch: 8   accuracy: 0.9950625  val_acc: 0.9763333
48000/48000 - 48s - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.1040 - val_accuracy: 0.9763
Epoch 10/10
 -> id = 18  Epoch: 9   accuracy: 0.9851875  val_acc: 0.9763333
48000/48000 - 42s - loss: 0.0484 - accuracy: 0.9852 - val_loss: 0.0882 - val_accuracy: 0.9763
 -> id = 13  Epoch: 8   accuracy: 0.96383333  val_acc: 0.9576667
48000/48000 - 45s - loss: 0.1207 - accuracy: 0.9638 - val_loss: 0.1504 - val_accuracy: 0.9577
Epoch 10/10
 -> id = 4  Epoch: 8   accuracy: 0.9863333  val_acc: 0.97966665
48000/48000 - 44s - loss: 0.0419 - accuracy: 0.9863 - val_loss: 0.0685 - val_accuracy: 0.9797
Epoch 10/10
 -> id = 11  Epoch: 8   accuracy: 0.97327083  val_acc: 0.97225
48000/48000 - 43s - loss: 0.0821 - accuracy: 0.9733 - val_loss: 0.0889 - val_accuracy: 0.9722
Epoch 10/10
 -> id = 7  Epoch: 9   accuracy: 0.99425  val_acc: 0.97791666
48000/48000 - 36s - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0882 - val_accuracy: 0.9779
 -> id = 2  Epoch: 8   accuracy: 0.9867917  val_acc: 0.98041666
48000/48000 - 41s - loss: 0.0395 - accuracy: 0.9868 - val_loss: 0.0720 - val_accuracy: 0.9804
Epoch 10/10
 -> id = 0  Epoch: 9   accuracy: 0.98875  val_acc: 0.97908336
48000/48000 - 34s - loss: 0.0355 - accuracy: 0.9887 - val_loss: 0.0766 - val_accuracy: 0.9791
 -> id = 15  Epoch: 9   accuracy: 0.96914583  val_acc: 0.9711667
48000/48000 - 32s - loss: 0.0947 - accuracy: 0.9691 - val_loss: 0.0984 - val_accuracy: 0.9712
 -> id = 1  Epoch: 8   accuracy: 0.9866458  val_acc: 0.9788333
48000/48000 - 39s - loss: 0.0403 - accuracy: 0.9866 - val_loss: 0.0736 - val_accuracy: 0.9788
Epoch 10/10
 -> id = 10  Epoch: 8   accuracy: 0.97933334  val_acc: 0.97491664
48000/48000 - 37s - loss: 0.0648 - accuracy: 0.9793 - val_loss: 0.0884 - val_accuracy: 0.9749
Epoch 10/10
 -> id = 12  Epoch: 9   accuracy: 0.9956875  val_acc: 0.9745833
48000/48000 - 31s - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.1021 - val_accuracy: 0.9746
 -> id = 9  Epoch: 8   accuracy: 0.9766875  val_acc: 0.97616667
48000/48000 - 37s - loss: 0.0732 - accuracy: 0.9767 - val_loss: 0.0825 - val_accuracy: 0.9762
Epoch 10/10
 -> id = 13  Epoch: 9   accuracy: 0.96945834  val_acc: 0.9630833
48000/48000 - 29s - loss: 0.1015 - accuracy: 0.9695 - val_loss: 0.1288 - val_accuracy: 0.9631
 -> id = 4  Epoch: 9   accuracy: 0.98804164  val_acc: 0.98083335
48000/48000 - 29s - loss: 0.0358 - accuracy: 0.9880 - val_loss: 0.0652 - val_accuracy: 0.9808
 -> id = 11  Epoch: 9   accuracy: 0.97695833  val_acc: 0.97475
48000/48000 - 29s - loss: 0.0718 - accuracy: 0.9770 - val_loss: 0.0844 - val_accuracy: 0.9747
 -> id = 2  Epoch: 9   accuracy: 0.9874167  val_acc: 0.97891665
48000/48000 - 28s - loss: 0.0361 - accuracy: 0.9874 - val_loss: 0.0717 - val_accuracy: 0.9789
 -> id = 1  Epoch: 9   accuracy: 0.9879583  val_acc: 0.979
48000/48000 - 20s - loss: 0.0373 - accuracy: 0.9880 - val_loss: 0.0780 - val_accuracy: 0.9790
 -> id = 10  Epoch: 9   accuracy: 0.98225  val_acc: 0.97491664
48000/48000 - 19s - loss: 0.0549 - accuracy: 0.9822 - val_loss: 0.0865 - val_accuracy: 0.9749
 -> id = 9  Epoch: 9   accuracy: 0.98022914  val_acc: 0.9766667
48000/48000 - 15s - loss: 0.0630 - accuracy: 0.9802 - val_loss: 0.0817 - val_accuracy: 0.9767
 id = 4  val_accuracy = 0.9808333516120911
 id = 0  val_accuracy = 0.9790833592414856
 id = 16  val_accuracy = 0.9790833592414856
